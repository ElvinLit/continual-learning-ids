{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c094fa-8da6-48b6-b19f-1627adfbfcba",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72e802f5-4d04-43b3-ba66-19400b29a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.base import clone\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "765e6a2d-453f-4b10-8aa3-c4e8f516e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a1d38bf-fc37-42ff-a9a8-c5e35b2978b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('data/x_train.npy')\n",
    "y_train = np.load('data/y_train.npy')\n",
    "\n",
    "X_test = np.load('data/x_test.npy')\n",
    "y_test = np.load('data/y_test.npy')\n",
    "\n",
    "X = np.concatenate([X_train, X_test], axis=0)\n",
    "y = np.concatenate([y_train, y_test], axis=0)\n",
    "\n",
    "y = np.where(y == 6, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878d0ff6-198a-4f43-bf2c-9c795817ad9e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fefa4ff-04b2-4dda-8b66-08c618fb7be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_phi(normal_data, c):\n",
    "    \"\"\"\n",
    "    Concept creation function for normal data.\n",
    "    Uses k-Means clustering to partition normal data into c clusters.\n",
    "    \n",
    "    Args:\n",
    "        normal_data (numpy array): The normal data points.\n",
    "        c (int): Number of desired normal concepts.\n",
    "    \n",
    "    Returns:\n",
    "        list of numpy arrays: List of normal clusters.\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=c, random_state=42)\n",
    "    labels = kmeans.fit_predict(normal_data)\n",
    "    \n",
    "    normal_concepts = [normal_data[labels == i] for i in range(c)]\n",
    "    print(\"Finished creating normal concepts\")\n",
    "    \n",
    "    return normal_concepts\n",
    "\n",
    "\n",
    "def create_gamma(anomaly_data, c):\n",
    "    \"\"\"\n",
    "    Concept creation function for anomaly data.\n",
    "    Uses k-Means clustering to partition anomaly data into c clusters.\n",
    "    \n",
    "    Args:\n",
    "        anomaly_data (numpy array): The anomaly data points.\n",
    "        c (int): Number of desired anomaly concepts.\n",
    "    \n",
    "    Returns:\n",
    "        list of numpy arrays: List of anomaly clusters.\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=c, random_state=42)\n",
    "    labels = kmeans.fit_predict(anomaly_data)\n",
    "    \n",
    "    anomaly_concepts = [anomaly_data[labels == i] for i in range(c)]\n",
    "    print(\"Finished creating anomaly concepts\")\n",
    "    \n",
    "    return anomaly_concepts\n",
    "    \n",
    "def match_lambda(anomaly_concepts, normal_concepts):\n",
    "    \"\"\"\n",
    "    Matches each normal concept with the closest anomaly concept.\n",
    "    Uses Euclidean distance to determine the best match.\n",
    "    \n",
    "    Args:\n",
    "        anomaly_concepts (list of numpy arrays): List of anomaly clusters.\n",
    "        normal_concepts (list of numpy arrays): List of normal clusters.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Pairs of (normal_concept, matched_anomaly_concept)\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    remaining_anomalies = anomaly_concepts.copy()\n",
    "\n",
    "    for normal_concept in normal_concepts:\n",
    "        normal_centroid = np.mean(normal_concept, axis=0)\n",
    "        anomaly_centroids = [np.mean(ac, axis=0) for ac in remaining_anomalies]\n",
    "\n",
    "        distances = cdist([normal_centroid], anomaly_centroids, metric='euclidean')[0]\n",
    "        closest_idx = np.argmin(distances)\n",
    "\n",
    "        pairs.append((normal_concept, remaining_anomalies[closest_idx]))\n",
    "        remaining_anomalies.pop(closest_idx)\n",
    "\n",
    "    print(\"Finished matching concept pairs\")\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "def lifelong_roc_auc(R):\n",
    "    \"\"\"\n",
    "    Computes the Lifelong ROC-AUC metric.\n",
    "    \n",
    "    Args:\n",
    "        R (numpy array): NxN matrix of ROC-AUC scores, where R[i, j] is the model's \n",
    "                         performance on concept j after learning concept i.\n",
    "    \n",
    "    Returns:\n",
    "        float: Lifelong ROC-AUC score.\n",
    "    \"\"\"\n",
    "    N = R.shape[0]\n",
    "    lower_triangular_sum = np.sum(np.tril(R))\n",
    "    normalization_factor = (N * (N + 1)) / 2\n",
    "\n",
    "    return lower_triangular_sum / normalization_factor\n",
    "\n",
    "def BWT(R):\n",
    "    \"\"\"\n",
    "    Computes the Backward Transfer (BWT) score.\n",
    "    \n",
    "    Args:\n",
    "        R (numpy array): NxN results matrix.\n",
    "    \n",
    "    Returns:\n",
    "        float: BWT score.\n",
    "    \"\"\"\n",
    "    N = R.shape[0]\n",
    "    backward_transfer = 0\n",
    "    count = 0\n",
    "\n",
    "    for i in range(1, N):\n",
    "        for j in range(i):\n",
    "            backward_transfer += (R[i, j] - R[j, j])\n",
    "            count += 1\n",
    "\n",
    "    return backward_transfer / count if count > 0 else 0\n",
    "\n",
    "def FWT(R):\n",
    "    \"\"\"\n",
    "    Computes the Forward Transfer (FWT) score.\n",
    "    \n",
    "    Args:\n",
    "        R (numpy array): NxN results matrix.\n",
    "    \n",
    "    Returns:\n",
    "        float: FWT score.\n",
    "    \"\"\"\n",
    "    N = R.shape[0]\n",
    "    forward_transfer = 0\n",
    "    count = 0\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(i + 1, N): \n",
    "            forward_transfer += R[i, j]\n",
    "            count += 1\n",
    "\n",
    "    return forward_transfer / count if count > 0 else 0 \n",
    "\n",
    "def kolmogorov_smirnov_test(X_old, X_new, alpha=0.05):\n",
    "    \"\"\"Detect concept drift using KS-test on feature distributions.\"\"\"\n",
    "    \n",
    "    p_values = [ks_2samp(X_old[:, i], X_new[:, i]).pvalue for i in range(X_old.shape[1])]\n",
    "    return np.any(np.array(p_values) < alpha)\n",
    "\n",
    "def histogram_binning(X, bins=25):\n",
    "    \"\"\"Convert sample distributions into histograms.\"\"\"\n",
    "    \n",
    "    return np.array([np.histogram(X[:, i], bins=bins, density=True)[0] for i in range(X.shape[1])]).T\n",
    "\n",
    "def kl_divergence(P, Q):\n",
    "    \"\"\"Compute KL divergence between two distributions.\"\"\"\n",
    "    \n",
    "    P, Q = np.clip(P, 1e-10, None), np.clip(Q, 1e-10, None)  # Avoid log(0)\n",
    "    return np.sum(P * np.log(P / Q))\n",
    "\n",
    "def strategic_sample_selection(X_old, X_new, top_k=100, learning_rate=0.01, num_iterations=100):\n",
    "    \"\"\"\n",
    "    Selects representative new samples by minimizing KL divergence.\n",
    "    \n",
    "    Args:\n",
    "        X_old (numpy.ndarray): Old memory buffer samples.\n",
    "        X_new (numpy.ndarray): Incoming new samples.\n",
    "        top_k (int): Number of samples to retain.\n",
    "        learning_rate (float): Step size for optimization.\n",
    "        num_iterations (int): Number of optimization steps.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Selected representative new samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    H_old, H_new = histogram_binning(X_old), histogram_binning(X_new)\n",
    "    m_n = np.random.rand(H_new.shape[0])  \n",
    "\n",
    "    def loss_function(m_n):\n",
    "        \"\"\"Computes KL divergence loss for selected samples.\"\"\"\n",
    "        weighted_H_new = H_new * m_n[:, np.newaxis]  \n",
    "        combined_H = (H_old + weighted_H_new) / 2 \n",
    "        return kl_divergence(H_new, combined_H) \n",
    "\n",
    "    progress_bar = tqdm(total=num_iterations, desc=\"Optimizing Sample Selection\", position=0, leave=True)\n",
    "\n",
    "    def callback(xk):\n",
    "        progress_bar.update(1)  \n",
    "\n",
    "    result = minimize(loss_function, m_n, method=\"L-BFGS-B\", bounds=[(0, 1)] * len(m_n), \n",
    "                      options={\"maxiter\": num_iterations, \"ftol\": 1e-10}, callback=callback)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    selected_indices = np.argsort(result.x)[-top_k:]\n",
    "\n",
    "    return X_new[selected_indices] \n",
    "\n",
    "\n",
    "def update_memory_buffer(X_old, X_new_selected, memory_size=3000):\n",
    "    \"\"\"Updates memory buffer using strategic forgetting.\"\"\"\n",
    "    updated_buffer = np.vstack((X_old, X_new_selected))  \n",
    "\n",
    "    if updated_buffer.shape[0] > memory_size:\n",
    "        updated_buffer = updated_buffer[-memory_size:]\n",
    "\n",
    "    return updated_buffer\n",
    "\n",
    "class HierarchicalMemory:\n",
    "    def __init__(self, memory_limit=5000, pyramid_factor=2, centroids_per_concept=10):\n",
    "        self.memory_limit = memory_limit\n",
    "        self.pyramid_factor = pyramid_factor\n",
    "        self.centroids_per_concept = centroids_per_concept\n",
    "        self.memory = {}  # level: [concept1, concept2, ...]\n",
    "\n",
    "    def add_concept(self, data, level=1):\n",
    "        if level not in self.memory:\n",
    "            self.memory[level] = []\n",
    "        self.memory[level].append(np.array(data))\n",
    "        self._summarize_memory()\n",
    "\n",
    "    def _pyramidal_allocation(self):\n",
    "        levels = sorted(self.memory.keys())\n",
    "        weights = np.array([1 / (self.pyramid_factor ** (lvl - 1)) for lvl in levels])\n",
    "        total_weight = weights.sum()\n",
    "        allocations = (weights / total_weight) * self.memory_limit\n",
    "        return {lvl: int(alloc) for lvl, alloc in zip(levels, allocations)}\n",
    "\n",
    "    def _summarize_concept(self, concept, n_samples):\n",
    "        if len(concept) <= n_samples:\n",
    "            return concept\n",
    "        kmeans = KMeans(n_clusters=min(self.centroids_per_concept, len(concept)), random_state=42).fit(concept)\n",
    "        centroids = kmeans.cluster_centers_\n",
    "        distances = np.linalg.norm(concept[:, None] - centroids, axis=2)\n",
    "        closest_indices = np.argmin(distances, axis=0)\n",
    "        summarized = concept[closest_indices]\n",
    "        return summarized\n",
    "\n",
    "    def _summarize_memory(self):\n",
    "        allocations = self._pyramidal_allocation()\n",
    "        for level, concepts in self.memory.items():\n",
    "            summarized_level = []\n",
    "            alloc_per_concept = max(1, allocations[level] // len(concepts))\n",
    "            for concept in concepts:\n",
    "                summarized = self._summarize_concept(concept, alloc_per_concept)\n",
    "                summarized_level.append(summarized)\n",
    "            self.memory[level] = summarized_level\n",
    "\n",
    "    def get_all_memory(self):\n",
    "        all_data = []\n",
    "        for level_concepts in self.memory.values():\n",
    "            for concept in level_concepts:\n",
    "                all_data.append(concept)\n",
    "        return np.vstack(all_data) if all_data else np.empty((0,))\n",
    "\n",
    "def scenario_design(normal_data, anomaly_data, c):\n",
    "    \"\"\"\n",
    "    Implements Algorithm 1 to create a lifelong learning scenario.\n",
    "    \n",
    "    Args:\n",
    "        normal_data (numpy array): The normal data points.\n",
    "        anomaly_data (numpy array): The anomaly data points.\n",
    "        c (int): Number of desired concepts.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: List of (normal_concept, anomaly_concept) pairs forming the scenario.\n",
    "    \"\"\"\n",
    "    normal_concepts = create_phi(normal_data, c)\n",
    "    anomaly_concepts = create_gamma(anomaly_data, c)\n",
    "    \n",
    "    scenario = match_lambda(anomaly_concepts, normal_concepts)\n",
    "    \n",
    "    return scenario\n",
    "\n",
    "def evaluation_protocol(T, E, Y, model, strategy=\"naive\", replay_buffer_size=5000, memory_size=5000, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Implements Algorithm 2: Lifelong Learning Evaluation Protocol with multiple strategies.\n",
    "    \n",
    "    Args:\n",
    "        T (list): Sequence of N training sets.\n",
    "        E (list): Sequence of N testing sets.\n",
    "        Y (list): Sequence of true labels for test sets.\n",
    "        model (sklearn.base.BaseEstimator): A scikit-learn-like model instance that supports `fit` and `decision_function`.\n",
    "        strategy (str): Strategy for training.\n",
    "        replay_buffer_size (int): Maximum size of replay buffer if applicable\n",
    "        memory_size (int): Maximum memory size if applicable\n",
    "        alpha (float): KS-test threshold for drift detection.\n",
    "\n",
    "    Returns:\n",
    "        numpy array: NxN results matrix R where R[i, j] is ROC-AUC of model on E[j] after learning T[i].\n",
    "    \"\"\"\n",
    "    N = len(T)\n",
    "    R = np.zeros((N, N))  \n",
    "\n",
    "    if strategy in [\"cumulative\"]:\n",
    "        cumulative_data = []\n",
    "    \n",
    "    if strategy in [\"replay\"]:\n",
    "        replay_buffer = []\n",
    "\n",
    "    if strategy == \"SSF\":\n",
    "        memory_buffer = None \n",
    "\n",
    "    if strategy == \"hierarchical\":\n",
    "        h_memory = HierarchicalMemory(memory_limit=memory_size, pyramid_factor=2, centroids_per_concept=10)\n",
    "\n",
    "    for i, Ti in tqdm(enumerate(T), desc=f\"Evaluating using {strategy} strategy\"):\n",
    "        current_model = deepcopy(model)\n",
    "\n",
    "        # -- NAIVE --\n",
    "        if strategy == \"naive\":\n",
    "            current_model.fit(Ti)\n",
    "\n",
    "        # -- CUMULATIVE --\n",
    "        elif strategy == \"cumulative\":\n",
    "            cumulative_data.extend(Ti.tolist())\n",
    "            current_model.fit(np.array(cumulative_data)) \n",
    "\n",
    "        # -- REPLAY -- \n",
    "        elif strategy == \"replay\":\n",
    "            if replay_buffer:\n",
    "                combined_data = np.vstack((np.array(replay_buffer), Ti))\n",
    "            else:\n",
    "                combined_data = Ti\n",
    "\n",
    "            current_model.fit(combined_data)\n",
    "            replay_buffer.extend(Ti.tolist())\n",
    "\n",
    "            if len(replay_buffer) > replay_buffer_size:\n",
    "                replay_buffer = replay_buffer[-replay_buffer_size:]\n",
    "        \n",
    "        # -- SSF -- \n",
    "        elif strategy == \"SSF\":\n",
    "            if memory_buffer is None:\n",
    "                memory_buffer = Ti[:memory_size]  \n",
    "            else:\n",
    "                drift_detected = kolmogorov_smirnov_test(memory_buffer, Ti, alpha)\n",
    "                if drift_detected:\n",
    "                    X_new_selected = strategic_sample_selection(memory_buffer, Ti, top_k=1000)\n",
    "                    memory_buffer = update_memory_buffer(memory_buffer, X_new_selected, memory_size=memory_size)\n",
    "            memory_buffer = np.unique(memory_buffer, axis=0)\n",
    "            current_model.fit(memory_buffer)\n",
    "\n",
    "        # -- HIERARCHICAL --\n",
    "        elif strategy == \"hierarchical\":\n",
    "\n",
    "            memory_data = h_memory.get_all_memory()\n",
    "            if memory_data.size == 0:\n",
    "                drift_level = 1\n",
    "            else:\n",
    "                drift_distances = [\n",
    "                    wasserstein_distance(Ti[:, d], memory_data[:, d])\n",
    "                    for d in range(Ti.shape[1])\n",
    "                ]\n",
    "                drift_score = np.mean(drift_distances)\n",
    "                print(f\"drift: {drift_score}\")\n",
    "                \n",
    "                if drift_score < 0.05:\n",
    "                    drift_level = 1\n",
    "                elif drift_score < 0.1:\n",
    "                    drift_level = 2\n",
    "                elif drift_score < 0.2:\n",
    "                    drift_level = 3\n",
    "                else:\n",
    "                    drift_level = 4\n",
    "        \n",
    "            h_memory.add_concept(Ti, level=drift_level)\n",
    "            summarized_memory = h_memory.get_all_memory()\n",
    "            current_model.fit(summarized_memory)\n",
    "\n",
    "        # -- Evaluation --\n",
    "        for j, ((Ej_normal, Ej_anomaly), (y_normal, y_anomaly)) in enumerate(zip(E, Y)):\n",
    "            test_data = np.vstack((Ej_normal, Ej_anomaly))\n",
    "            test_labels = np.hstack((y_normal, y_anomaly))  \n",
    "        \n",
    "            scores = -current_model.decision_function(test_data)  \n",
    "            R[i, j] = average_precision_score(test_labels, scores)\n",
    "\n",
    "    return R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf8d81d-8bba-4559-920b-86f9d642c0c2",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55f3b00c-79f9-4d98-aa7c-0dd1cb98a783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating normal concepts\n",
      "Finished creating anomaly concepts\n",
      "Finished matching concept pairs\n"
     ]
    }
   ],
   "source": [
    "num_concepts = 5\n",
    "\n",
    "X_normal = X[y == 0]  \n",
    "X_anomaly = X[y == 1]\n",
    "\n",
    "normal_concepts = create_phi(X_normal, num_concepts)\n",
    "anomaly_concepts = create_gamma(X_anomaly, num_concepts)\n",
    "\n",
    "concept_pairs = match_lambda(anomaly_concepts, normal_concepts)\n",
    "\n",
    "T = []  \n",
    "E = [] \n",
    "Y = []\n",
    "\n",
    "for normal, anomaly in concept_pairs:\n",
    "\n",
    "    normal_train, normal_test = train_test_split(normal, test_size=0.3, random_state=42)\n",
    "    anomaly_train, anomaly_test = train_test_split(anomaly, test_size=0.3, random_state=42)  \n",
    "\n",
    "    T.append(normal_train)\n",
    "    E.append((normal_test, anomaly_test))\n",
    "\n",
    "    y_normal_test = np.zeros(len(normal_test))\n",
    "    y_anomaly_test = np.ones(len(anomaly_test))\n",
    "    \n",
    "    Y.append((y_normal_test, y_anomaly_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35516e86-3161-46cf-a3fe-2a7559327ca7",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a110d25-bd8e-452a-9aa9-f0ed1110ff78",
   "metadata": {},
   "source": [
    "## LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c9838f-ecee-415c-9b77-f4b5fecb2689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 1it [00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.2009141688186157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 2it [00:01,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.6825707131791178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 3it [00:01,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5369153546908596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 4it [00:02,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5778725606766417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 5it [00:03,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.6058086718178083, BWT: -0.05192413793713711, FWT: 0.8173483540003452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_hm = evaluation_protocol(T, E, Y, LocalOutlierFactor(n_neighbors=20, novelty=True), strategy=\"hierarchical\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_hm)}, BWT: {BWT(R_hm)}, FWT: {FWT(R_hm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8dc23cbb-9f1e-4922-b6d6-30e38b6877e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aluating using SSF strategy: 0it [00:00, ?it/s]\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 273.05it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 256.08it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 276.87it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 326.53it/s]\n",
      "\n",
      "Evaluating using SSF strategy: 5it [00:05,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.7544561432893502, BWT: -0.0039135441339650965, FWT: 0.45301001764958054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_ssf = evaluation_protocol(T, E, Y, LocalOutlierFactor(n_neighbors=20, novelty=True), strategy=\"SSF\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_ssf)}, BWT: {BWT(R_ssf)}, FWT: {FWT(R_ssf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2407e687-65f9-4fd0-91ab-aeec46194150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 5it [00:05,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong PR-AUC: 0.9128745004789134, BWT: -0.09466834976427904, FWT: 0.9157097058148231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_naive = evaluation_protocol(T, E, Y, LocalOutlierFactor(n_neighbors=20, novelty=True), strategy=\"naive\")\n",
    "print(f\"Lifelong PR-AUC: {lifelong_roc_auc(R_naive)}, BWT: {BWT(R_naive)}, FWT: {FWT(R_naive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f739cd8-a365-4473-93f7-afad06db7593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using cumulative strategy: 5it [02:10, 26.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.9238354062988797, BWT: -0.004499087364359666, FWT: 0.17379610432039533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_cumulative = evaluation_protocol(T, E, Y, LocalOutlierFactor(n_neighbors=20, novelty=True), strategy=\"cumulative\")\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_cumulative)}, BWT: {BWT(R_cumulative)}, FWT: {FWT(R_cumulative)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "986be1f1-4345-463c-9e0c-d96d6965c427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 5it [00:08,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong PR-AUC: 0.9050132060003965, BWT: -0.044942094815280595, FWT: 0.907066989353293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_replay = evaluation_protocol(T, E, Y, LocalOutlierFactor(n_neighbors=20, novelty=True), strategy=\"replay\", replay_buffer_size=5000)\n",
    "print(f\"Lifelong PR-AUC: {lifelong_roc_auc(R_replay)}, BWT: {BWT(R_replay)}, FWT: {FWT(R_replay)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea398ac8-335e-4d07-86bf-3f1d38fcb214",
   "metadata": {},
   "source": [
    "## IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2376e23-30fd-487d-872e-2335183a4dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 1it [00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.2009141688186157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 2it [00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.6825707131791178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 3it [00:00,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5369153546908596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 4it [00:01,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5778725606766417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 5it [00:01,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.7977446218811072, BWT: 0.053902109492241966, FWT: 0.6446608787208653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_hm = evaluation_protocol(T, E, Y, IsolationForest(n_estimators=100), strategy=\"hierarchical\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_hm)}, BWT: {BWT(R_hm)}, FWT: {FWT(R_hm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f1f73a7-1ced-4b06-9d95-9ae0910d4276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aluating using SSF strategy: 0it [00:00, ?it/s]\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 281.14it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 253.28it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 237.31it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 244.61it/s]\n",
      "\n",
      "Evaluating using SSF strategy: 5it [00:05,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.6559285630296237, BWT: 0.06868127809581366, FWT: 0.804018261100736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_ssf = evaluation_protocol(T, E, Y,  IsolationForest(n_estimators=100), strategy=\"SSF\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_ssf)}, BWT: {BWT(R_ssf)}, FWT: {FWT(R_ssf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9f202fe-3718-47e9-92e9-0c22128560ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 5it [00:01,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong PR-AUC: 0.9335178099343663, BWT: -0.04675470442762723, FWT: 0.8529475270131522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_naive = evaluation_protocol(T, E, Y, IsolationForest(n_estimators=100), strategy=\"naive\")\n",
    "print(f\"Lifelong PR-AUC: {lifelong_roc_auc(R_naive)}, BWT: {BWT(R_naive)}, FWT: {FWT(R_naive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ce69456-76b9-4ad5-98d0-99dad36d3f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using cumulative strategy: 5it [00:07,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.753897896406868, BWT: -0.0066406078135951676, FWT: 0.7719174809547474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_cumulative = evaluation_protocol(T, E, Y, IsolationForest(n_estimators=100), strategy=\"cumulative\")\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_cumulative)}, BWT: {BWT(R_cumulative)}, FWT: {FWT(R_cumulative)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11c4cd01-9013-4206-a359-b81bd9efc8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 5it [00:01,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong PR-AUC: 0.9284071521088412, BWT: -0.048947079582307804, FWT: 0.8583617431922234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_replay = evaluation_protocol(T, E, Y, IsolationForest(n_estimators=100), strategy=\"replay\", replay_buffer_size=5000)\n",
    "print(f\"Lifelong PR-AUC: {lifelong_roc_auc(R_replay)}, BWT: {BWT(R_replay)}, FWT: {FWT(R_replay)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518a2e23-e8aa-4cb3-821e-7136e982cd8b",
   "metadata": {},
   "source": [
    "## SGDOCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e2fedc2-c496-457f-b96e-03be3be95ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 2it [00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.2009141688186157\n",
      "drift: 0.6825707131791178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 4it [00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5369153546908596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 5it [00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5778725606766417\n",
      "Lifelong ROC-AUC: 0.835257953664189, BWT: -0.0019655490765778773, FWT: 0.9206040708906336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_hm = evaluation_protocol(T, E, Y, SGDOneClassSVM(), strategy=\"hierarchical\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_hm)}, BWT: {BWT(R_hm)}, FWT: {FWT(R_hm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af0bd83b-8946-4170-a140-ab931a8948af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aluating using SSF strategy: 0it [00:00, ?it/s]\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 288.13it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 307.55it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 306.85it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 271.76it/s]\n",
      "\n",
      "Evaluating using SSF strategy: 5it [00:02,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.790790866239933, BWT: -0.004091332504534584, FWT: 0.5467376505389003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_ssf = evaluation_protocol(T, E, Y,  SGDOneClassSVM(), strategy=\"SSF\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_ssf)}, BWT: {BWT(R_ssf)}, FWT: {FWT(R_ssf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dabcbd0-6f8b-4e08-b1f0-df8822d6fcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 5it [00:00, 34.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong PR-AUC: 0.9521660949747427, BWT: -0.02644843476150549, FWT: 0.9161663070040479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_naive = evaluation_protocol(T, E, Y, SGDOneClassSVM(), strategy=\"naive\")\n",
    "print(f\"Lifelong PR-AUC: {lifelong_roc_auc(R_naive)}, BWT: {BWT(R_naive)}, FWT: {FWT(R_naive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4ef0151-6f99-4f48-9025-c789ca69f474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using cumulative strategy: 5it [00:04,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.597799790906325, BWT: -0.215598947769658, FWT: 0.6579349113663381\n"
     ]
    }
   ],
   "source": [
    "R_cumulative = evaluation_protocol(T, E, Y, SGDOneClassSVM(), strategy=\"cumulative\")\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_cumulative)}, BWT: {BWT(R_cumulative)}, FWT: {FWT(R_cumulative)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9ae2708-dbfc-4dbd-ab56-9aedd7405b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 5it [00:00, 19.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong PR-AUC: 0.9097415400631277, BWT: -0.02204239499114761, FWT: 0.9061291883073295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_replay = evaluation_protocol(T, E, Y, SGDOneClassSVM(), strategy=\"replay\", replay_buffer_size=5000)\n",
    "print(f\"Lifelong PR-AUC: {lifelong_roc_auc(R_replay)}, BWT: {BWT(R_replay)}, FWT: {FWT(R_replay)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63ed2c1-c826-4ea1-8f3f-85f6ac4eaa7f",
   "metadata": {},
   "source": [
    "# SLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "767548bb-cfce-4f23-a11a-03a5e88d58af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import SLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e51b9e6f-44fc-467f-affb-b3b031c2008c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6  7  9 10 12 13 14 16 17 18 20 22 24 25 26 27 28 30 31\n",
      " 32 33 34 35 36 37 38 40 41 42 44 45 46 47 48 49 50 51 53 54 55 56 57 58\n",
      " 59 60]\n",
      "epoch  1, training loss: 0.712536, time: 0.7s\n",
      "epoch 10, training loss: 0.659050, time: 0.2s\n",
      "epoch 20, training loss: 0.657261, time: 0.2s\n",
      "epoch 30, training loss: 0.657593, time: 0.2s\n",
      "epoch 40, training loss: 0.656994, time: 0.2s\n",
      "epoch 50, training loss: 0.657273, time: 0.2s\n",
      "epoch 60, training loss: 0.660568, time: 0.2s\n",
      "epoch 70, training loss: 0.657720, time: 0.2s\n",
      "epoch 80, training loss: 0.656769, time: 0.2s\n",
      "epoch 90, training loss: 0.657673, time: 0.2s\n",
      "epoch100, training loss: 0.658179, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 1it [00:59, 59.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.2009141688186157\n",
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  5  6  9 10 11 12 13 15 16 18 19 20 21 22 23 24 25 26 27 28 29\n",
      " 30 31 32 33 34 37 38 39 41 42 43 45 46 48 49 51 52 53 54 55 56 57 58 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.730908, time: 0.3s\n",
      "epoch 10, training loss: 0.684903, time: 0.6s\n",
      "epoch 20, training loss: 0.685247, time: 0.2s\n",
      "epoch 30, training loss: 0.684145, time: 0.2s\n",
      "epoch 40, training loss: 0.684298, time: 0.2s\n",
      "epoch 50, training loss: 0.684007, time: 0.2s\n",
      "epoch 60, training loss: 0.684095, time: 0.2s\n",
      "epoch 70, training loss: 0.683978, time: 0.2s\n",
      "epoch 80, training loss: 0.684351, time: 0.2s\n",
      "epoch 90, training loss: 0.686563, time: 0.2s\n",
      "epoch100, training loss: 0.684172, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 2it [02:04, 63.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.6825707131791178\n",
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6 10 11 13 14 15 16 17 18 19 20 21 22 25 26 27 29 30 31\n",
      " 32 35 36 38 39 40 41 42 43 44 45 46 47 49 50 51 52 53 54 55 56 57 58 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.742276, time: 0.2s\n",
      "epoch 10, training loss: 0.699415, time: 0.2s\n",
      "epoch 20, training loss: 0.698991, time: 0.2s\n",
      "epoch 30, training loss: 0.698774, time: 0.2s\n",
      "epoch 40, training loss: 0.698946, time: 0.2s\n",
      "epoch 50, training loss: 0.699356, time: 0.2s\n",
      "epoch 60, training loss: 0.698485, time: 0.2s\n",
      "epoch 70, training loss: 0.699056, time: 0.2s\n",
      "epoch 80, training loss: 0.699213, time: 0.2s\n",
      "epoch 90, training loss: 0.698442, time: 0.2s\n",
      "epoch100, training loss: 0.698385, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 3it [03:00, 59.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5369153546908596\n",
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 2  3  4  5  6  7  8  9 10 12 14 15 16 17 18 19 20 21 22 23 24 26 29 30\n",
      " 31 32 34 35 36 37 38 40 41 42 43 44 45 46 47 48 49 50 51 53 54 56 57 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.742005, time: 0.2s\n",
      "epoch 10, training loss: 0.693480, time: 0.2s\n",
      "epoch 20, training loss: 0.692852, time: 0.2s\n",
      "epoch 30, training loss: 0.692477, time: 0.2s\n",
      "epoch 40, training loss: 0.692260, time: 0.2s\n",
      "epoch 50, training loss: 0.692188, time: 0.2s\n",
      "epoch 60, training loss: 0.692323, time: 0.2s\n",
      "epoch 70, training loss: 0.692108, time: 0.2s\n",
      "epoch 80, training loss: 0.692044, time: 0.2s\n",
      "epoch 90, training loss: 0.691979, time: 0.2s\n",
      "epoch100, training loss: 0.692024, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 4it [03:54, 57.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5778725606766417\n",
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  4  5  6  7  8  9 10 11 12 13 14 15 17 18 21 22 23 24 25 27 28 30\n",
      " 31 33 34 35 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 57\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.746088, time: 0.2s\n",
      "epoch 10, training loss: 0.698483, time: 0.2s\n",
      "epoch 20, training loss: 0.697748, time: 0.2s\n",
      "epoch 30, training loss: 0.697948, time: 0.6s\n",
      "epoch 40, training loss: 0.703712, time: 0.2s\n",
      "epoch 50, training loss: 0.699852, time: 0.2s\n",
      "epoch 60, training loss: 0.697652, time: 0.2s\n",
      "epoch 70, training loss: 0.697151, time: 0.2s\n",
      "epoch 80, training loss: 0.698701, time: 0.2s\n",
      "epoch 90, training loss: 0.702269, time: 0.3s\n",
      "epoch100, training loss: 0.697445, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 5it [04:51, 58.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.23776955402315705, BWT: 0.0011069075056131066, FWT: 0.264828863878072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_hm = evaluation_protocol(T, E, Y, SLAD(), strategy=\"hierarchical\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_hm)}, BWT: {BWT(R_hm)}, FWT: {FWT(R_hm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc35698c-92f2-46fb-a58b-6951f3dc6538",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using SSF strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6  7  9 10 12 13 14 16 17 18 20 22 24 25 26 27 28 30 31\n",
      " 32 33 34 35 36 37 38 40 41 42 44 45 46 47 48 49 50 51 53 54 55 56 57 58\n",
      " 59 60]\n",
      "epoch  1, training loss: 0.713113, time: 1.2s\n",
      "epoch 10, training loss: 0.658922, time: 1.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 276.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 2  3  4  5  6  8 10 11 12 13 14 16 17 18 19 20 21 22 23 26 27 28 30 31\n",
      " 32 33 34 35 36 37 38 39 40 42 43 44 46 47 48 49 50 51 52 53 54 55 56 57\n",
      " 58 59]\n",
      "epoch  1, training loss: 0.689160, time: 0.2s\n",
      "epoch 10, training loss: 0.635717, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing Sample Selection:   2%|▏         | 2/100 [00:00<00:00, 184.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6  7  8 10 11 12 13 14 16 17 18 19 20 21 22 23 25 26 27\n",
      " 28 29 30 31 34 35 36 38 39 40 41 43 45 46 47 48 49 50 52 54 56 57 58 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.712030, time: 1.3s\n",
      "epoch 10, training loss: 0.662940, time: 1.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 303.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6  7  9 10 12 13 14 15 16 17 18 19 20 21 22 23 25 26 27\n",
      " 28 29 30 31 32 34 35 37 39 40 41 42 43 44 45 46 47 48 50 51 53 55 57 58\n",
      " 59 60]\n",
      "epoch  1, training loss: 0.694377, time: 0.2s\n",
      "epoch 10, training loss: 0.636759, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 274.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 27\n",
      " 28 30 31 32 33 34 36 37 38 40 41 44 45 46 47 49 51 52 53 55 56 57 58 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.679085, time: 1.3s\n",
      "epoch 10, training loss: 0.620422, time: 1.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using SSF strategy: 5it [10:17, 123.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.22979397963140194, BWT: 0.04452327661901747, FWT: 0.1780373793977931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_ssf = evaluation_protocol(T, E, Y, SLAD(epochs=10), strategy=\"SSF\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_ssf)}, BWT: {BWT(R_ssf)}, FWT: {FWT(R_ssf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b1d5060-780a-410d-9abd-f112e25f357e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6  7  9 10 12 13 14 16 17 18 20 22 24 25 26 27 28 30 31\n",
      " 32 33 34 35 36 37 38 40 41 42 44 45 46 47 48 49 50 51 53 54 55 56 57 58\n",
      " 59 60]\n",
      "epoch  1, training loss: 0.712536, time: 4.1s\n",
      "epoch 10, training loss: 0.659050, time: 2.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 1it [07:24, 444.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  5  6  9 10 11 12 13 15 16 18 19 20 21 22 23 24 25 26 27 28 29\n",
      " 30 31 32 33 34 37 38 39 41 42 43 45 46 48 49 51 52 53 54 55 56 57 58 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.731120, time: 2.3s\n",
      "epoch 10, training loss: 0.658768, time: 2.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 2it [14:05, 418.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6 10 11 13 14 15 16 17 18 19 20 21 22 25 26 27 29 30 31\n",
      " 32 35 36 38 39 40 41 42 43 44 45 46 47 49 50 51 52 53 54 55 56 57 58 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.732390, time: 1.1s\n",
      "epoch 10, training loss: 0.639096, time: 1.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 3it [18:04, 336.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 2  3  4  5  6  7  8  9 10 12 14 15 16 17 18 19 20 21 22 23 24 26 29 30\n",
      " 31 32 34 35 36 37 38 40 41 42 43 44 45 46 47 48 49 50 51 53 54 56 57 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.725860, time: 1.6s\n",
      "epoch 10, training loss: 0.669007, time: 1.6s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 4it [22:00, 296.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  4  5  6  7  8  9 10 11 12 13 14 15 17 18 21 22 23 24 25 27 28 30\n",
      " 31 33 34 35 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 57\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.738106, time: 0.7s\n",
      "epoch 10, training loss: 0.671427, time: 0.9s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 5it [25:46, 309.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong PR-AUC: 0.859639351423322, BWT: 0.08450842132602072, FWT: 0.8235790428797447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_naive = evaluation_protocol(T, E, Y, SLAD(epochs=10), strategy=\"naive\")\n",
    "print(f\"Lifelong PR-AUC: {lifelong_roc_auc(R_naive)}, BWT: {BWT(R_naive)}, FWT: {FWT(R_naive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0b8572b-677d-4c67-bf2c-58713031e516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6  7  9 10 12 13 14 16 17 18 20 22 24 25 26 27 28 30 31\n",
      " 32 33 34 35 36 37 38 40 41 42 44 45 46 47 48 49 50 51 53 54 55 56 57 58\n",
      " 59 60]\n",
      "epoch  1, training loss: 0.712536, time: 1.6s\n",
      "epoch 10, training loss: 0.659050, time: 1.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 1it [03:54, 234.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  5  6  9 10 11 12 13 15 16 18 19 20 21 22 23 24 25 26 27 28 29\n",
      " 30 31 32 33 34 37 38 39 41 42 43 45 46 48 49 51 52 53 54 55 56 57 58 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.633241, time: 2.7s\n",
      "epoch 10, training loss: 0.586830, time: 2.7s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 2it [08:11, 247.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6 10 11 13 14 15 16 17 18 19 20 21 22 25 26 27 29 30 31\n",
      " 32 35 36 38 39 40 41 42 43 44 45 46 47 49 50 51 52 53 54 55 56 57 58 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.745461, time: 2.3s\n",
      "epoch 10, training loss: 0.679813, time: 2.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 3it [12:32, 253.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 2  3  4  5  6  7  8  9 10 12 14 15 16 17 18 19 20 21 22 23 24 26 29 30\n",
      " 31 32 34 35 36 37 38 40 41 42 43 44 45 46 47 48 49 50 51 53 54 56 57 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.734115, time: 1.6s\n",
      "epoch 10, training loss: 0.652431, time: 1.7s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 4it [16:46, 253.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  4  5  6  7  8  9 10 11 12 13 14 15 17 18 21 22 23 24 25 27 28 30\n",
      " 31 33 34 35 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 57\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.764536, time: 1.3s\n",
      "epoch 10, training loss: 0.685621, time: 1.4s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 5it [20:53, 250.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong PR-AUC: 0.8440990193874339, BWT: 0.05122011531031388, FWT: 0.8338284824041009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_replay = evaluation_protocol(T, E, Y, SLAD(epochs=10), strategy=\"replay\", replay_buffer_size=5000)\n",
    "print(f\"Lifelong PR-AUC: {lifelong_roc_auc(R_replay)}, BWT: {BWT(R_replay)}, FWT: {FWT(R_replay)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0a878c-3554-438f-965a-5b737daaf531",
   "metadata": {},
   "source": [
    "# ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6868de5b-507d-4d5e-9bf4-1640353034e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c968d091-f41b-4f75-8cc4-5633f614ab07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.948761, time: 0.2s\n",
      "epoch 10, training loss: 0.952242, time: 0.2s\n",
      "epoch 20, training loss: 0.763701, time: 0.2s\n",
      "epoch 30, training loss: 0.657330, time: 0.2s\n",
      "epoch 40, training loss: 0.614635, time: 0.2s\n",
      "epoch 50, training loss: 0.558023, time: 0.2s\n",
      "epoch 60, training loss: 0.516520, time: 0.2s\n",
      "epoch 70, training loss: 0.525952, time: 0.2s\n",
      "epoch 80, training loss: 0.486222, time: 0.2s\n",
      "epoch 90, training loss: 0.475002, time: 0.2s\n",
      "epoch100, training loss: 0.453438, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.987716, time: 0.2s\n",
      "epoch 10, training loss: 0.980755, time: 0.2s\n",
      "epoch 20, training loss: 0.781785, time: 0.2s\n",
      "epoch 30, training loss: 0.683723, time: 0.2s\n",
      "epoch 40, training loss: 0.618962, time: 0.2s\n",
      "epoch 50, training loss: 0.558521, time: 0.2s\n",
      "epoch 60, training loss: 0.534794, time: 0.2s\n",
      "epoch 70, training loss: 0.519491, time: 0.2s\n",
      "epoch 80, training loss: 0.497130, time: 0.2s\n",
      "epoch 90, training loss: 0.493986, time: 0.2s\n",
      "epoch100, training loss: 0.461473, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 636.07it/s]\n",
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 639.55it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  38%|███▊      | 64/168 [00:00<00:00, 634.19it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 632.21it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  39%|███▊      | 65/168 [00:00<00:00, 642.28it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 639.76it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 65/370 [00:00<00:00, 640.83it/s]\u001b[A\n",
      "testing:  35%|███▌      | 130/370 [00:00<00:00, 642.27it/s]\u001b[A\n",
      "testing:  53%|█████▎    | 195/370 [00:00<00:00, 640.00it/s]\u001b[A\n",
      "testing:  70%|███████   | 260/370 [00:00<00:00, 639.06it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 638.80it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 65/370 [00:00<00:00, 644.81it/s]\u001b[A\n",
      "testing:  35%|███▌      | 130/370 [00:00<00:00, 643.40it/s]\u001b[A\n",
      "testing:  53%|█████▎    | 195/370 [00:00<00:00, 630.69it/s]\u001b[A\n",
      "testing:  70%|███████   | 260/370 [00:00<00:00, 636.16it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 637.86it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 65/375 [00:00<00:00, 641.53it/s]\u001b[A\n",
      "testing:  35%|███▍      | 130/375 [00:00<00:00, 641.78it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 195/375 [00:00<00:00, 642.11it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 260/375 [00:00<00:00, 642.62it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 641.87it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 65/375 [00:00<00:00, 644.33it/s]\u001b[A\n",
      "testing:  35%|███▍      | 130/375 [00:00<00:00, 644.44it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 195/375 [00:00<00:00, 645.04it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 260/375 [00:00<00:00, 641.88it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 641.76it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 644.47it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 651.45it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 64/238 [00:00<00:00, 639.15it/s]\u001b[A\n",
      "testing:  54%|█████▍    | 129/238 [00:00<00:00, 641.40it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 641.27it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 65/238 [00:00<00:00, 647.02it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 130/238 [00:00<00:00, 645.08it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 644.30it/s]\u001b[A\n",
      "Evaluating using hierarchical strategy: 1it [00:38, 38.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.2009141688186157\n",
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.839387, time: 0.2s\n",
      "epoch 10, training loss: 0.983760, time: 0.2s\n",
      "epoch 20, training loss: 0.807595, time: 0.2s\n",
      "epoch 30, training loss: 0.707977, time: 0.2s\n",
      "epoch 40, training loss: 0.612029, time: 0.2s\n",
      "epoch 50, training loss: 0.577397, time: 0.2s\n",
      "epoch 60, training loss: 0.555283, time: 0.2s\n",
      "epoch 70, training loss: 0.537713, time: 0.2s\n",
      "epoch 80, training loss: 0.510573, time: 0.2s\n",
      "epoch 90, training loss: 0.543364, time: 0.2s\n",
      "epoch100, training loss: 0.475243, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.888801, time: 0.2s\n",
      "epoch 10, training loss: 1.001919, time: 0.2s\n",
      "epoch 20, training loss: 0.791522, time: 0.2s\n",
      "epoch 30, training loss: 0.703189, time: 0.2s\n",
      "epoch 40, training loss: 0.606171, time: 0.2s\n",
      "epoch 50, training loss: 0.563933, time: 0.2s\n",
      "epoch 60, training loss: 0.540288, time: 0.2s\n",
      "epoch 70, training loss: 0.523950, time: 0.2s\n",
      "epoch 80, training loss: 0.518778, time: 0.2s\n",
      "epoch 90, training loss: 0.485208, time: 0.2s\n",
      "epoch100, training loss: 0.473045, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 646.01it/s]\n",
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 650.40it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  39%|███▊      | 65/168 [00:00<00:00, 642.75it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 639.50it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  39%|███▊      | 65/168 [00:00<00:00, 646.85it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 644.54it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 65/370 [00:00<00:00, 641.80it/s]\u001b[A\n",
      "testing:  35%|███▌      | 130/370 [00:00<00:00, 641.89it/s]\u001b[A\n",
      "testing:  53%|█████▎    | 195/370 [00:00<00:00, 641.69it/s]\u001b[A\n",
      "testing:  70%|███████   | 260/370 [00:00<00:00, 642.49it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 640.64it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 65/370 [00:00<00:00, 646.39it/s]\u001b[A\n",
      "testing:  35%|███▌      | 130/370 [00:00<00:00, 645.64it/s]\u001b[A\n",
      "testing:  53%|█████▎    | 195/370 [00:00<00:00, 644.99it/s]\u001b[A\n",
      "testing:  70%|███████   | 260/370 [00:00<00:00, 643.52it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 641.29it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 65/375 [00:00<00:00, 642.52it/s]\u001b[A\n",
      "testing:  35%|███▍      | 130/375 [00:00<00:00, 643.69it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 195/375 [00:00<00:00, 643.23it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 260/375 [00:00<00:00, 642.40it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 642.14it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 65/375 [00:00<00:00, 644.83it/s]\u001b[A\n",
      "testing:  35%|███▍      | 130/375 [00:00<00:00, 645.10it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 195/375 [00:00<00:00, 644.11it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 260/375 [00:00<00:00, 643.31it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 643.12it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 641.67it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 646.81it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 65/238 [00:00<00:00, 641.28it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 130/238 [00:00<00:00, 642.23it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 641.97it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 65/238 [00:00<00:00, 646.37it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 130/238 [00:00<00:00, 644.51it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 644.64it/s]\u001b[A\n",
      "Evaluating using hierarchical strategy: 2it [01:15, 37.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.6825707131791178\n",
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 10.023214, time: 0.2s\n",
      "epoch 10, training loss: 1.077467, time: 0.2s\n",
      "epoch 20, training loss: 0.883634, time: 0.2s\n",
      "epoch 30, training loss: 0.750454, time: 0.2s\n",
      "epoch 40, training loss: 0.658198, time: 0.2s\n",
      "epoch 50, training loss: 0.597107, time: 0.2s\n",
      "epoch 60, training loss: 0.564311, time: 0.2s\n",
      "epoch 70, training loss: 0.541217, time: 0.2s\n",
      "epoch 80, training loss: 0.521539, time: 0.2s\n",
      "epoch 90, training loss: 0.498727, time: 0.2s\n",
      "epoch100, training loss: 0.546287, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 10.466333, time: 0.2s\n",
      "epoch 10, training loss: 1.074272, time: 0.2s\n",
      "epoch 20, training loss: 0.863848, time: 0.2s\n",
      "epoch 30, training loss: 0.760959, time: 0.2s\n",
      "epoch 40, training loss: 0.713439, time: 0.2s\n",
      "epoch 50, training loss: 0.647319, time: 0.2s\n",
      "epoch 60, training loss: 0.580746, time: 0.2s\n",
      "epoch 70, training loss: 0.555804, time: 0.2s\n",
      "epoch 80, training loss: 0.572009, time: 0.2s\n",
      "epoch 90, training loss: 0.518282, time: 0.2s\n",
      "epoch100, training loss: 0.518624, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 632.46it/s]\n",
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 641.79it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  38%|███▊      | 64/168 [00:00<00:00, 635.96it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 636.97it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  39%|███▊      | 65/168 [00:00<00:00, 645.52it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 642.57it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/370 [00:00<00:00, 638.15it/s]\u001b[A\n",
      "testing:  35%|███▍      | 129/370 [00:00<00:00, 639.91it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 193/370 [00:00<00:00, 639.71it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 257/370 [00:00<00:00, 638.43it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 638.07it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 65/370 [00:00<00:00, 641.51it/s]\u001b[A\n",
      "testing:  35%|███▌      | 130/370 [00:00<00:00, 643.28it/s]\u001b[A\n",
      "testing:  53%|█████▎    | 195/370 [00:00<00:00, 643.77it/s]\u001b[A\n",
      "testing:  70%|███████   | 260/370 [00:00<00:00, 644.13it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 641.98it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 65/375 [00:00<00:00, 641.52it/s]\u001b[A\n",
      "testing:  35%|███▍      | 130/375 [00:00<00:00, 643.12it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 195/375 [00:00<00:00, 644.09it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 260/375 [00:00<00:00, 643.59it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 642.87it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 65/375 [00:00<00:00, 648.18it/s]\u001b[A\n",
      "testing:  35%|███▍      | 130/375 [00:00<00:00, 645.93it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 195/375 [00:00<00:00, 645.48it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 260/375 [00:00<00:00, 645.37it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 644.55it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 642.62it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 647.76it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 65/238 [00:00<00:00, 645.55it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 130/238 [00:00<00:00, 643.06it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 643.58it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 65/238 [00:00<00:00, 645.66it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 130/238 [00:00<00:00, 644.69it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 644.50it/s]\u001b[A\n",
      "Evaluating using hierarchical strategy: 3it [01:54, 38.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5369153546908596\n",
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 9.759340, time: 0.2s\n",
      "epoch 10, training loss: 1.134607, time: 0.2s\n",
      "epoch 20, training loss: 0.897392, time: 0.2s\n",
      "epoch 30, training loss: 0.800953, time: 0.2s\n",
      "epoch 40, training loss: 0.690445, time: 0.2s\n",
      "epoch 50, training loss: 0.656141, time: 0.2s\n",
      "epoch 60, training loss: 0.614994, time: 0.2s\n",
      "epoch 70, training loss: 0.575214, time: 0.2s\n",
      "epoch 80, training loss: 0.549091, time: 0.2s\n",
      "epoch 90, training loss: 0.528218, time: 0.2s\n",
      "epoch100, training loss: 0.518280, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 9.947048, time: 0.2s\n",
      "epoch 10, training loss: 1.203967, time: 0.2s\n",
      "epoch 20, training loss: 0.929582, time: 0.2s\n",
      "epoch 30, training loss: 0.805237, time: 0.2s\n",
      "epoch 40, training loss: 0.736656, time: 0.2s\n",
      "epoch 50, training loss: 0.694338, time: 0.2s\n",
      "epoch 60, training loss: 0.655416, time: 0.2s\n",
      "epoch 70, training loss: 0.621854, time: 0.2s\n",
      "epoch 80, training loss: 0.572150, time: 0.2s\n",
      "epoch 90, training loss: 0.578524, time: 0.2s\n",
      "epoch100, training loss: 0.546114, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 644.29it/s]\n",
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 650.56it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  39%|███▊      | 65/168 [00:00<00:00, 646.16it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 641.11it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  39%|███▊      | 65/168 [00:00<00:00, 647.14it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 644.51it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 65/370 [00:00<00:00, 644.65it/s]\u001b[A\n",
      "testing:  35%|███▌      | 130/370 [00:00<00:00, 644.61it/s]\u001b[A\n",
      "testing:  53%|█████▎    | 195/370 [00:00<00:00, 644.97it/s]\u001b[A\n",
      "testing:  70%|███████   | 260/370 [00:00<00:00, 643.45it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 642.55it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 65/370 [00:00<00:00, 646.99it/s]\u001b[A\n",
      "testing:  35%|███▌      | 130/370 [00:00<00:00, 645.23it/s]\u001b[A\n",
      "testing:  53%|█████▎    | 195/370 [00:00<00:00, 645.40it/s]\u001b[A\n",
      "testing:  70%|███████   | 260/370 [00:00<00:00, 644.63it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 643.96it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 65/375 [00:00<00:00, 645.42it/s]\u001b[A\n",
      "testing:  35%|███▍      | 130/375 [00:00<00:00, 644.81it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 195/375 [00:00<00:00, 643.80it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 260/375 [00:00<00:00, 641.96it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 641.62it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 65/375 [00:00<00:00, 645.19it/s]\u001b[A\n",
      "testing:  35%|███▍      | 130/375 [00:00<00:00, 641.87it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 195/375 [00:00<00:00, 641.72it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 260/375 [00:00<00:00, 641.17it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 640.02it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 640.99it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 647.20it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 65/238 [00:00<00:00, 642.71it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 130/238 [00:00<00:00, 642.81it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 640.92it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 65/238 [00:00<00:00, 644.51it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 130/238 [00:00<00:00, 642.80it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 641.23it/s]\u001b[A\n",
      "Evaluating using hierarchical strategy: 4it [02:32, 38.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5778725606766417\n",
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 10.431931, time: 0.2s\n",
      "epoch 10, training loss: 1.228770, time: 0.2s\n",
      "epoch 20, training loss: 0.935810, time: 0.2s\n",
      "epoch 30, training loss: 0.849331, time: 0.2s\n",
      "epoch 40, training loss: 0.749345, time: 0.2s\n",
      "epoch 50, training loss: 0.730987, time: 0.2s\n",
      "epoch 60, training loss: 0.625350, time: 0.2s\n",
      "epoch 70, training loss: 0.605660, time: 0.2s\n",
      "epoch 80, training loss: 0.565348, time: 0.2s\n",
      "epoch 90, training loss: 0.542000, time: 0.2s\n",
      "epoch100, training loss: 0.517007, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 10.083010, time: 0.2s\n",
      "epoch 10, training loss: 1.122464, time: 0.2s\n",
      "epoch 20, training loss: 0.918111, time: 0.2s\n",
      "epoch 30, training loss: 0.799271, time: 0.2s\n",
      "epoch 40, training loss: 0.715741, time: 0.2s\n",
      "epoch 50, training loss: 0.663231, time: 0.2s\n",
      "epoch 60, training loss: 0.651469, time: 0.2s\n",
      "epoch 70, training loss: 0.573895, time: 0.2s\n",
      "epoch 80, training loss: 0.610289, time: 0.2s\n",
      "epoch 90, training loss: 0.529767, time: 0.2s\n",
      "epoch100, training loss: 0.537167, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 43/43 [00:00<00:00, 641.94it/s]\n",
      "\n",
      "testing: 100%|██████████| 43/43 [00:00<00:00, 643.99it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  38%|███▊      | 64/168 [00:00<00:00, 638.73it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 636.98it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  39%|███▊      | 65/168 [00:00<00:00, 646.31it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 640.84it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/370 [00:00<00:00, 639.60it/s]\u001b[A\n",
      "testing:  35%|███▍      | 128/370 [00:00<00:00, 637.81it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 192/370 [00:00<00:00, 636.96it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 256/370 [00:00<00:00, 636.11it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 636.45it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 65/370 [00:00<00:00, 642.94it/s]\u001b[A\n",
      "testing:  35%|███▌      | 130/370 [00:00<00:00, 641.14it/s]\u001b[A\n",
      "testing:  53%|█████▎    | 195/370 [00:00<00:00, 640.86it/s]\u001b[A\n",
      "testing:  70%|███████   | 260/370 [00:00<00:00, 640.70it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 639.33it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 65/375 [00:00<00:00, 641.24it/s]\u001b[A\n",
      "testing:  35%|███▍      | 130/375 [00:00<00:00, 641.60it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 195/375 [00:00<00:00, 642.06it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 260/375 [00:00<00:00, 642.11it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 642.34it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 65/375 [00:00<00:00, 645.81it/s]\u001b[A\n",
      "testing:  35%|███▍      | 130/375 [00:00<00:00, 643.93it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 195/375 [00:00<00:00, 643.64it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 260/375 [00:00<00:00, 643.88it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 643.11it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 641.26it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 646.56it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 65/238 [00:00<00:00, 641.44it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 130/238 [00:00<00:00, 641.94it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 641.54it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 65/238 [00:00<00:00, 644.32it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 130/238 [00:00<00:00, 642.89it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 642.74it/s]\u001b[A\n",
      "Evaluating using hierarchical strategy: 5it [03:10, 38.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.18070982384736164, BWT: 0.030175774028118257, FWT: 0.42892037910644704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_hm = evaluation_protocol(T, E, Y, ICL(epochs=100), strategy=\"hierarchical\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_hm)}, BWT: {BWT(R_hm)}, FWT: {FWT(R_hm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3b4c53f-fa88-49e1-860c-05f649d4cf8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using SSF strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.557956, time: 1.8s\n",
      "epoch 10, training loss: 0.967617, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.547110, time: 0.2s\n",
      "epoch 10, training loss: 0.968635, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 676.29it/s]\n",
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 686.72it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 683.96it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 680.37it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 686.76it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 683.30it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 684.68it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 686.49it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 684.90it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 683.12it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 683.49it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 686.02it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 684.94it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 685.43it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 684.59it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 683.46it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 68/375 [00:00<00:00, 679.40it/s]\u001b[A\n",
      "testing:  37%|███▋      | 137/375 [00:00<00:00, 682.55it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 206/375 [00:00<00:00, 683.50it/s]\u001b[A\n",
      "testing:  73%|███████▎  | 275/375 [00:00<00:00, 683.50it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 681.91it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 683.19it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 684.66it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 685.60it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 685.07it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 682.78it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 685.17it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 690.09it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 685.71it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 683.94it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 683.67it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 684.30it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 683.74it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 682.80it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 294.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.740979, time: 0.2s\n",
      "epoch 10, training loss: 0.968405, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 10.113696, time: 0.2s\n",
      "epoch 10, training loss: 1.058360, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 688.02it/s]\n",
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 692.07it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 686.64it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 681.80it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 687.01it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 684.28it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 680.38it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 681.54it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 681.69it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 679.62it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 675.10it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 684.30it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 681.74it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 681.10it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 679.78it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 678.83it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 68/375 [00:00<00:00, 678.66it/s]\u001b[A\n",
      "testing:  37%|███▋      | 137/375 [00:00<00:00, 681.56it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 206/375 [00:00<00:00, 679.29it/s]\u001b[A\n",
      "testing:  73%|███████▎  | 275/375 [00:00<00:00, 680.45it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 679.47it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 685.72it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 684.79it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 685.93it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 684.45it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 682.49it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 670.60it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 685.14it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 680.26it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 684.01it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 681.94it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 687.60it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 686.56it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 684.70it/s]\u001b[A\n",
      "Optimizing Sample Selection:   3%|▎         | 3/100 [00:00<00:00, 192.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 9.844010, time: 0.2s\n",
      "epoch 10, training loss: 1.060534, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.572062, time: 0.2s\n",
      "epoch 10, training loss: 1.068390, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 43/43 [00:00<00:00, 684.25it/s]\n",
      "\n",
      "testing: 100%|██████████| 43/43 [00:00<00:00, 685.73it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 685.05it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 684.05it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 684.59it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 682.09it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 682.33it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 683.06it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 683.10it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 682.44it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 682.10it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▉        | 70/370 [00:00<00:00, 690.43it/s]\u001b[A\n",
      "testing:  38%|███▊      | 140/370 [00:00<00:00, 686.92it/s]\u001b[A\n",
      "testing:  56%|█████▋    | 209/370 [00:00<00:00, 685.67it/s]\u001b[A\n",
      "testing:  75%|███████▌  | 278/370 [00:00<00:00, 684.74it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 683.14it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 680.45it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 681.31it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 681.01it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 680.95it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 678.96it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 688.14it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 688.32it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 686.48it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 684.77it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 683.22it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 680.29it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 687.25it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 683.00it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 685.87it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 683.74it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 687.36it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 685.09it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 683.69it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 315.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.861760, time: 0.2s\n",
      "epoch 10, training loss: 1.128419, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 9.071051, time: 0.2s\n",
      "epoch 10, training loss: 1.147296, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 43/43 [00:00<00:00, 692.21it/s]\n",
      "\n",
      "testing: 100%|██████████| 43/43 [00:00<00:00, 686.98it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 686.02it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 684.03it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 688.03it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 687.06it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 685.45it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 686.41it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 686.97it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 684.94it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 683.47it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 684.32it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 685.91it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 685.48it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 682.59it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 681.38it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 682.71it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 683.12it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 682.40it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 679.65it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 679.16it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 684.75it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 684.84it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 684.72it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 683.49it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 681.94it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 682.75it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 687.25it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 68/238 [00:00<00:00, 677.84it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 136/238 [00:00<00:00, 674.94it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 677.41it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 687.02it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 687.49it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 684.47it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 331.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 10.415680, time: 0.2s\n",
      "epoch 10, training loss: 1.237449, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 9.516177, time: 0.2s\n",
      "epoch 10, training loss: 1.172816, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 44/44 [00:00<00:00, 693.96it/s]\n",
      "\n",
      "testing: 100%|██████████| 44/44 [00:00<00:00, 689.75it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 686.92it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 685.81it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  42%|████▏     | 70/168 [00:00<00:00, 691.06it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 689.18it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 684.41it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 682.50it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 682.85it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 681.66it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 680.20it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 682.95it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 682.52it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 682.63it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 682.34it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 680.89it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 680.41it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 681.17it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 682.37it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 680.83it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 679.60it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 684.73it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 684.06it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 676.22it/s]\u001b[A\n",
      "testing:  73%|███████▎  | 275/375 [00:00<00:00, 674.92it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 675.44it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 682.78it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 685.36it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 68/238 [00:00<00:00, 679.63it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 137/238 [00:00<00:00, 683.11it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 681.28it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 688.03it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 685.81it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 683.72it/s]\u001b[A\n",
      "Evaluating using SSF strategy: 5it [00:41,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.21140831558070158, BWT: 0.04032918546117241, FWT: 0.26611288741057415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_ssf = evaluation_protocol(T, E, Y, ICL(epochs=10), strategy=\"SSF\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_ssf)}, BWT: {BWT(R_ssf)}, FWT: {FWT(R_ssf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a8ccdf0-1a1f-49cd-8a91-aab0932d0828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.948761, time: 0.2s\n",
      "epoch 10, training loss: 0.952242, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.603786, time: 0.2s\n",
      "epoch 10, training loss: 0.987010, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 640.68it/s]\n",
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 647.16it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  38%|███▊      | 64/168 [00:00<00:00, 639.00it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 635.00it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  39%|███▊      | 65/168 [00:00<00:00, 641.25it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 638.93it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/370 [00:00<00:00, 639.07it/s]\u001b[A\n",
      "testing:  35%|███▍      | 128/370 [00:00<00:00, 635.66it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 192/370 [00:00<00:00, 636.57it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 256/370 [00:00<00:00, 637.55it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 597.92it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 65/370 [00:00<00:00, 641.47it/s]\u001b[A\n",
      "testing:  35%|███▌      | 130/370 [00:00<00:00, 640.97it/s]\u001b[A\n",
      "testing:  53%|█████▎    | 195/370 [00:00<00:00, 638.17it/s]\u001b[A\n",
      "testing:  70%|███████   | 259/370 [00:00<00:00, 638.31it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 637.67it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/375 [00:00<00:00, 634.86it/s]\u001b[A\n",
      "testing:  34%|███▍      | 128/375 [00:00<00:00, 634.65it/s]\u001b[A\n",
      "testing:  51%|█████     | 192/375 [00:00<00:00, 635.57it/s]\u001b[A\n",
      "testing:  68%|██████▊   | 256/375 [00:00<00:00, 635.59it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 612.50it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 63/375 [00:00<00:00, 623.47it/s]\u001b[A\n",
      "testing:  34%|███▍      | 127/375 [00:00<00:00, 631.68it/s]\u001b[A\n",
      "testing:  51%|█████     | 192/375 [00:00<00:00, 635.77it/s]\u001b[A\n",
      "testing:  68%|██████▊   | 256/375 [00:00<00:00, 635.20it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 634.84it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 636.78it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 642.51it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 64/238 [00:00<00:00, 634.73it/s]\u001b[A\n",
      "testing:  54%|█████▍    | 128/238 [00:00<00:00, 637.25it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 635.46it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  20%|██        | 48/238 [00:00<00:00, 473.48it/s]\u001b[A\n",
      "testing:  46%|████▌     | 110/238 [00:00<00:00, 556.60it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 591.80it/s]\u001b[A\n",
      "Evaluating using naive strategy: 1it [00:07,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 12.216283, time: 0.1s\n",
      "epoch 10, training loss: 1.081261, time: 0.1s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 12.785188, time: 0.1s\n",
      "epoch 10, training loss: 1.002754, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 36/36 [00:00<00:00, 634.73it/s]\n",
      "\n",
      "testing: 100%|██████████| 36/36 [00:00<00:00, 642.81it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  38%|███▊      | 64/168 [00:00<00:00, 638.32it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 636.67it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  39%|███▊      | 65/168 [00:00<00:00, 643.55it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 567.57it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/370 [00:00<00:00, 638.03it/s]\u001b[A\n",
      "testing:  35%|███▍      | 128/370 [00:00<00:00, 635.35it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 192/370 [00:00<00:00, 636.69it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 256/370 [00:00<00:00, 635.86it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 635.54it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/370 [00:00<00:00, 637.04it/s]\u001b[A\n",
      "testing:  35%|███▍      | 128/370 [00:00<00:00, 637.47it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 192/370 [00:00<00:00, 636.71it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 256/370 [00:00<00:00, 637.01it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 636.09it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  13%|█▎        | 48/375 [00:00<00:00, 472.51it/s]\u001b[A\n",
      "testing:  29%|██▉       | 108/375 [00:00<00:00, 545.43it/s]\u001b[A\n",
      "testing:  45%|████▌     | 170/375 [00:00<00:00, 576.58it/s]\u001b[A\n",
      "testing:  62%|██████▏   | 234/375 [00:00<00:00, 600.17it/s]\u001b[A\n",
      "testing:  79%|███████▉  | 298/375 [00:00<00:00, 613.05it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 599.00it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/375 [00:00<00:00, 632.91it/s]\u001b[A\n",
      "testing:  34%|███▍      | 128/375 [00:00<00:00, 634.42it/s]\u001b[A\n",
      "testing:  51%|█████     | 192/375 [00:00<00:00, 634.32it/s]\u001b[A\n",
      "testing:  68%|██████▊   | 256/375 [00:00<00:00, 635.71it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 635.32it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 637.98it/s]\n",
      "\n",
      "testing:   0%|          | 0/61 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 480.53it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 65/238 [00:00<00:00, 642.05it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 130/238 [00:00<00:00, 641.37it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 638.87it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 64/238 [00:00<00:00, 638.21it/s]\u001b[A\n",
      "testing:  54%|█████▍    | 128/238 [00:00<00:00, 638.89it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 636.69it/s]\u001b[A\n",
      "Evaluating using naive strategy: 2it [00:14,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 9.732757, time: 0.3s\n",
      "epoch 10, training loss: 1.307059, time: 0.3s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.951256, time: 0.3s\n",
      "epoch 10, training loss: 1.273736, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing:   0%|          | 0/81 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 81/81 [00:00<00:00, 638.58it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/81 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 81/81 [00:00<00:00, 637.18it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  34%|███▍      | 57/168 [00:00<00:00, 565.62it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 444.85it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  39%|███▊      | 65/168 [00:00<00:00, 644.24it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 638.82it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/370 [00:00<00:00, 637.06it/s]\u001b[A\n",
      "testing:  35%|███▍      | 128/370 [00:00<00:00, 635.90it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 192/370 [00:00<00:00, 634.77it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 256/370 [00:00<00:00, 635.92it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 634.35it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/370 [00:00<00:00, 638.37it/s]\u001b[A\n",
      "testing:  35%|███▍      | 128/370 [00:00<00:00, 577.64it/s]\u001b[A\n",
      "testing:  51%|█████     | 188/370 [00:00<00:00, 587.00it/s]\u001b[A\n",
      "testing:  68%|██████▊   | 252/370 [00:00<00:00, 606.38it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 610.50it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/375 [00:00<00:00, 631.44it/s]\u001b[A\n",
      "testing:  34%|███▍      | 128/375 [00:00<00:00, 631.98it/s]\u001b[A\n",
      "testing:  51%|█████     | 192/375 [00:00<00:00, 631.28it/s]\u001b[A\n",
      "testing:  68%|██████▊   | 256/375 [00:00<00:00, 632.11it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 632.90it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/375 [00:00<00:00, 634.59it/s]\u001b[A\n",
      "testing:  34%|███▍      | 128/375 [00:00<00:00, 634.89it/s]\u001b[A\n",
      "testing:  51%|█████     | 192/375 [00:00<00:00, 577.42it/s]\u001b[A\n",
      "testing:  68%|██████▊   | 256/375 [00:00<00:00, 599.57it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 613.41it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 634.32it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 639.69it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 64/238 [00:00<00:00, 635.51it/s]\u001b[A\n",
      "testing:  54%|█████▍    | 128/238 [00:00<00:00, 633.82it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 633.63it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 64/238 [00:00<00:00, 637.86it/s]\u001b[A\n",
      "testing:  54%|█████▍    | 128/238 [00:00<00:00, 637.04it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 600.56it/s]\u001b[A\n",
      "Evaluating using naive strategy: 3it [00:25,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 10.521512, time: 0.2s\n",
      "epoch 10, training loss: 0.989495, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 9.734859, time: 0.2s\n",
      "epoch 10, training loss: 0.999919, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 46/46 [00:00<00:00, 642.47it/s]\n",
      "\n",
      "testing: 100%|██████████| 46/46 [00:00<00:00, 647.13it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  38%|███▊      | 64/168 [00:00<00:00, 638.38it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 636.76it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  39%|███▊      | 65/168 [00:00<00:00, 641.73it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 637.57it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/370 [00:00<00:00, 632.95it/s]\u001b[A\n",
      "testing:  35%|███▍      | 128/370 [00:00<00:00, 635.21it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 193/370 [00:00<00:00, 637.97it/s]\u001b[A\n",
      "testing:  70%|██████▉   | 258/370 [00:00<00:00, 639.61it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 537.19it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 65/370 [00:00<00:00, 640.21it/s]\u001b[A\n",
      "testing:  35%|███▌      | 130/370 [00:00<00:00, 633.59it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 194/370 [00:00<00:00, 634.81it/s]\u001b[A\n",
      "testing:  70%|██████▉   | 258/370 [00:00<00:00, 635.81it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 635.66it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/375 [00:00<00:00, 631.25it/s]\u001b[A\n",
      "testing:  34%|███▍      | 128/375 [00:00<00:00, 633.57it/s]\u001b[A\n",
      "testing:  51%|█████     | 192/375 [00:00<00:00, 635.26it/s]\u001b[A\n",
      "testing:  68%|██████▊   | 256/375 [00:00<00:00, 537.74it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 541.15it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  16%|█▋        | 61/375 [00:00<00:00, 609.85it/s]\u001b[A\n",
      "testing:  33%|███▎      | 125/375 [00:00<00:00, 626.51it/s]\u001b[A\n",
      "testing:  50%|█████     | 189/375 [00:00<00:00, 632.24it/s]\u001b[A\n",
      "testing:  67%|██████▋   | 253/375 [00:00<00:00, 633.47it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 632.78it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 636.31it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 641.91it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 64/238 [00:00<00:00, 635.76it/s]\u001b[A\n",
      "testing:  54%|█████▍    | 128/238 [00:00<00:00, 528.55it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 582.62it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 64/238 [00:00<00:00, 639.78it/s]\u001b[A\n",
      "testing:  54%|█████▍    | 128/238 [00:00<00:00, 637.05it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 638.36it/s]\u001b[A\n",
      "Evaluating using naive strategy: 4it [00:34,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 13.879924, time: 0.1s\n",
      "epoch 10, training loss: 1.192874, time: 0.1s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 14.775580, time: 0.1s\n",
      "epoch 10, training loss: 1.251964, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 24/24 [00:00<00:00, 426.36it/s]\n",
      "\n",
      "testing: 100%|██████████| 24/24 [00:00<00:00, 489.73it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  39%|███▊      | 65/168 [00:00<00:00, 643.34it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 640.78it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  39%|███▊      | 65/168 [00:00<00:00, 644.48it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 641.36it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/370 [00:00<00:00, 638.45it/s]\u001b[A\n",
      "testing:  35%|███▍      | 128/370 [00:00<00:00, 636.84it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 192/370 [00:00<00:00, 637.71it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 257/370 [00:00<00:00, 638.90it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 638.36it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 65/370 [00:00<00:00, 643.41it/s]\u001b[A\n",
      "testing:  35%|███▌      | 130/370 [00:00<00:00, 538.21it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 191/370 [00:00<00:00, 566.77it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 255/370 [00:00<00:00, 592.41it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 599.49it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/375 [00:00<00:00, 638.17it/s]\u001b[A\n",
      "testing:  34%|███▍      | 128/375 [00:00<00:00, 639.02it/s]\u001b[A\n",
      "testing:  51%|█████     | 192/375 [00:00<00:00, 637.36it/s]\u001b[A\n",
      "testing:  68%|██████▊   | 256/375 [00:00<00:00, 638.04it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 637.44it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/375 [00:00<00:00, 638.77it/s]\u001b[A\n",
      "testing:  34%|███▍      | 128/375 [00:00<00:00, 570.03it/s]\u001b[A\n",
      "testing:  50%|████▉     | 186/375 [00:00<00:00, 569.14it/s]\u001b[A\n",
      "testing:  67%|██████▋   | 250/375 [00:00<00:00, 595.46it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 605.30it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 638.45it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 643.66it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 65/238 [00:00<00:00, 642.41it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 130/238 [00:00<00:00, 637.88it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 637.98it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 64/238 [00:00<00:00, 639.60it/s]\u001b[A\n",
      "testing:  54%|█████▍    | 128/238 [00:00<00:00, 639.40it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 588.62it/s]\u001b[A\n",
      "Evaluating using naive strategy: 5it [00:40,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong PR-AUC: 0.8506130693012651, BWT: 0.081870277354563, FWT: 0.8109753811217235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_naive = evaluation_protocol(T, E, Y, ICL(epochs=10), strategy=\"naive\")\n",
    "print(f\"Lifelong PR-AUC: {lifelong_roc_auc(R_naive)}, BWT: {BWT(R_naive)}, FWT: {FWT(R_naive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21f3dfde-ddf4-4c18-b98d-dfa64b820092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.948761, time: 0.2s\n",
      "epoch 10, training loss: 0.952242, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.603786, time: 0.2s\n",
      "epoch 10, training loss: 0.987010, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 635.54it/s]\n",
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 645.20it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  38%|███▊      | 64/168 [00:00<00:00, 636.52it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 594.98it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  38%|███▊      | 64/168 [00:00<00:00, 631.03it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 634.99it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/370 [00:00<00:00, 634.98it/s]\u001b[A\n",
      "testing:  35%|███▍      | 128/370 [00:00<00:00, 634.72it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 192/370 [00:00<00:00, 633.83it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 256/370 [00:00<00:00, 635.36it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 635.54it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/370 [00:00<00:00, 635.94it/s]\u001b[A\n",
      "testing:  35%|███▍      | 128/370 [00:00<00:00, 636.63it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 192/370 [00:00<00:00, 637.65it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 256/370 [00:00<00:00, 586.92it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 556.30it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/375 [00:00<00:00, 632.31it/s]\u001b[A\n",
      "testing:  34%|███▍      | 128/375 [00:00<00:00, 634.73it/s]\u001b[A\n",
      "testing:  51%|█████     | 192/375 [00:00<00:00, 634.42it/s]\u001b[A\n",
      "testing:  68%|██████▊   | 256/375 [00:00<00:00, 634.77it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 635.01it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/375 [00:00<00:00, 638.93it/s]\u001b[A\n",
      "testing:  34%|███▍      | 129/375 [00:00<00:00, 639.52it/s]\u001b[A\n",
      "testing:  51%|█████▏    | 193/375 [00:00<00:00, 638.20it/s]\u001b[A\n",
      "testing:  69%|██████▊   | 257/375 [00:00<00:00, 453.46it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 533.33it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 637.67it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 640.75it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 64/238 [00:00<00:00, 633.10it/s]\u001b[A\n",
      "testing:  54%|█████▍    | 128/238 [00:00<00:00, 633.18it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 632.71it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 64/238 [00:00<00:00, 635.25it/s]\u001b[A\n",
      "testing:  54%|█████▍    | 128/238 [00:00<00:00, 634.71it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 634.07it/s]\u001b[A\n",
      "Evaluating using replay strategy: 1it [00:07,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 7.577939, time: 0.3s\n",
      "epoch 10, training loss: 0.897464, time: 0.3s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.577353, time: 0.3s\n",
      "epoch 10, training loss: 0.906317, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing:   0%|          | 0/78 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 78/78 [00:00<00:00, 474.62it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/78 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 78/78 [00:00<00:00, 617.06it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  38%|███▊      | 64/168 [00:00<00:00, 637.97it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 635.30it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  38%|███▊      | 64/168 [00:00<00:00, 637.71it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 634.24it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/370 [00:00<00:00, 636.85it/s]\u001b[A\n",
      "testing:  35%|███▍      | 128/370 [00:00<00:00, 632.36it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 192/370 [00:00<00:00, 632.45it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 256/370 [00:00<00:00, 631.68it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 632.03it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  16%|█▌        | 60/370 [00:00<00:00, 592.34it/s]\u001b[A\n",
      "testing:  34%|███▎      | 124/370 [00:00<00:00, 616.56it/s]\u001b[A\n",
      "testing:  51%|█████     | 188/370 [00:00<00:00, 626.24it/s]\u001b[A\n",
      "testing:  68%|██████▊   | 252/370 [00:00<00:00, 629.18it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 627.89it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/375 [00:00<00:00, 634.91it/s]\u001b[A\n",
      "testing:  34%|███▍      | 128/375 [00:00<00:00, 632.75it/s]\u001b[A\n",
      "testing:  51%|█████     | 192/375 [00:00<00:00, 634.39it/s]\u001b[A\n",
      "testing:  68%|██████▊   | 256/375 [00:00<00:00, 635.62it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 635.16it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/375 [00:00<00:00, 634.42it/s]\u001b[A\n",
      "testing:  34%|███▍      | 128/375 [00:00<00:00, 625.76it/s]\u001b[A\n",
      "testing:  51%|█████     | 192/375 [00:00<00:00, 630.99it/s]\u001b[A\n",
      "testing:  69%|██████▊   | 257/375 [00:00<00:00, 634.42it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 633.32it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 636.47it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 642.30it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 64/238 [00:00<00:00, 636.88it/s]\u001b[A\n",
      "testing:  54%|█████▍    | 128/238 [00:00<00:00, 636.46it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 636.62it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 64/238 [00:00<00:00, 639.73it/s]\u001b[A\n",
      "testing:  54%|█████▍    | 128/238 [00:00<00:00, 628.64it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 528.37it/s]\u001b[A\n",
      "Evaluating using replay strategy: 2it [00:18,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 6.835413, time: 0.6s\n",
      "epoch 10, training loss: 1.016230, time: 0.7s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 6.898898, time: 0.6s\n",
      "epoch 10, training loss: 1.043806, time: 0.6s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing:   0%|          | 0/158 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 65/158 [00:00<00:00, 641.70it/s]\u001b[A\n",
      "testing: 100%|██████████| 158/158 [00:00<00:00, 636.16it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/158 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 64/158 [00:00<00:00, 636.91it/s]\u001b[A\n",
      "testing: 100%|██████████| 158/158 [00:00<00:00, 633.37it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  38%|███▊      | 64/168 [00:00<00:00, 635.10it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 631.71it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  38%|███▊      | 64/168 [00:00<00:00, 637.46it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 635.09it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  15%|█▌        | 57/370 [00:00<00:00, 540.64it/s]\u001b[A\n",
      "testing:  30%|███       | 112/370 [00:00<00:00, 539.13it/s]\u001b[A\n",
      "testing:  48%|████▊     | 176/370 [00:00<00:00, 582.34it/s]\u001b[A\n",
      "testing:  65%|██████▍   | 240/370 [00:00<00:00, 603.98it/s]\u001b[A\n",
      "testing:  82%|████████▏ | 304/370 [00:00<00:00, 614.65it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 601.57it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/370 [00:00<00:00, 636.32it/s]\u001b[A\n",
      "testing:  35%|███▍      | 128/370 [00:00<00:00, 635.53it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 192/370 [00:00<00:00, 634.48it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 256/370 [00:00<00:00, 633.22it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 634.30it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/375 [00:00<00:00, 634.44it/s]\u001b[A\n",
      "testing:  34%|███▍      | 128/375 [00:00<00:00, 561.97it/s]\u001b[A\n",
      "testing:  50%|████▉     | 186/375 [00:00<00:00, 569.09it/s]\u001b[A\n",
      "testing:  67%|██████▋   | 250/375 [00:00<00:00, 593.82it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 603.60it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/375 [00:00<00:00, 636.04it/s]\u001b[A\n",
      "testing:  34%|███▍      | 128/375 [00:00<00:00, 635.06it/s]\u001b[A\n",
      "testing:  51%|█████     | 192/375 [00:00<00:00, 635.42it/s]\u001b[A\n",
      "testing:  68%|██████▊   | 256/375 [00:00<00:00, 635.50it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 634.82it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 632.69it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 642.14it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  25%|██▍       | 59/238 [00:00<00:00, 585.90it/s]\u001b[A\n",
      "testing:  50%|████▉     | 118/238 [00:00<00:00, 538.97it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 587.78it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 64/238 [00:00<00:00, 639.04it/s]\u001b[A\n",
      "testing:  54%|█████▍    | 128/238 [00:00<00:00, 636.18it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 635.45it/s]\u001b[A\n",
      "Evaluating using replay strategy: 3it [00:35, 13.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.237390, time: 0.5s\n",
      "epoch 10, training loss: 1.120666, time: 0.6s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 7.529574, time: 0.5s\n",
      "epoch 10, training loss: 1.089599, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 124/124 [00:00<00:00, 635.76it/s][A\n",
      "\n",
      "testing:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 124/124 [00:00<00:00, 635.35it/s][A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  38%|███▊      | 64/168 [00:00<00:00, 637.73it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 635.61it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  28%|██▊       | 47/168 [00:00<00:00, 466.12it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 556.24it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/370 [00:00<00:00, 634.38it/s]\u001b[A\n",
      "testing:  35%|███▍      | 128/370 [00:00<00:00, 633.40it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 192/370 [00:00<00:00, 633.83it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 256/370 [00:00<00:00, 634.17it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 634.20it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/370 [00:00<00:00, 635.10it/s]\u001b[A\n",
      "testing:  35%|███▍      | 128/370 [00:00<00:00, 632.72it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 192/370 [00:00<00:00, 634.12it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 256/370 [00:00<00:00, 548.31it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 576.15it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/375 [00:00<00:00, 636.42it/s]\u001b[A\n",
      "testing:  34%|███▍      | 128/375 [00:00<00:00, 635.83it/s]\u001b[A\n",
      "testing:  51%|█████     | 192/375 [00:00<00:00, 634.68it/s]\u001b[A\n",
      "testing:  68%|██████▊   | 256/375 [00:00<00:00, 634.57it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 635.26it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/375 [00:00<00:00, 635.04it/s]\u001b[A\n",
      "testing:  34%|███▍      | 128/375 [00:00<00:00, 635.39it/s]\u001b[A\n",
      "testing:  51%|█████     | 192/375 [00:00<00:00, 636.31it/s]\u001b[A\n",
      "testing:  68%|██████▊   | 256/375 [00:00<00:00, 636.68it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 558.37it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 634.90it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 639.47it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 64/238 [00:00<00:00, 632.77it/s]\u001b[A\n",
      "testing:  54%|█████▍    | 128/238 [00:00<00:00, 633.08it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 633.47it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 64/238 [00:00<00:00, 635.36it/s]\u001b[A\n",
      "testing:  54%|█████▍    | 128/238 [00:00<00:00, 637.65it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 636.14it/s]\u001b[A\n",
      "Evaluating using replay strategy: 4it [00:50, 13.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 9.332559, time: 0.5s\n",
      "epoch 10, training loss: 1.148323, time: 0.5s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 9.365357, time: 0.4s\n",
      "epoch 10, training loss: 1.148879, time: 0.4s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing:   0%|          | 0/103 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 103/103 [00:00<00:00, 633.50it/s][A\n",
      "\n",
      "testing:   0%|          | 0/103 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 103/103 [00:00<00:00, 636.45it/s][A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  38%|███▊      | 64/168 [00:00<00:00, 634.70it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 566.02it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  39%|███▊      | 65/168 [00:00<00:00, 641.92it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 637.99it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/370 [00:00<00:00, 635.09it/s]\u001b[A\n",
      "testing:  35%|███▍      | 128/370 [00:00<00:00, 632.24it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 192/370 [00:00<00:00, 632.09it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 256/370 [00:00<00:00, 632.51it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 631.95it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/370 [00:00<00:00, 636.70it/s]\u001b[A\n",
      "testing:  35%|███▍      | 128/370 [00:00<00:00, 634.11it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 192/370 [00:00<00:00, 634.41it/s]\u001b[A\n",
      "testing:  69%|██████▉   | 256/370 [00:00<00:00, 569.16it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 555.80it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 63/375 [00:00<00:00, 629.85it/s]\u001b[A\n",
      "testing:  34%|███▍      | 127/375 [00:00<00:00, 630.49it/s]\u001b[A\n",
      "testing:  51%|█████     | 191/375 [00:00<00:00, 630.80it/s]\u001b[A\n",
      "testing:  68%|██████▊   | 255/375 [00:00<00:00, 630.18it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 630.38it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  17%|█▋        | 64/375 [00:00<00:00, 633.79it/s]\u001b[A\n",
      "testing:  34%|███▍      | 128/375 [00:00<00:00, 635.60it/s]\u001b[A\n",
      "testing:  51%|█████     | 192/375 [00:00<00:00, 635.37it/s]\u001b[A\n",
      "testing:  68%|██████▊   | 256/375 [00:00<00:00, 468.77it/s]\u001b[A\n",
      "testing:  82%|████████▏ | 308/375 [00:00<00:00, 479.33it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 532.15it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 636.77it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 639.60it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 64/238 [00:00<00:00, 636.45it/s]\u001b[A\n",
      "testing:  54%|█████▍    | 128/238 [00:00<00:00, 636.66it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 634.17it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  27%|██▋       | 65/238 [00:00<00:00, 640.48it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 130/238 [00:00<00:00, 637.67it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 601.55it/s]\u001b[A\n",
      "Evaluating using replay strategy: 5it [01:03, 12.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong PR-AUC: 0.8403503949329891, BWT: 0.05347278560858655, FWT: 0.8209540266301282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_replay = evaluation_protocol(T, E, Y, ICL(epochs=10), strategy=\"replay\", replay_buffer_size=5000)\n",
    "print(f\"Lifelong PR-AUC: {lifelong_roc_auc(R_replay)}, BWT: {BWT(R_replay)}, FWT: {FWT(R_replay)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7694dfa-3a80-431a-a5fb-363df9d5ee02",
   "metadata": {},
   "source": [
    "# RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a873ad7-face-4d9d-9a8b-d20c3a6fa2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1192f181-05e0-4d44-b773-faea59494903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.133825, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.283720, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 26.88it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 26.88it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 26.79it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  6.74it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.73it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.72it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.72it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.72it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.72it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.72it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.72it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.71it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.71it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.07it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.07it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.07it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.08it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.08it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.08it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.08it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.08it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.08it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.07it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.04it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.04it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.04it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.04it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.04it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.04it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.04it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.04it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.04it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.03it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 18.55it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 18.51it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 18.48it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 18.47it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.44it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.77it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.76it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.76it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.76it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.77it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.76it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.76it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.76it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.76it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.76it/s]\u001b[A\n",
      "Evaluating using hierarchical strategy: 1it [00:12, 12.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.2009141688186157\n",
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.183043, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.281424, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 27.07it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 27.03it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 26.90it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  6.77it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.78it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.77it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.78it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.78it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.77it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.78it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.78it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.78it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.77it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.09it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.09it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.09it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.09it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.09it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.09it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.09it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.09it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.09it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.09it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.05it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.05it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.05it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.05it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.05it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.05it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.05it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.05it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.05it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.05it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 18.71it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 18.65it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 18.65it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 18.67it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.64it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.80it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.80it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.81it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.81it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.81it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.81it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.81it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.81it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.82it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.81it/s]\u001b[A\n",
      "Evaluating using hierarchical strategy: 2it [00:25, 12.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.6825707131791178\n",
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.130460, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.298401, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 27.05it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 26.99it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 26.85it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  6.80it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.79it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.79it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.79it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.79it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.79it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.78it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.79it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.79it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.78it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.10it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.09it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.09it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.09it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.09it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.09it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.10it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.10it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.10it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.09it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.06it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.05it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.05it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.05it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.05it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.05it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.05it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.05it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.05it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.05it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 18.60it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 18.60it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 18.60it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 18.59it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.57it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.81it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.81it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.80it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.80it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.80it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.80it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.80it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.80it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.80it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.80it/s]\u001b[A\n",
      "Evaluating using hierarchical strategy: 3it [00:38, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5369153546908596\n",
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.169789, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.302847, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 27.10it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 27.00it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 26.94it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  6.79it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.78it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.78it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.78it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.78it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.77it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.78it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.77it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.78it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.77it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.10it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.09it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.09it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.07it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.08it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.08it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.09it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.09it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.09it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.08it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.05it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.05it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.04it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.04it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.04it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.04it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.04it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.04it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.04it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.04it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 18.75it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 18.67it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 18.64it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 18.61it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.60it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.80it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.79it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.79it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.79it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.79it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.79it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.79it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.79it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.79it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.79it/s]\u001b[A\n",
      "Evaluating using hierarchical strategy: 4it [00:51, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5778725606766417\n",
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.200156, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.298126, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 26.55it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 26.49it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 26.39it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  6.81it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.80it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.80it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.79it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.79it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.78it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.78it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.77it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.77it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.78it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.10it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.09it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.09it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.09it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.09it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.09it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.09it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.09it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.09it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.09it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.06it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.06it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.05it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.05it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.05it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.05it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.05it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.05it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.05it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.05it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 18.73it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 18.71it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 18.70it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 18.72it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.69it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.81it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.81it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.81it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.78it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.77it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.79it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.79it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.79it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.80it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.79it/s]\u001b[A\n",
      "Evaluating using hierarchical strategy: 5it [01:04, 12.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.31407917418089837, BWT: 0.004820625978131138, FWT: 0.4126868412903904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_hm = evaluation_protocol(T, E, Y, RCA(epochs=10), strategy=\"hierarchical\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_hm)}, BWT: {BWT(R_hm)}, FWT: {FWT(R_hm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3fc7318-cfd4-4160-98c9-b9f3e5014864",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using SSF strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.129436, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.283179, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 28.15it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 28.02it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 27.93it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.02it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.01it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.00it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.00it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.00it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.00it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.98it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.99it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.99it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.99it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.16it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.17it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.17it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.17it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.17it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.13it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.13it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.13it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.13it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.13it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.13it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.13it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.09it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.17it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.19it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.21it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.18it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.96it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.93it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.95it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.95it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.95it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.95it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 299.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.176405, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.286861, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 28.14it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 28.07it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 27.96it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.00it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.98it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.98it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.99it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.99it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.99it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.99it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.99it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.99it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.98it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.19it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.18it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.18it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.18it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.18it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.18it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.14it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.14it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.14it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.01it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.05it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.10it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.28it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.23it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.27it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.28it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.24it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.92it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.91it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.90it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.91it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.92it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.93it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.93it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.93it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.94it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.91it/s]\u001b[A\n",
      "Optimizing Sample Selection:   3%|▎         | 3/100 [00:00<00:00, 255.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.127915, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.297795, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 27.75it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 27.50it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 27.45it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.07it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.03it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.02it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.01it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.01it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.01it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  7.00it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  7.01it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  7.01it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.00it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.17it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.17it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.18it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.18it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.13it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.14it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.29it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.30it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.32it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.35it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.32it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.91it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.92it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.94it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.95it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.95it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.94it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 334.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.143658, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.301785, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 27.48it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 27.46it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 27.39it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.08it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.06it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.06it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.06it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.05it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.05it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  7.05it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  7.04it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  7.04it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.04it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.18it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.19it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.18it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.19it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.20it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.21it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.21it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.20it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.15it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.16it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.16it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.16it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.16it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.40it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.31it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.35it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.38it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.37it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  5.01it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  5.00it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.99it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.99it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.98it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.98it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.98it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.98it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.98it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.98it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 151.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.156713, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.324469, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 27.28it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 27.11it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 26.95it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.03it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.01it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.02it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.06it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.07it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.07it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  7.05it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  7.05it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  7.03it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.04it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.20it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.19it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.18it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.18it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.19it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.20it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.19it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.13it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.15it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.14it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.37it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.28it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.27it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.28it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.27it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.98it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.94it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.95it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.95it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.96it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.95it/s]\u001b[A\n",
      "Evaluating using SSF strategy: 5it [01:07, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.3150596094401886, BWT: 0.008468256555611004, FWT: 0.40685438222971354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_ssf = evaluation_protocol(T, E, Y, RCA(epochs=10), strategy=\"SSF\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_ssf)}, BWT: {BWT(R_ssf)}, FWT: {FWT(R_ssf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d89cd0b8-76b6-416d-ae38-03026f1e0879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.133825, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.283720, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 22.50it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 23.93it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 24.69it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  6.62it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.62it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.62it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.61it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.61it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.61it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.28it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.40it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.47it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.51it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.02it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.01it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.92it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.95it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.98it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.99it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.93it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.96it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.97it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.95it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:03,  3.00it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  2.99it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.98it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.89it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.92it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.94it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.95it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.89it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.92it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.93it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 18.16it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 18.19it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 18.25it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 16.79it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 17.44it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.75it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.71it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.69it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.69it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.70it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.51it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.57it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.60it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.63it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.64it/s]\u001b[A\n",
      "Evaluating using naive strategy: 1it [00:13, 13.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.653978, time: 0.1s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.213133, time: 0.1s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 23.96it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 28.39it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  6.64it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.63it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.62it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.62it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.61it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.63it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.29it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.39it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.45it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.51it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.01it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.01it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.91it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.95it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.97it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.98it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.93it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.95it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.97it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.97it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:03,  2.79it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  2.89it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.93it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.95it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.88it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.91it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.93it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.88it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.91it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.91it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 18.13it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 18.18it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 18.22it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 18.20it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 17.46it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.63it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.66it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.67it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.67it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.67it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.50it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.56it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.59it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.62it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.62it/s]\u001b[A\n",
      "Evaluating using naive strategy: 2it [00:26, 13.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.755487, time: 0.3s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.274268, time: 0.4s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 13.86it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 13.78it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 13.75it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 13.75it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.75it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  6.65it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.14it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.26it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.42it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.49it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.54it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.57it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.59it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.59it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.52it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:03,  2.81it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  2.91it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.95it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.90it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.92it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.95it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.97it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.91it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.94it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.94it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:03,  2.97it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  2.86it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.91it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.93it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.94it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.88it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.91it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.93it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.94it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.90it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 18.38it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 18.28it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 18.21it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 18.18it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.18it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.67it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.67it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.44it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.53it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.58it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.61it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.63it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.65it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.50it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.57it/s]\u001b[A\n",
      "Evaluating using naive strategy: 3it [00:41, 14.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.928987, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.268703, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 24.54it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 24.39it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 20.35it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  6.67it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.63it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.61it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.61it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.62it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.61it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.62it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.29it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.39it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.51it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.02it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.02it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.92it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.96it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.98it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.99it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.92it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.95it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.96it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.97it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:03,  2.80it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  2.91it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.94it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.95it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.88it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.91it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.93it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.95it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.89it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.92it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 18.24it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 18.18it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 18.18it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 18.19it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.16it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  4.14it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.45it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.56it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.60it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.63it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.65it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.46it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.54it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.58it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.56it/s]\u001b[A\n",
      "Evaluating using naive strategy: 4it [00:55, 13.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.633695, time: 0.1s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.381846, time: 0.1s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00, 46.42it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 46.16it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  6.67it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.66it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.67it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.28it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.42it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.50it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.55it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.57it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.59it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.55it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:03,  2.84it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  2.96it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.98it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  3.00it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.93it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.96it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.98it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.00it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.85it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.94it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:03,  2.99it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  2.99it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.90it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.93it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.95it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.91it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.92it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.94it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.95it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.92it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 18.33it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 18.31it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 18.29it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 18.29it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.25it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.71it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.70it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.71it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.48it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.56it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.60it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.63it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.65it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.66it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.59it/s]\u001b[A\n",
      "Evaluating using naive strategy: 5it [01:07, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong PR-AUC: 0.8636049038205936, BWT: 0.07893067433862168, FWT: 0.8398777648968359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_naive = evaluation_protocol(T, E, Y, RCA(epochs=10), strategy=\"naive\")\n",
    "print(f\"Lifelong PR-AUC: {lifelong_roc_auc(R_naive)}, BWT: {BWT(R_naive)}, FWT: {FWT(R_naive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7206648-d043-47f2-b7a8-629528b60176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.133825, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.283720, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 26.46it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 26.48it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 26.40it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  6.66it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.51it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.21it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.38it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.48it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.53it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.56it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.59it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.60it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.53it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:03,  2.81it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  2.93it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.98it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  3.00it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.93it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.96it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.98it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.93it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.93it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.95it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:03,  3.00it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  2.88it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.92it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.95it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.96it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.90it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.93it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.95it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.96it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.92it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 18.34it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 18.28it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 18.28it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 18.29it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.24it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.70it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.69it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.48it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.56it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.60it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.63it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.64it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.66it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.52it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.59it/s]\u001b[A\n",
      "Evaluating using replay strategy: 1it [00:13, 13.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.771072, time: 0.3s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.281382, time: 0.3s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 14.47it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 13.62it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 13.80it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 14.03it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.03it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  6.64it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.61it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.62it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.61it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.63it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.45it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.44it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.50it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.53it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.55it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.00it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  2.94it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.98it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.99it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.00it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.97it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.98it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.99it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  3.00it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.98it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:03,  3.00it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  2.98it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.97it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.93it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.95it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.95it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.96it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.93it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.94it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.95it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 18.14it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 18.19it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 18.17it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 17.21it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 17.66it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.70it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.69it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.68it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.68it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.68it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.60it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.62it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.64it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.66it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.66it/s]\u001b[A\n",
      "Evaluating using replay strategy: 2it [00:28, 14.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.777492, time: 0.7s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.337077, time: 0.6s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.11it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.67it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.86it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.94it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.99it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.01it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  7.01it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  7.01it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  7.04it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.99it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  6.02it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.38it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.49it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.55it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.59it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.59it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.61it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.61it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.64it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.51it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:03,  2.92it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  2.99it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.02it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.94it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.97it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.98it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  3.00it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.94it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.97it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.88it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:03,  2.97it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  2.88it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.92it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.94it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.96it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.88it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.91it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.93it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.88it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.91it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 18.24it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 18.23it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 18.31it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 18.26it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.24it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.65it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.38it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.53it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.59it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.62it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.65it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.66it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.50it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.57it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.58it/s]\u001b[A\n",
      "Evaluating using replay strategy: 3it [00:47, 16.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.835143, time: 0.5s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.337040, time: 0.5s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:00,  9.05it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00,  8.97it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  8.95it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  8.98it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  8.97it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  8.35it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  8.51it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00,  8.64it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  8.73it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.75it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  6.64it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.63it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.61it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.61it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.61it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.28it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.39it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.45it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.50it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.51it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.00it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  2.88it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.93it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.96it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.97it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.92it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.94it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.96it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.97it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.94it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:03,  2.95it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  2.96it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.96it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.88it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.91it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.93it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.87it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.90it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.92it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.92it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 18.31it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 18.22it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 16.58it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 17.24it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 17.49it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.66it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.65it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.65it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.66it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.49it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.55it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.59it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.62it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.62it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.61it/s]\u001b[A\n",
      "Evaluating using replay strategy: 4it [01:05, 17.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.008612, time: 0.5s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.444617, time: 0.4s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 10.82it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 10.75it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 10.74it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 10.75it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 10.75it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  5.68it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.19it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.36it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.45it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.49it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.50it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.53it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.53it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.32it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.36it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:03,  3.00it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  2.99it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.99it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.91it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.94it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.96it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.97it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.92it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.94it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.95it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:03,  2.80it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  2.87it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.91it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.93it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.87it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  2.90it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:01,  2.92it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  2.93it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.88it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.90it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 18.07it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 18.07it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 18.04it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 18.06it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.05it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  4.43it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.44it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.54it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.58it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.61it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.63it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.51it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.50it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.55it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.55it/s]\u001b[A\n",
      "Evaluating using replay strategy: 5it [01:21, 16.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong PR-AUC: 0.8478671497999173, BWT: 0.05518521273001675, FWT: 0.8111760793826907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_replay = evaluation_protocol(T, E, Y, RCA(epochs=10), strategy=\"replay\", replay_buffer_size=5000)\n",
    "print(f\"Lifelong PR-AUC: {lifelong_roc_auc(R_replay)}, BWT: {BWT(R_replay)}, FWT: {FWT(R_replay)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d01ba4-0b27-4be0-9e4d-5550bc5fed96",
   "metadata": {},
   "source": [
    "# RDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbff48e6-6200-42e9-9075-0f3d6ee92df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import RDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2e6671a-f35e-4e0a-a210-dfe19c04ca87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000016, time: 0.2s\n",
      "epoch 10, training loss: 0.000018, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 1073.71it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1075.81it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 108/370 [00:00<00:00, 1075.25it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 216/370 [00:00<00:00, 1074.60it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1071.99it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 108/375 [00:00<00:00, 1077.64it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 216/375 [00:00<00:00, 1077.34it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1074.24it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1079.69it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  46%|████▌     | 109/238 [00:00<00:00, 1081.11it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1074.63it/s]\u001b[A\n",
      "Evaluating using hierarchical strategy: 1it [00:02,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.2009141688186157\n",
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000027, time: 0.2s\n",
      "epoch 10, training loss: 0.000017, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 1066.02it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1067.12it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 107/370 [00:00<00:00, 1067.53it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 214/370 [00:00<00:00, 1066.90it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1062.25it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 108/375 [00:00<00:00, 1070.81it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 216/375 [00:00<00:00, 1068.29it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1064.50it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1064.01it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  45%|████▌     | 108/238 [00:00<00:00, 1072.63it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1062.78it/s]\u001b[A\n",
      "Evaluating using hierarchical strategy: 2it [00:05,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.6825707131791178\n",
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000015, time: 0.3s\n",
      "epoch 10, training loss: 0.000023, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 1058.27it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1061.64it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 107/370 [00:00<00:00, 1061.60it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 214/370 [00:00<00:00, 1063.96it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1062.34it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 107/375 [00:00<00:00, 1062.97it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 214/375 [00:00<00:00, 1064.11it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1064.83it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1062.69it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  45%|████▍     | 107/238 [00:00<00:00, 1068.91it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1065.34it/s]\u001b[A\n",
      "Evaluating using hierarchical strategy: 3it [00:08,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5369153546908596\n",
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000024, time: 0.2s\n",
      "epoch 10, training loss: 0.000026, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 1071.99it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1054.19it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 107/370 [00:00<00:00, 1065.35it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 214/370 [00:00<00:00, 1067.47it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1065.55it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 107/375 [00:00<00:00, 1067.19it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 214/375 [00:00<00:00, 1068.09it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1067.72it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1052.96it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  45%|████▌     | 108/238 [00:00<00:00, 1072.24it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1066.02it/s]\u001b[A\n",
      "Evaluating using hierarchical strategy: 4it [00:11,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5778725606766417\n",
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000023, time: 0.4s\n",
      "epoch 10, training loss: 0.000027, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 43/43 [00:00<00:00, 1069.51it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1066.43it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 106/370 [00:00<00:00, 1059.73it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 214/370 [00:00<00:00, 1066.95it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1065.52it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 107/375 [00:00<00:00, 1067.01it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 214/375 [00:00<00:00, 1067.24it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1065.52it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1055.61it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  45%|████▍     | 107/238 [00:00<00:00, 1068.94it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1064.09it/s]\u001b[A\n",
      "Evaluating using hierarchical strategy: 5it [00:14,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.20849982652606378, BWT: 0.04336387647658, FWT: 0.28669754677625797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_hm = evaluation_protocol(T, E, Y, RDP(epochs=10), strategy=\"hierarchical\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_hm)}, BWT: {BWT(R_hm)}, FWT: {FWT(R_hm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f74a9f1-07b2-451a-a98b-19f725e1deb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using SSF strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000017, time: 0.5s\n",
      "epoch 10, training loss: 0.000017, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 1133.13it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1115.31it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  31%|███       | 114/370 [00:00<00:00, 1132.22it/s]\u001b[A\n",
      "testing:  62%|██████▏   | 228/370 [00:00<00:00, 1124.40it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1119.47it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|███       | 113/375 [00:00<00:00, 1120.07it/s]\u001b[A\n",
      "testing:  60%|██████    | 226/375 [00:00<00:00, 1121.82it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1119.63it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1111.58it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  47%|████▋     | 113/238 [00:00<00:00, 1123.36it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1117.06it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 323.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000026, time: 0.3s\n",
      "epoch 10, training loss: 0.000018, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 1124.95it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1115.64it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  31%|███       | 113/370 [00:00<00:00, 1122.06it/s]\u001b[A\n",
      "testing:  61%|██████    | 226/370 [00:00<00:00, 1121.92it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1119.64it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|██▉       | 112/375 [00:00<00:00, 1119.33it/s]\u001b[A\n",
      "testing:  60%|██████    | 225/375 [00:00<00:00, 1121.42it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1120.76it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1111.33it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  47%|████▋     | 113/238 [00:00<00:00, 1125.01it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1121.87it/s]\u001b[A\n",
      "Optimizing Sample Selection:   3%|▎         | 3/100 [00:00<00:00, 263.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000022, time: 0.4s\n",
      "epoch 10, training loss: 0.000023, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 43/43 [00:00<00:00, 993.51it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1012.41it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  28%|██▊       | 104/370 [00:00<00:00, 1030.88it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 208/370 [00:00<00:00, 1013.37it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 998.95it/s] \u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  26%|██▌       | 98/375 [00:00<00:00, 979.49it/s]\u001b[A\n",
      "testing:  53%|█████▎    | 197/375 [00:00<00:00, 981.62it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 984.11it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 965.16it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  42%|████▏     | 100/238 [00:00<00:00, 997.74it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1005.48it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 204.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000018, time: 0.5s\n",
      "epoch 10, training loss: 0.000024, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 43/43 [00:00<00:00, 1128.31it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1124.53it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  31%|███       | 113/370 [00:00<00:00, 1123.56it/s]\u001b[A\n",
      "testing:  61%|██████▏   | 227/370 [00:00<00:00, 1130.03it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1126.28it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|███       | 113/375 [00:00<00:00, 1121.29it/s]\u001b[A\n",
      "testing:  60%|██████    | 226/375 [00:00<00:00, 1124.34it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1122.44it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1119.02it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  47%|████▋     | 113/238 [00:00<00:00, 1128.08it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1125.11it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 315.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000022, time: 0.5s\n",
      "epoch 10, training loss: 0.000026, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 44/44 [00:00<00:00, 1134.36it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1123.64it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  31%|███       | 113/370 [00:00<00:00, 1121.11it/s]\u001b[A\n",
      "testing:  61%|██████    | 226/370 [00:00<00:00, 1122.00it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1119.28it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|██▉       | 112/375 [00:00<00:00, 1117.21it/s]\u001b[A\n",
      "testing:  60%|██████    | 226/375 [00:00<00:00, 1124.46it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1120.79it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1117.02it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  48%|████▊     | 114/238 [00:00<00:00, 1133.37it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1122.85it/s]\u001b[A\n",
      "Evaluating using SSF strategy: 5it [00:30,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.22137051134872962, BWT: 0.04914431520735178, FWT: 0.31390066909618175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_ssf = evaluation_protocol(T, E, Y, RDP(epochs=10), strategy=\"SSF\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_ssf)}, BWT: {BWT(R_ssf)}, FWT: {FWT(R_ssf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97bc0bc5-9043-401a-9c18-1fc8beb1f9c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000016, time: 0.5s\n",
      "epoch 10, training loss: 0.000018, time: 0.7s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 1031.95it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1040.76it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  28%|██▊       | 105/370 [00:00<00:00, 1041.84it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 210/370 [00:00<00:00, 1042.95it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1042.74it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  28%|██▊       | 105/375 [00:00<00:00, 1046.02it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 210/375 [00:00<00:00, 1047.81it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 980.16it/s] \u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1042.81it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  45%|████▍     | 106/238 [00:00<00:00, 1050.45it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1048.07it/s]\u001b[A\n",
      "Evaluating using naive strategy: 1it [00:07,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000014, time: 0.4s\n",
      "epoch 10, training loss: 0.000022, time: 0.4s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 36/36 [00:00<00:00, 1042.37it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1046.60it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 106/370 [00:00<00:00, 1052.31it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 212/370 [00:00<00:00, 1047.20it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 982.69it/s] \u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  28%|██▊       | 106/375 [00:00<00:00, 1056.10it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 212/375 [00:00<00:00, 1052.17it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1052.57it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1043.56it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  45%|████▍     | 106/238 [00:00<00:00, 1052.84it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1050.26it/s]\u001b[A\n",
      "Evaluating using naive strategy: 2it [00:13,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000009, time: 1.1s\n",
      "epoch 10, training loss: 0.000030, time: 1.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 81/81 [00:00<00:00, 1055.49it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1047.51it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  28%|██▊       | 105/370 [00:00<00:00, 1044.28it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 210/370 [00:00<00:00, 915.76it/s] \u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 978.57it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  28%|██▊       | 106/375 [00:00<00:00, 1051.40it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 212/375 [00:00<00:00, 1046.45it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1046.10it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1038.45it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  45%|████▍     | 106/238 [00:00<00:00, 1052.97it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1047.06it/s]\u001b[A\n",
      "Evaluating using naive strategy: 3it [00:25,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000022, time: 0.7s\n",
      "epoch 10, training loss: 0.000026, time: 0.7s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 46/46 [00:00<00:00, 1054.02it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1045.75it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 106/370 [00:00<00:00, 1058.24it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 212/370 [00:00<00:00, 1053.21it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1054.71it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  28%|██▊       | 106/375 [00:00<00:00, 1054.48it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 212/375 [00:00<00:00, 1053.56it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1005.56it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1059.62it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  45%|████▍     | 107/238 [00:00<00:00, 1068.46it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1060.95it/s]\u001b[A\n",
      "Evaluating using naive strategy: 4it [00:33,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000041, time: 0.3s\n",
      "epoch 10, training loss: 0.000014, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 24/24 [00:00<00:00, 1001.82it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1045.97it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  28%|██▊       | 105/370 [00:00<00:00, 1045.34it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 210/370 [00:00<00:00, 1043.26it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 981.05it/s] \u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  28%|██▊       | 106/375 [00:00<00:00, 1057.92it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 212/375 [00:00<00:00, 1058.01it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1055.73it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1037.44it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  45%|████▍     | 106/238 [00:00<00:00, 1050.43it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1047.30it/s]\u001b[A\n",
      "Evaluating using naive strategy: 5it [00:38,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong PR-AUC: 0.8545668502575858, BWT: 0.07726954159554941, FWT: 0.8306566779875293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_naive = evaluation_protocol(T, E, Y, RDP(epochs=10), strategy=\"naive\")\n",
    "print(f\"Lifelong PR-AUC: {lifelong_roc_auc(R_naive)}, BWT: {BWT(R_naive)}, FWT: {FWT(R_naive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "076a1086-24d9-4cb9-b6cb-0395f08dd5b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000016, time: 0.6s\n",
      "epoch 10, training loss: 0.000018, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 842.16it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 935.15it/s][A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  23%|██▎       | 84/370 [00:00<00:00, 832.55it/s]\u001b[A\n",
      "testing:  45%|████▌     | 168/370 [00:00<00:00, 621.58it/s]\u001b[A\n",
      "testing:  70%|███████   | 259/370 [00:00<00:00, 730.14it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 792.09it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  28%|██▊       | 105/375 [00:00<00:00, 1042.54it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 210/375 [00:00<00:00, 1040.72it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1041.01it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1044.42it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  44%|████▍     | 105/238 [00:00<00:00, 1049.90it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1041.39it/s]\u001b[A\n",
      "Evaluating using replay strategy: 1it [00:07,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000015, time: 1.1s\n",
      "epoch 10, training loss: 0.000026, time: 1.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 78/78 [00:00<00:00, 1050.23it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1046.30it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 106/370 [00:00<00:00, 1055.61it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 212/370 [00:00<00:00, 1053.27it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 977.64it/s] \u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  24%|██▎       | 89/375 [00:00<00:00, 887.25it/s]\u001b[A\n",
      "testing:  52%|█████▏    | 195/375 [00:00<00:00, 986.78it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1007.97it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1051.46it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  45%|████▍     | 106/238 [00:00<00:00, 1053.55it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1047.59it/s]\u001b[A\n",
      "Evaluating using replay strategy: 2it [00:19, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000015, time: 2.2s\n",
      "epoch 10, training loss: 0.000045, time: 2.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing:   0%|          | 0/158 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 158/158 [00:00<00:00, 1047.11it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1047.51it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 106/370 [00:00<00:00, 1050.36it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 212/370 [00:00<00:00, 1052.86it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1052.08it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  28%|██▊       | 106/375 [00:00<00:00, 1055.74it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 212/375 [00:00<00:00, 1053.15it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 900.35it/s] \u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 686.94it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  45%|████▍     | 106/238 [00:00<00:00, 1057.28it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1049.34it/s]\u001b[A\n",
      "Evaluating using replay strategy: 3it [00:43, 16.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000015, time: 1.7s\n",
      "epoch 10, training loss: 0.000042, time: 1.9s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 124/124 [00:00<00:00, 595.28it/s][A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1061.96it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 106/370 [00:00<00:00, 1058.65it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 212/370 [00:00<00:00, 1054.74it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1050.98it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 107/375 [00:00<00:00, 1060.41it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 214/375 [00:00<00:00, 1059.28it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1057.11it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1061.32it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  45%|████▍     | 107/238 [00:00<00:00, 1066.37it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 940.23it/s] \u001b[A\n",
      "Evaluating using replay strategy: 4it [01:02, 17.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000017, time: 1.4s\n",
      "epoch 10, training loss: 0.000045, time: 1.4s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 103/103 [00:00<00:00, 1059.24it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1045.01it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  28%|██▊       | 105/370 [00:00<00:00, 1045.75it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 211/370 [00:00<00:00, 1048.99it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1047.91it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  28%|██▊       | 106/375 [00:00<00:00, 1051.77it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 212/375 [00:00<00:00, 1053.25it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1052.60it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/61 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 459.63it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  43%|████▎     | 103/238 [00:00<00:00, 1022.17it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1041.13it/s]\u001b[A\n",
      "Evaluating using replay strategy: 5it [01:17, 15.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong PR-AUC: 0.854602546628472, BWT: 0.04632019033317643, FWT: 0.8339123618817329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_replay = evaluation_protocol(T, E, Y, RDP(epochs=10), strategy=\"replay\", replay_buffer_size=5000)\n",
    "print(f\"Lifelong PR-AUC: {lifelong_roc_auc(R_replay)}, BWT: {BWT(R_replay)}, FWT: {FWT(R_replay)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b89e81-c7b8-48de-91c0-790a5ff3876b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
