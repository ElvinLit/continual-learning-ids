{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c094fa-8da6-48b6-b19f-1627adfbfcba",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e802f5-4d04-43b3-ba66-19400b29a966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.base import clone\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import wasserstein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "765e6a2d-453f-4b10-8aa3-c4e8f516e2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_685/980380746.py\", line 1, in <module>\n",
      "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "/tmp/ipykernel_685/980380746.py:1: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:77.)\n",
      "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a1d38bf-fc37-42ff-a9a8-c5e35b2978b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('data/x_train.npy')\n",
    "y_train = np.load('data/y_train.npy')\n",
    "\n",
    "X_test = np.load('data/x_test.npy')\n",
    "y_test = np.load('data/y_test.npy')\n",
    "\n",
    "X = np.concatenate([X_train, X_test], axis=0)\n",
    "y = np.concatenate([y_train, y_test], axis=0)\n",
    "\n",
    "y = np.where(y == 6, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878d0ff6-198a-4f43-bf2c-9c795817ad9e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fefa4ff-04b2-4dda-8b66-08c618fb7be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_phi(normal_data, c):\n",
    "    \"\"\"\n",
    "    Concept creation function for normal data.\n",
    "    Uses k-Means clustering to partition normal data into c clusters.\n",
    "    \n",
    "    Args:\n",
    "        normal_data (numpy array): The normal data points.\n",
    "        c (int): Number of desired normal concepts.\n",
    "    \n",
    "    Returns:\n",
    "        list of numpy arrays: List of normal clusters.\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=c, random_state=42)\n",
    "    labels = kmeans.fit_predict(normal_data)\n",
    "    \n",
    "    normal_concepts = [normal_data[labels == i] for i in range(c)]\n",
    "    print(\"Finished creating normal concepts\")\n",
    "    \n",
    "    return normal_concepts\n",
    "\n",
    "\n",
    "def create_gamma(anomaly_data, c):\n",
    "    \"\"\"\n",
    "    Concept creation function for anomaly data.\n",
    "    Uses k-Means clustering to partition anomaly data into c clusters.\n",
    "    \n",
    "    Args:\n",
    "        anomaly_data (numpy array): The anomaly data points.\n",
    "        c (int): Number of desired anomaly concepts.\n",
    "    \n",
    "    Returns:\n",
    "        list of numpy arrays: List of anomaly clusters.\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=c, random_state=42)\n",
    "    labels = kmeans.fit_predict(anomaly_data)\n",
    "    \n",
    "    anomaly_concepts = [anomaly_data[labels == i] for i in range(c)]\n",
    "    print(\"Finished creating anomaly concepts\")\n",
    "    \n",
    "    return anomaly_concepts\n",
    "    \n",
    "def match_lambda(anomaly_concepts, normal_concepts):\n",
    "    \"\"\"\n",
    "    Matches each normal concept with the closest anomaly concept.\n",
    "    Uses Euclidean distance to determine the best match.\n",
    "    \n",
    "    Args:\n",
    "        anomaly_concepts (list of numpy arrays): List of anomaly clusters.\n",
    "        normal_concepts (list of numpy arrays): List of normal clusters.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Pairs of (normal_concept, matched_anomaly_concept)\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    remaining_anomalies = anomaly_concepts.copy()\n",
    "\n",
    "    for normal_concept in normal_concepts:\n",
    "        normal_centroid = np.mean(normal_concept, axis=0)\n",
    "        anomaly_centroids = [np.mean(ac, axis=0) for ac in remaining_anomalies]\n",
    "\n",
    "        distances = cdist([normal_centroid], anomaly_centroids, metric='euclidean')[0]\n",
    "        closest_idx = np.argmin(distances)\n",
    "\n",
    "        pairs.append((normal_concept, remaining_anomalies[closest_idx]))\n",
    "        remaining_anomalies.pop(closest_idx)\n",
    "\n",
    "    print(\"Finished matching concept pairs\")\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "def lifelong_roc_auc(R):\n",
    "    \"\"\"\n",
    "    Computes the Lifelong ROC-AUC metric.\n",
    "    \n",
    "    Args:\n",
    "        R (numpy array): NxN matrix of ROC-AUC scores, where R[i, j] is the model's \n",
    "                         performance on concept j after learning concept i.\n",
    "    \n",
    "    Returns:\n",
    "        float: Lifelong ROC-AUC score.\n",
    "    \"\"\"\n",
    "    N = R.shape[0]\n",
    "    lower_triangular_sum = np.sum(np.tril(R))\n",
    "    normalization_factor = (N * (N + 1)) / 2\n",
    "\n",
    "    return lower_triangular_sum / normalization_factor\n",
    "\n",
    "def BWT(R):\n",
    "    \"\"\"\n",
    "    Computes the Backward Transfer (BWT) score.\n",
    "    \n",
    "    Args:\n",
    "        R (numpy array): NxN results matrix.\n",
    "    \n",
    "    Returns:\n",
    "        float: BWT score.\n",
    "    \"\"\"\n",
    "    N = R.shape[0]\n",
    "    backward_transfer = 0\n",
    "    count = 0\n",
    "\n",
    "    for i in range(1, N):\n",
    "        for j in range(i):\n",
    "            backward_transfer += (R[i, j] - R[j, j])\n",
    "            count += 1\n",
    "\n",
    "    return backward_transfer / count if count > 0 else 0\n",
    "\n",
    "def FWT(R):\n",
    "    \"\"\"\n",
    "    Computes the Forward Transfer (FWT) score.\n",
    "    \n",
    "    Args:\n",
    "        R (numpy array): NxN results matrix.\n",
    "    \n",
    "    Returns:\n",
    "        float: FWT score.\n",
    "    \"\"\"\n",
    "    N = R.shape[0]\n",
    "    forward_transfer = 0\n",
    "    count = 0\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(i + 1, N): \n",
    "            forward_transfer += R[i, j]\n",
    "            count += 1\n",
    "\n",
    "    return forward_transfer / count if count > 0 else 0 \n",
    "\n",
    "def kolmogorov_smirnov_test(X_old, X_new, alpha=0.05):\n",
    "    \"\"\"Detect concept drift using KS-test on feature distributions.\"\"\"\n",
    "    \n",
    "    p_values = [ks_2samp(X_old[:, i], X_new[:, i]).pvalue for i in range(X_old.shape[1])]\n",
    "    return np.any(np.array(p_values) < alpha)\n",
    "\n",
    "def histogram_binning(X, bins=25):\n",
    "    \"\"\"Convert sample distributions into histograms.\"\"\"\n",
    "    \n",
    "    return np.array([np.histogram(X[:, i], bins=bins, density=True)[0] for i in range(X.shape[1])]).T\n",
    "\n",
    "def kl_divergence(P, Q):\n",
    "    \"\"\"Compute KL divergence between two distributions.\"\"\"\n",
    "    \n",
    "    P, Q = np.clip(P, 1e-10, None), np.clip(Q, 1e-10, None)  # Avoid log(0)\n",
    "    return np.sum(P * np.log(P / Q))\n",
    "\n",
    "def strategic_sample_selection(X_old, X_new, top_k=100, learning_rate=0.01, num_iterations=100):\n",
    "    \"\"\"\n",
    "    Selects representative new samples by minimizing KL divergence.\n",
    "    \n",
    "    Args:\n",
    "        X_old (numpy.ndarray): Old memory buffer samples.\n",
    "        X_new (numpy.ndarray): Incoming new samples.\n",
    "        top_k (int): Number of samples to retain.\n",
    "        learning_rate (float): Step size for optimization.\n",
    "        num_iterations (int): Number of optimization steps.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Selected representative new samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    H_old, H_new = histogram_binning(X_old), histogram_binning(X_new)\n",
    "    m_n = np.random.rand(H_new.shape[0])  \n",
    "\n",
    "    def loss_function(m_n):\n",
    "        \"\"\"Computes KL divergence loss for selected samples.\"\"\"\n",
    "        weighted_H_new = H_new * m_n[:, np.newaxis]  \n",
    "        combined_H = (H_old + weighted_H_new) / 2 \n",
    "        return kl_divergence(H_new, combined_H) \n",
    "\n",
    "    progress_bar = tqdm(total=num_iterations, desc=\"Optimizing Sample Selection\", position=0, leave=True)\n",
    "\n",
    "    def callback(xk):\n",
    "        progress_bar.update(1)  \n",
    "\n",
    "    result = minimize(loss_function, m_n, method=\"L-BFGS-B\", bounds=[(0, 1)] * len(m_n), \n",
    "                      options={\"maxiter\": num_iterations, \"ftol\": 1e-10}, callback=callback)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    selected_indices = np.argsort(result.x)[-top_k:]\n",
    "\n",
    "    return X_new[selected_indices] \n",
    "\n",
    "\n",
    "def update_memory_buffer(X_old, X_new_selected, memory_size=3000):\n",
    "    \"\"\"Updates memory buffer using strategic forgetting.\"\"\"\n",
    "    updated_buffer = np.vstack((X_old, X_new_selected))  \n",
    "\n",
    "    if updated_buffer.shape[0] > memory_size:\n",
    "        updated_buffer = updated_buffer[-memory_size:]\n",
    "\n",
    "    return updated_buffer\n",
    "\n",
    "class HierarchicalMemory:\n",
    "    def __init__(self, memory_limit=5000, pyramid_factor=2, centroids_per_concept=10):\n",
    "        self.memory_limit = memory_limit\n",
    "        self.pyramid_factor = pyramid_factor\n",
    "        self.centroids_per_concept = centroids_per_concept\n",
    "        self.memory = {}  # level: [concept1, concept2, ...]\n",
    "\n",
    "    def add_concept(self, data, level=1):\n",
    "        if level not in self.memory:\n",
    "            self.memory[level] = []\n",
    "        self.memory[level].append(np.array(data))\n",
    "        self._summarize_memory()\n",
    "\n",
    "    def _pyramidal_allocation(self):\n",
    "        levels = sorted(self.memory.keys())\n",
    "        weights = np.array([1 / (self.pyramid_factor ** (lvl - 1)) for lvl in levels])\n",
    "        total_weight = weights.sum()\n",
    "        allocations = (weights / total_weight) * self.memory_limit\n",
    "        return {lvl: int(alloc) for lvl, alloc in zip(levels, allocations)}\n",
    "\n",
    "    def _summarize_concept(self, concept, n_samples):\n",
    "        if len(concept) <= n_samples:\n",
    "            return concept\n",
    "        kmeans = KMeans(n_clusters=min(self.centroids_per_concept, len(concept)), random_state=42).fit(concept)\n",
    "        centroids = kmeans.cluster_centers_\n",
    "        distances = np.linalg.norm(concept[:, None] - centroids, axis=2)\n",
    "        closest_indices = np.argmin(distances, axis=0)\n",
    "        summarized = concept[closest_indices]\n",
    "        return summarized\n",
    "\n",
    "    def _summarize_memory(self):\n",
    "        allocations = self._pyramidal_allocation()\n",
    "        for level, concepts in self.memory.items():\n",
    "            summarized_level = []\n",
    "            alloc_per_concept = max(1, allocations[level] // len(concepts))\n",
    "            for concept in concepts:\n",
    "                summarized = self._summarize_concept(concept, alloc_per_concept)\n",
    "                summarized_level.append(summarized)\n",
    "            self.memory[level] = summarized_level\n",
    "\n",
    "    def get_all_memory(self):\n",
    "        all_data = []\n",
    "        for level_concepts in self.memory.values():\n",
    "            for concept in level_concepts:\n",
    "                all_data.append(concept)\n",
    "        return np.vstack(all_data) if all_data else np.empty((0,))\n",
    "\n",
    "def scenario_design(normal_data, anomaly_data, c):\n",
    "    \"\"\"\n",
    "    Implements Algorithm 1 to create a lifelong learning scenario.\n",
    "    \n",
    "    Args:\n",
    "        normal_data (numpy array): The normal data points.\n",
    "        anomaly_data (numpy array): The anomaly data points.\n",
    "        c (int): Number of desired concepts.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: List of (normal_concept, anomaly_concept) pairs forming the scenario.\n",
    "    \"\"\"\n",
    "    normal_concepts = create_phi(normal_data, c)\n",
    "    anomaly_concepts = create_gamma(anomaly_data, c)\n",
    "    \n",
    "    scenario = match_lambda(anomaly_concepts, normal_concepts)\n",
    "    \n",
    "    return scenario\n",
    "\n",
    "def evaluation_protocol(T, E, Y, model, strategy=\"naive\", replay_buffer_size=5000, memory_size=5000, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Implements Algorithm 2: Lifelong Learning Evaluation Protocol with multiple strategies.\n",
    "    \n",
    "    Args:\n",
    "        T (list): Sequence of N training sets.\n",
    "        E (list): Sequence of N testing sets.\n",
    "        Y (list): Sequence of true labels for test sets.\n",
    "        model (sklearn.base.BaseEstimator): A scikit-learn-like model instance that supports `fit` and `decision_function`.\n",
    "        strategy (str): Strategy for training.\n",
    "        replay_buffer_size (int): Maximum size of replay buffer if applicable\n",
    "        memory_size (int): Maximum memory size if applicable\n",
    "        alpha (float): KS-test threshold for drift detection.\n",
    "\n",
    "    Returns:\n",
    "        numpy array: NxN results matrix R where R[i, j] is ROC-AUC of model on E[j] after learning T[i].\n",
    "    \"\"\"\n",
    "    N = len(T)\n",
    "    R = np.zeros((N, N))  \n",
    "\n",
    "    if strategy in [\"cumulative\"]:\n",
    "        cumulative_data = []\n",
    "    \n",
    "    if strategy in [\"replay\"]:\n",
    "        replay_buffer = []\n",
    "\n",
    "    if strategy == \"SSF\":\n",
    "        memory_buffer = None \n",
    "\n",
    "    if strategy == \"hierarchical\":\n",
    "        h_memory = HierarchicalMemory(memory_limit=memory_size, pyramid_factor=2, centroids_per_concept=10)\n",
    "\n",
    "    for i, Ti in tqdm(enumerate(T), desc=f\"Evaluating using {strategy} strategy\"):\n",
    "        current_model = deepcopy(model)\n",
    "\n",
    "        # -- NAIVE --\n",
    "        if strategy == \"naive\":\n",
    "            current_model.fit(Ti)\n",
    "\n",
    "        # -- CUMULATIVE --\n",
    "        elif strategy == \"cumulative\":\n",
    "            cumulative_data.extend(Ti.tolist())\n",
    "            current_model.fit(np.array(cumulative_data)) \n",
    "\n",
    "        # -- REPLAY -- \n",
    "        elif strategy == \"replay\":\n",
    "            if replay_buffer:\n",
    "                combined_data = np.vstack((np.array(replay_buffer), Ti))\n",
    "            else:\n",
    "                combined_data = Ti\n",
    "\n",
    "            current_model.fit(combined_data)\n",
    "            replay_buffer.extend(Ti.tolist())\n",
    "\n",
    "            if len(replay_buffer) > replay_buffer_size:\n",
    "                replay_buffer = replay_buffer[-replay_buffer_size:]\n",
    "        \n",
    "        # -- SSF -- \n",
    "        elif strategy == \"SSF\":\n",
    "            if memory_buffer is None:\n",
    "                memory_buffer = Ti[:memory_size]  \n",
    "            else:\n",
    "                drift_detected = kolmogorov_smirnov_test(memory_buffer, Ti, alpha)\n",
    "                if drift_detected:\n",
    "                    X_new_selected = strategic_sample_selection(memory_buffer, Ti, top_k=1000)\n",
    "                    memory_buffer = update_memory_buffer(memory_buffer, X_new_selected, memory_size=memory_size)\n",
    "            memory_buffer = np.unique(memory_buffer, axis=0)\n",
    "            current_model.fit(memory_buffer)\n",
    "\n",
    "        # -- HIERARCHICAL --\n",
    "        elif strategy == \"hierarchical\":\n",
    "\n",
    "            memory_data = h_memory.get_all_memory()\n",
    "            if memory_data.size == 0:\n",
    "                drift_level = 1\n",
    "            else:\n",
    "                drift_distances = [\n",
    "                    wasserstein_distance(Ti[:, d], memory_data[:, d])\n",
    "                    for d in range(Ti.shape[1])\n",
    "                ]\n",
    "                drift_score = np.mean(drift_distances)\n",
    "                print(f\"drift: {drift_score}\")\n",
    "                \n",
    "                if drift_score < 0.05:\n",
    "                    drift_level = 1\n",
    "                elif drift_score < 0.1:\n",
    "                    drift_level = 2\n",
    "                elif drift_score < 0.2:\n",
    "                    drift_level = 3\n",
    "                else:\n",
    "                    drift_level = 4\n",
    "        \n",
    "            h_memory.add_concept(Ti, level=drift_level)\n",
    "            summarized_memory = h_memory.get_all_memory()\n",
    "            current_model.fit(summarized_memory)\n",
    "\n",
    "        # -- Evaluation --\n",
    "        for j, ((Ej_normal, Ej_anomaly), (y_normal, y_anomaly)) in enumerate(zip(E, Y)):\n",
    "            test_data = np.vstack((Ej_normal, Ej_anomaly))\n",
    "            test_labels = np.hstack((y_normal, y_anomaly))  \n",
    "        \n",
    "            scores = -current_model.decision_function(test_data)  \n",
    "            R[i, j] = roc_auc_score(test_labels, scores)\n",
    "\n",
    "    return R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf8d81d-8bba-4559-920b-86f9d642c0c2",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f3b00c-79f9-4d98-aa7c-0dd1cb98a783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating normal concepts\n",
      "Finished creating anomaly concepts\n",
      "Finished matching concept pairs\n"
     ]
    }
   ],
   "source": [
    "num_concepts = 5\n",
    "\n",
    "X_normal = X[y == 0]  \n",
    "X_anomaly = X[y == 1]\n",
    "\n",
    "normal_concepts = create_phi(X_normal, num_concepts)\n",
    "anomaly_concepts = create_gamma(X_anomaly, num_concepts)\n",
    "\n",
    "concept_pairs = match_lambda(anomaly_concepts, normal_concepts)\n",
    "\n",
    "T = []  \n",
    "E = [] \n",
    "Y = []\n",
    "\n",
    "for normal, anomaly in concept_pairs:\n",
    "\n",
    "    normal_train, normal_test = train_test_split(normal, test_size=0.3, random_state=42)\n",
    "    anomaly_train, anomaly_test = train_test_split(anomaly, test_size=0.3, random_state=42)  \n",
    "\n",
    "    T.append(normal_train)\n",
    "    E.append((normal_test, anomaly_test))\n",
    "\n",
    "    y_normal_test = np.zeros(len(normal_test))\n",
    "    y_anomaly_test = np.ones(len(anomaly_test))\n",
    "    \n",
    "    Y.append((y_normal_test, y_anomaly_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35516e86-3161-46cf-a3fe-2a7559327ca7",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a110d25-bd8e-452a-9aa9-f0ed1110ff78",
   "metadata": {},
   "source": [
    "## LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c9838f-ecee-415c-9b77-f4b5fecb2689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 1it [00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.2009141688186157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 2it [00:01,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.6825707131791178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 3it [00:01,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5369153546908596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 4it [00:02,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5778725606766417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 5it [00:03,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.6058086718178083, BWT: -0.05192413793713711, FWT: 0.8173483540003452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_hm = evaluation_protocol(T, E, Y, LocalOutlierFactor(n_neighbors=20, novelty=True), strategy=\"hierarchical\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_hm)}, BWT: {BWT(R_hm)}, FWT: {FWT(R_hm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8dc23cbb-9f1e-4922-b6d6-30e38b6877e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aluating using SSF strategy: 0it [00:00, ?it/s]\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 273.05it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 256.08it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 276.87it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 326.53it/s]\n",
      "\n",
      "Evaluating using SSF strategy: 5it [00:05,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.7544561432893502, BWT: -0.0039135441339650965, FWT: 0.45301001764958054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_ssf = evaluation_protocol(T, E, Y, LocalOutlierFactor(n_neighbors=20, novelty=True), strategy=\"SSF\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_ssf)}, BWT: {BWT(R_ssf)}, FWT: {FWT(R_ssf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2407e687-65f9-4fd0-91ab-aeec46194150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 5it [00:51, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.6207107852264637, BWT: -0.283093404759226, FWT: 0.377989401800772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_naive = evaluation_protocol(T, E, Y, LocalOutlierFactor(n_neighbors=20, novelty=True), strategy=\"naive\")\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_naive)}, BWT: {BWT(R_naive)}, FWT: {FWT(R_naive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f739cd8-a365-4473-93f7-afad06db7593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using cumulative strategy: 5it [02:10, 26.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.9238354062988797, BWT: -0.004499087364359666, FWT: 0.17379610432039533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_cumulative = evaluation_protocol(T, E, Y, LocalOutlierFactor(n_neighbors=20, novelty=True), strategy=\"cumulative\")\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_cumulative)}, BWT: {BWT(R_cumulative)}, FWT: {FWT(R_cumulative)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "986be1f1-4345-463c-9e0c-d96d6965c427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 5it [00:53, 10.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.7034898501276438, BWT: -0.19004147760711937, FWT: 0.24881712704471132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_replay = evaluation_protocol(T, E, Y, LocalOutlierFactor(n_neighbors=20, novelty=True), strategy=\"replay\", replay_buffer_size=5000)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_replay)}, BWT: {BWT(R_replay)}, FWT: {FWT(R_replay)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea398ac8-335e-4d07-86bf-3f1d38fcb214",
   "metadata": {},
   "source": [
    "## IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2376e23-30fd-487d-872e-2335183a4dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 1it [00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.2009141688186157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 2it [00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.6825707131791178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 3it [00:00,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5369153546908596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 4it [00:01,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5778725606766417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 5it [00:01,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.7977446218811072, BWT: 0.053902109492241966, FWT: 0.6446608787208653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_hm = evaluation_protocol(T, E, Y, IsolationForest(n_estimators=100), strategy=\"hierarchical\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_hm)}, BWT: {BWT(R_hm)}, FWT: {FWT(R_hm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f1f73a7-1ced-4b06-9d95-9ae0910d4276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aluating using SSF strategy: 0it [00:00, ?it/s]\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 281.14it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 253.28it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 237.31it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 244.61it/s]\n",
      "\n",
      "Evaluating using SSF strategy: 5it [00:05,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.6559285630296237, BWT: 0.06868127809581366, FWT: 0.804018261100736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_ssf = evaluation_protocol(T, E, Y,  IsolationForest(n_estimators=100), strategy=\"SSF\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_ssf)}, BWT: {BWT(R_ssf)}, FWT: {FWT(R_ssf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f202fe-3718-47e9-92e9-0c22128560ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 5it [00:04,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.6771475708237422, BWT: -0.22528601715677166, FWT: 0.6957773121657185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_naive = evaluation_protocol(T, E, Y, IsolationForest(n_estimators=100), strategy=\"naive\")\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_naive)}, BWT: {BWT(R_naive)}, FWT: {FWT(R_naive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ce69456-76b9-4ad5-98d0-99dad36d3f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using cumulative strategy: 5it [00:07,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.753897896406868, BWT: -0.0066406078135951676, FWT: 0.7719174809547474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_cumulative = evaluation_protocol(T, E, Y, IsolationForest(n_estimators=100), strategy=\"cumulative\")\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_cumulative)}, BWT: {BWT(R_cumulative)}, FWT: {FWT(R_cumulative)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11c4cd01-9013-4206-a359-b81bd9efc8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 5it [00:05,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.6977725521692333, BWT: -0.16392284276343677, FWT: 0.7159532915927771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_replay = evaluation_protocol(T, E, Y, IsolationForest(n_estimators=100), strategy=\"replay\", replay_buffer_size=5000)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_replay)}, BWT: {BWT(R_replay)}, FWT: {FWT(R_replay)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518a2e23-e8aa-4cb3-821e-7136e982cd8b",
   "metadata": {},
   "source": [
    "## SGDOCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e2fedc2-c496-457f-b96e-03be3be95ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 2it [00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.2009141688186157\n",
      "drift: 0.6825707131791178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 4it [00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5369153546908596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using hierarchical strategy: 5it [00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift: 0.5778725606766417\n",
      "Lifelong ROC-AUC: 0.835257953664189, BWT: -0.0019655490765778773, FWT: 0.9206040708906336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_hm = evaluation_protocol(T, E, Y, SGDOneClassSVM(), strategy=\"hierarchical\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_hm)}, BWT: {BWT(R_hm)}, FWT: {FWT(R_hm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af0bd83b-8946-4170-a140-ab931a8948af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aluating using SSF strategy: 0it [00:00, ?it/s]\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 288.13it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 307.55it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 306.85it/s]\n",
      "\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 271.76it/s]\n",
      "\n",
      "Evaluating using SSF strategy: 5it [00:02,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.790790866239933, BWT: -0.004091332504534584, FWT: 0.5467376505389003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_ssf = evaluation_protocol(T, E, Y,  SGDOneClassSVM(), strategy=\"SSF\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_ssf)}, BWT: {BWT(R_ssf)}, FWT: {FWT(R_ssf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dabcbd0-6f8b-4e08-b1f0-df8822d6fcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 5it [00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.6589862939199218, BWT: -0.2399821951513669, FWT: 0.5658554538516768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_naive = evaluation_protocol(T, E, Y, SGDOneClassSVM(), strategy=\"naive\")\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_naive)}, BWT: {BWT(R_naive)}, FWT: {FWT(R_naive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4ef0151-6f99-4f48-9025-c789ca69f474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using cumulative strategy: 5it [00:04,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.597799790906325, BWT: -0.215598947769658, FWT: 0.6579349113663381\n"
     ]
    }
   ],
   "source": [
    "R_cumulative = evaluation_protocol(T, E, Y, SGDOneClassSVM(), strategy=\"cumulative\")\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_cumulative)}, BWT: {BWT(R_cumulative)}, FWT: {FWT(R_cumulative)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9ae2708-dbfc-4dbd-ab56-9aedd7405b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 5it [00:01,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.653901107789708, BWT: -0.23987138665874969, FWT: 0.5783463917929488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_replay = evaluation_protocol(T, E, Y, SGDOneClassSVM(), strategy=\"replay\", replay_buffer_size=5000)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_replay)}, BWT: {BWT(R_replay)}, FWT: {FWT(R_replay)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63ed2c1-c826-4ea1-8f3f-85f6ac4eaa7f",
   "metadata": {},
   "source": [
    "# SLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767548bb-cfce-4f23-a11a-03a5e88d58af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import SLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc35698c-92f2-46fb-a58b-6951f3dc6538",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using SSF strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6  7  9 10 12 13 14 16 17 18 20 22 24 25 26 27 28 30 31\n",
      " 32 33 34 35 36 37 38 40 41 42 44 45 46 47 48 49 50 51 53 54 55 56 57 58\n",
      " 59 60]\n",
      "epoch  1, training loss: 0.713113, time: 1.2s\n",
      "epoch 10, training loss: 0.658922, time: 1.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 276.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 2  3  4  5  6  8 10 11 12 13 14 16 17 18 19 20 21 22 23 26 27 28 30 31\n",
      " 32 33 34 35 36 37 38 39 40 42 43 44 46 47 48 49 50 51 52 53 54 55 56 57\n",
      " 58 59]\n",
      "epoch  1, training loss: 0.689160, time: 0.2s\n",
      "epoch 10, training loss: 0.635717, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing Sample Selection:   2%|▏         | 2/100 [00:00<00:00, 184.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6  7  8 10 11 12 13 14 16 17 18 19 20 21 22 23 25 26 27\n",
      " 28 29 30 31 34 35 36 38 39 40 41 43 45 46 47 48 49 50 52 54 56 57 58 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.712030, time: 1.3s\n",
      "epoch 10, training loss: 0.662940, time: 1.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 303.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6  7  9 10 12 13 14 15 16 17 18 19 20 21 22 23 25 26 27\n",
      " 28 29 30 31 32 34 35 37 39 40 41 42 43 44 45 46 47 48 50 51 53 55 57 58\n",
      " 59 60]\n",
      "epoch  1, training loss: 0.694377, time: 0.2s\n",
      "epoch 10, training loss: 0.636759, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 274.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 27\n",
      " 28 30 31 32 33 34 36 37 38 40 41 44 45 46 47 49 51 52 53 55 56 57 58 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.679085, time: 1.3s\n",
      "epoch 10, training loss: 0.620422, time: 1.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using SSF strategy: 5it [10:17, 123.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.22979397963140194, BWT: 0.04452327661901747, FWT: 0.1780373793977931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_ssf = evaluation_protocol(T, E, Y, SLAD(epochs=10), strategy=\"SSF\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_ssf)}, BWT: {BWT(R_ssf)}, FWT: {FWT(R_ssf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b1d5060-780a-410d-9abd-f112e25f357e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6  7  9 10 12 13 14 16 17 18 20 22 24 25 26 27 28 30 31\n",
      " 32 33 34 35 36 37 38 40 41 42 44 45 46 47 48 49 50 51 53 54 55 56 57 58\n",
      " 59 60]\n",
      "epoch  1, training loss: 0.712536, time: 1.2s\n",
      "epoch 10, training loss: 0.659050, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 1it [01:43, 103.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  5  6  9 10 11 12 13 15 16 18 19 20 21 22 23 24 25 26 27 28 29\n",
      " 30 31 32 33 34 37 38 39 41 42 43 45 46 48 49 51 52 53 54 55 56 57 58 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.731120, time: 0.2s\n",
      "epoch 10, training loss: 0.658768, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 2it [03:35, 108.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6 10 11 13 14 15 16 17 18 19 20 21 22 25 26 27 29 30 31\n",
      " 32 35 36 38 39 40 41 42 43 44 45 46 47 49 50 51 52 53 54 55 56 57 58 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.732390, time: 0.9s\n",
      "epoch 10, training loss: 0.639096, time: 0.9s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 3it [06:21, 134.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 2  3  4  5  6  7  8  9 10 12 14 15 16 17 18 19 20 21 22 23 24 26 29 30\n",
      " 31 32 34 35 36 37 38 40 41 42 43 44 45 46 47 48 49 50 51 53 54 56 57 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.725860, time: 1.3s\n",
      "epoch 10, training loss: 0.669007, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 4it [09:04, 146.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  4  5  6  7  8  9 10 11 12 13 14 15 17 18 21 22 23 24 25 27 28 30\n",
      " 31 33 34 35 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 57\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.738106, time: 0.4s\n",
      "epoch 10, training loss: 0.671427, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 5it [11:50, 142.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.42501030198745793, BWT: 0.3790839248665491, FWT: 0.34203425505100765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_naive = evaluation_protocol(T, E, Y, SLAD(epochs=10), strategy=\"naive\")\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_naive)}, BWT: {BWT(R_naive)}, FWT: {FWT(R_naive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0b8572b-677d-4c67-bf2c-58713031e516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6  7  9 10 12 13 14 16 17 18 20 22 24 25 26 27 28 30 31\n",
      " 32 33 34 35 36 37 38 40 41 42 44 45 46 47 48 49 50 51 53 54 55 56 57 58\n",
      " 59 60]\n",
      "epoch  1, training loss: 0.712536, time: 1.2s\n",
      "epoch 10, training loss: 0.659050, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 1it [01:24, 84.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  5  6  9 10 11 12 13 15 16 18 19 20 21 22 23 24 25 26 27 28 29\n",
      " 30 31 32 33 34 37 38 39 41 42 43 45 46 48 49 51 52 53 54 55 56 57 58 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.633241, time: 2.3s\n",
      "epoch 10, training loss: 0.586830, time: 0.4s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 2it [03:56, 124.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6 10 11 13 14 15 16 17 18 19 20 21 22 25 26 27 29 30 31\n",
      " 32 35 36 38 39 40 41 42 43 44 45 46 47 49 50 51 52 53 54 55 56 57 58 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.745461, time: 2.9s\n",
      "epoch 10, training loss: 0.679813, time: 0.4s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 3it [05:40, 115.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 2  3  4  5  6  7  8  9 10 12 14 15 16 17 18 19 20 21 22 23 24 26 29 30\n",
      " 31 32 34 35 36 37 38 40 41 42 43 44 45 46 47 48 49 50 51 53 54 56 57 59\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.734115, time: 1.5s\n",
      "epoch 10, training loss: 0.652431, time: 1.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 4it [08:46, 143.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  2  4  5  6  7  8  9 10 11 12 13 14 15 17 18 21 22 23 24 25 27 28 30\n",
      " 31 33 34 35 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 57\n",
      " 60 61]\n",
      "epoch  1, training loss: 0.764536, time: 0.5s\n",
      "epoch 10, training loss: 0.685621, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 5it [11:35, 139.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.375337019597195, BWT: 0.27761302291808937, FWT: 0.425066935526481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_replay = evaluation_protocol(T, E, Y, SLAD(epochs=10), strategy=\"replay\", replay_buffer_size=5000)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_replay)}, BWT: {BWT(R_replay)}, FWT: {FWT(R_replay)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0a878c-3554-438f-965a-5b737daaf531",
   "metadata": {},
   "source": [
    "# ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6868de5b-507d-4d5e-9bf4-1640353034e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3b4c53f-fa88-49e1-860c-05f649d4cf8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using SSF strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.557956, time: 1.8s\n",
      "epoch 10, training loss: 0.967617, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.547110, time: 0.2s\n",
      "epoch 10, training loss: 0.968635, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 676.29it/s]\n",
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 686.72it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 683.96it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 680.37it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 686.76it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 683.30it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 684.68it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 686.49it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 684.90it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 683.12it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 683.49it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 686.02it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 684.94it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 685.43it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 684.59it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 683.46it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 68/375 [00:00<00:00, 679.40it/s]\u001b[A\n",
      "testing:  37%|███▋      | 137/375 [00:00<00:00, 682.55it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 206/375 [00:00<00:00, 683.50it/s]\u001b[A\n",
      "testing:  73%|███████▎  | 275/375 [00:00<00:00, 683.50it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 681.91it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 683.19it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 684.66it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 685.60it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 685.07it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 682.78it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 685.17it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 690.09it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 685.71it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 683.94it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 683.67it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 684.30it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 683.74it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 682.80it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 294.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.740979, time: 0.2s\n",
      "epoch 10, training loss: 0.968405, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 10.113696, time: 0.2s\n",
      "epoch 10, training loss: 1.058360, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 688.02it/s]\n",
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 692.07it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 686.64it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 681.80it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 687.01it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 684.28it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 680.38it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 681.54it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 681.69it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 679.62it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 675.10it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 684.30it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 681.74it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 681.10it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 679.78it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 678.83it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 68/375 [00:00<00:00, 678.66it/s]\u001b[A\n",
      "testing:  37%|███▋      | 137/375 [00:00<00:00, 681.56it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 206/375 [00:00<00:00, 679.29it/s]\u001b[A\n",
      "testing:  73%|███████▎  | 275/375 [00:00<00:00, 680.45it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 679.47it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 685.72it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 684.79it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 685.93it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 684.45it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 682.49it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 670.60it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 685.14it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 680.26it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 684.01it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 681.94it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 687.60it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 686.56it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 684.70it/s]\u001b[A\n",
      "Optimizing Sample Selection:   3%|▎         | 3/100 [00:00<00:00, 192.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 9.844010, time: 0.2s\n",
      "epoch 10, training loss: 1.060534, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.572062, time: 0.2s\n",
      "epoch 10, training loss: 1.068390, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 43/43 [00:00<00:00, 684.25it/s]\n",
      "\n",
      "testing: 100%|██████████| 43/43 [00:00<00:00, 685.73it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 685.05it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 684.05it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 684.59it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 682.09it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 682.33it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 683.06it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 683.10it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 682.44it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 682.10it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▉        | 70/370 [00:00<00:00, 690.43it/s]\u001b[A\n",
      "testing:  38%|███▊      | 140/370 [00:00<00:00, 686.92it/s]\u001b[A\n",
      "testing:  56%|█████▋    | 209/370 [00:00<00:00, 685.67it/s]\u001b[A\n",
      "testing:  75%|███████▌  | 278/370 [00:00<00:00, 684.74it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 683.14it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 680.45it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 681.31it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 681.01it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 680.95it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 678.96it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 688.14it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 688.32it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 686.48it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 684.77it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 683.22it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 680.29it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 687.25it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 683.00it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 685.87it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 683.74it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 687.36it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 685.09it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 683.69it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 315.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.861760, time: 0.2s\n",
      "epoch 10, training loss: 1.128419, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 9.071051, time: 0.2s\n",
      "epoch 10, training loss: 1.147296, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 43/43 [00:00<00:00, 692.21it/s]\n",
      "\n",
      "testing: 100%|██████████| 43/43 [00:00<00:00, 686.98it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 686.02it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 684.03it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 688.03it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 687.06it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 685.45it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 686.41it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 686.97it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 684.94it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 683.47it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 684.32it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 685.91it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 685.48it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 682.59it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 681.38it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 682.71it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 683.12it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 682.40it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 679.65it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 679.16it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 684.75it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 684.84it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 684.72it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 683.49it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 681.94it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 682.75it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 687.25it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 68/238 [00:00<00:00, 677.84it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 136/238 [00:00<00:00, 674.94it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 677.41it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 687.02it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 687.49it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 684.47it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 331.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 10.415680, time: 0.2s\n",
      "epoch 10, training loss: 1.237449, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 9.516177, time: 0.2s\n",
      "epoch 10, training loss: 1.172816, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 44/44 [00:00<00:00, 693.96it/s]\n",
      "\n",
      "testing: 100%|██████████| 44/44 [00:00<00:00, 689.75it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 686.92it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 685.81it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  42%|████▏     | 70/168 [00:00<00:00, 691.06it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 689.18it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 684.41it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 682.50it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 682.85it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 681.66it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 680.20it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 682.95it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 682.52it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 682.63it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 682.34it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 680.89it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 680.41it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 681.17it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 682.37it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 680.83it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 679.60it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 684.73it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 684.06it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 676.22it/s]\u001b[A\n",
      "testing:  73%|███████▎  | 275/375 [00:00<00:00, 674.92it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 675.44it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 682.78it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 685.36it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 68/238 [00:00<00:00, 679.63it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 137/238 [00:00<00:00, 683.11it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 681.28it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 688.03it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 685.81it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 683.72it/s]\u001b[A\n",
      "Evaluating using SSF strategy: 5it [00:41,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.21140831558070158, BWT: 0.04032918546117241, FWT: 0.26611288741057415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_ssf = evaluation_protocol(T, E, Y, ICL(epochs=10), strategy=\"SSF\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_ssf)}, BWT: {BWT(R_ssf)}, FWT: {FWT(R_ssf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a8ccdf0-1a1f-49cd-8a91-aab0932d0828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.948761, time: 0.6s\n",
      "epoch 10, training loss: 0.952242, time: 0.1s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.603786, time: 0.2s\n",
      "epoch 10, training loss: 0.987010, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 692.34it/s]\n",
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 688.24it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 687.06it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 680.63it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 684.72it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 683.26it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 681.58it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 680.51it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 681.01it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 679.76it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 679.70it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 686.99it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 687.99it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 685.51it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 682.01it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 681.72it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 681.06it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 683.23it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 682.33it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 681.11it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 679.87it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 683.66it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 683.72it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 683.43it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 681.41it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 679.48it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 682.20it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 686.20it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 680.52it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 683.77it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 681.46it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 681.13it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 680.46it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 677.72it/s]\u001b[A\n",
      "Evaluating using naive strategy: 1it [00:07,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 12.216283, time: 0.1s\n",
      "epoch 10, training loss: 1.081261, time: 0.1s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 12.785187, time: 0.1s\n",
      "epoch 10, training loss: 1.002754, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 36/36 [00:00<00:00, 689.31it/s]\n",
      "\n",
      "testing: 100%|██████████| 36/36 [00:00<00:00, 694.12it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  42%|████▏     | 70/168 [00:00<00:00, 690.64it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 688.39it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 684.22it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 683.21it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 681.69it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 684.92it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 683.99it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 681.86it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 681.43it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 685.53it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 686.10it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 683.95it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 682.13it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 681.89it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 680.47it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 681.40it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 681.67it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 680.85it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 680.49it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 685.29it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 685.55it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 683.70it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 681.78it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 681.55it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 684.15it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 684.84it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 680.30it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 683.30it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 681.88it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 683.94it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 684.29it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 682.61it/s]\u001b[A\n",
      "Evaluating using naive strategy: 2it [00:13,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 9.732757, time: 0.3s\n",
      "epoch 10, training loss: 1.307059, time: 0.3s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.951256, time: 0.3s\n",
      "epoch 10, training loss: 1.273736, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing:   0%|          | 0/81 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 81/81 [00:00<00:00, 685.17it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/81 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 81/81 [00:00<00:00, 684.02it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 684.81it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 683.75it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  42%|████▏     | 70/168 [00:00<00:00, 690.79it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 686.17it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 682.85it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 685.36it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 685.09it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 683.78it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 683.00it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 689.21it/s]\u001b[A\n",
      "testing:  38%|███▊      | 139/370 [00:00<00:00, 690.02it/s]\u001b[A\n",
      "testing:  56%|█████▋    | 209/370 [00:00<00:00, 690.33it/s]\u001b[A\n",
      "testing:  75%|███████▌  | 279/370 [00:00<00:00, 688.81it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 686.83it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 683.41it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 683.32it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 684.24it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 683.47it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 681.87it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 688.01it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 686.39it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 685.38it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 683.67it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 683.08it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 681.92it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 687.49it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 681.10it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 682.88it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 681.95it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 688.02it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 688.28it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 686.42it/s]\u001b[A\n",
      "Evaluating using naive strategy: 3it [00:23,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 10.521512, time: 0.2s\n",
      "epoch 10, training loss: 0.989495, time: 0.2s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 9.734859, time: 0.2s\n",
      "epoch 10, training loss: 0.999919, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 46/46 [00:00<00:00, 687.58it/s]\n",
      "\n",
      "testing: 100%|██████████| 46/46 [00:00<00:00, 690.67it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 684.99it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 682.79it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 687.13it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 683.22it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 684.12it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 685.41it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 684.77it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 683.20it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 682.33it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 685.09it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 684.92it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 683.82it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 683.15it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 681.20it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 684.32it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 682.94it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 676.79it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 679.77it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 678.21it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 687.74it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 683.34it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 680.10it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 679.82it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 679.90it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 683.75it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 684.76it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 682.15it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 682.63it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 682.47it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 685.72it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 685.38it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 681.81it/s]\u001b[A\n",
      "Evaluating using naive strategy: 4it [00:30,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 13.879924, time: 0.1s\n",
      "epoch 10, training loss: 1.192874, time: 0.1s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 14.775580, time: 0.1s\n",
      "epoch 10, training loss: 1.251964, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 24/24 [00:00<00:00, 683.87it/s]\n",
      "\n",
      "testing: 100%|██████████| 24/24 [00:00<00:00, 678.30it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 689.84it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 686.81it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  42%|████▏     | 70/168 [00:00<00:00, 691.90it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 687.98it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 682.28it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 682.23it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 683.43it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 682.15it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 681.50it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 688.43it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 688.18it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 687.32it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 686.59it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 686.04it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 682.65it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 682.13it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 682.17it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 681.27it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 680.53it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 683.50it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 683.49it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 682.69it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 680.10it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 680.19it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 679.22it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 683.77it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 678.88it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 681.00it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 680.40it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 682.46it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 682.89it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 682.00it/s]\u001b[A\n",
      "Evaluating using naive strategy: 5it [00:36,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.366368888036986, BWT: 0.3468663853036834, FWT: 0.27846962518715346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_naive = evaluation_protocol(T, E, Y, ICL(epochs=10), strategy=\"naive\")\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_naive)}, BWT: {BWT(R_naive)}, FWT: {FWT(R_naive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21f3dfde-ddf4-4c18-b98d-dfa64b820092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.948761, time: 0.2s\n",
      "epoch 10, training loss: 0.952242, time: 0.1s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.603787, time: 0.1s\n",
      "epoch 10, training loss: 0.987010, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 685.78it/s]\n",
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 687.98it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  40%|████      | 68/168 [00:00<00:00, 677.80it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 678.98it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 684.95it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 682.73it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 68/370 [00:00<00:00, 679.72it/s]\u001b[A\n",
      "testing:  37%|███▋      | 136/370 [00:00<00:00, 679.09it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 205/370 [00:00<00:00, 680.07it/s]\u001b[A\n",
      "testing:  74%|███████▍  | 274/370 [00:00<00:00, 679.07it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 677.61it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 685.14it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 686.37it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 686.12it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 684.90it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 683.48it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 680.43it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 681.55it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 681.25it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 680.52it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 679.49it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 684.72it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 684.81it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 685.03it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 684.16it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 682.20it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 678.72it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 683.96it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 68/238 [00:00<00:00, 679.82it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 137/238 [00:00<00:00, 681.24it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 681.02it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 687.55it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 139/238 [00:00<00:00, 689.02it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 687.26it/s]\u001b[A\n",
      "Evaluating using replay strategy: 1it [00:06,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 7.577938, time: 0.3s\n",
      "epoch 10, training loss: 0.897464, time: 0.3s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.577353, time: 0.3s\n",
      "epoch 10, training loss: 0.906317, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing:   0%|          | 0/78 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 78/78 [00:00<00:00, 684.32it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/78 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 78/78 [00:00<00:00, 683.03it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 683.85it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 684.08it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 685.55it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 684.86it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 684.08it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 686.44it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 686.79it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 683.99it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 683.60it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  16%|█▌        | 58/370 [00:00<00:00, 571.68it/s]\u001b[A\n",
      "testing:  34%|███▍      | 127/370 [00:00<00:00, 637.79it/s]\u001b[A\n",
      "testing:  53%|█████▎    | 196/370 [00:00<00:00, 659.88it/s]\u001b[A\n",
      "testing:  72%|███████▏  | 265/370 [00:00<00:00, 668.90it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 659.14it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 68/375 [00:00<00:00, 678.75it/s]\u001b[A\n",
      "testing:  37%|███▋      | 137/375 [00:00<00:00, 679.98it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 206/375 [00:00<00:00, 680.79it/s]\u001b[A\n",
      "testing:  73%|███████▎  | 275/375 [00:00<00:00, 680.51it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 679.41it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 685.46it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 684.42it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 683.97it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 682.77it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 683.05it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 680.29it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 685.62it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 68/238 [00:00<00:00, 678.86it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 136/238 [00:00<00:00, 679.44it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 678.74it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 681.42it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 679.11it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 678.49it/s]\u001b[A\n",
      "Evaluating using replay strategy: 2it [00:16,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 6.835413, time: 0.6s\n",
      "epoch 10, training loss: 1.016230, time: 0.6s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 6.898898, time: 0.6s\n",
      "epoch 10, training loss: 1.043806, time: 0.6s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing:   0%|          | 0/158 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  44%|████▍     | 70/158 [00:00<00:00, 692.04it/s]\u001b[A\n",
      "testing: 100%|██████████| 158/158 [00:00<00:00, 686.56it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/158 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  44%|████▎     | 69/158 [00:00<00:00, 688.55it/s]\u001b[A\n",
      "testing: 100%|██████████| 158/158 [00:00<00:00, 687.05it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 687.47it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 682.97it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  42%|████▏     | 70/168 [00:00<00:00, 691.50it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 685.75it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 68/370 [00:00<00:00, 679.42it/s]\u001b[A\n",
      "testing:  37%|███▋      | 137/370 [00:00<00:00, 683.55it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 206/370 [00:00<00:00, 684.70it/s]\u001b[A\n",
      "testing:  74%|███████▍  | 275/370 [00:00<00:00, 682.80it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 680.90it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 681.60it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 680.32it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 682.50it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 681.89it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 674.96it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 68/375 [00:00<00:00, 676.82it/s]\u001b[A\n",
      "testing:  37%|███▋      | 137/375 [00:00<00:00, 680.98it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 206/375 [00:00<00:00, 680.36it/s]\u001b[A\n",
      "testing:  73%|███████▎  | 275/375 [00:00<00:00, 678.66it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 677.36it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 682.77it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 683.75it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 684.87it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 683.35it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 682.46it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 678.55it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 688.32it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 68/238 [00:00<00:00, 678.10it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 137/238 [00:00<00:00, 681.36it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 680.79it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 684.76it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 682.95it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 681.95it/s]\u001b[A\n",
      "Evaluating using replay strategy: 3it [00:31, 11.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 8.237390, time: 0.4s\n",
      "epoch 10, training loss: 1.120666, time: 0.4s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 7.529574, time: 0.4s\n",
      "epoch 10, training loss: 1.089599, time: 0.4s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 124/124 [00:00<00:00, 687.75it/s][A\n",
      "\n",
      "testing:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 124/124 [00:00<00:00, 682.15it/s][A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 683.69it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 681.84it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 687.39it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 684.40it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 687.01it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 687.21it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 684.58it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 683.37it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 683.13it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▉        | 70/370 [00:00<00:00, 691.40it/s]\u001b[A\n",
      "testing:  38%|███▊      | 140/370 [00:00<00:00, 689.71it/s]\u001b[A\n",
      "testing:  56%|█████▋    | 209/370 [00:00<00:00, 677.99it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 277/370 [00:00<00:00, 674.70it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 676.36it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 683.10it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 683.17it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 680.79it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 678.84it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 678.73it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 682.35it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 680.60it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 682.07it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 681.14it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 680.00it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 682.40it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 686.61it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 680.68it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 680.88it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 679.00it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 681.20it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 680.77it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 679.81it/s]\u001b[A\n",
      "Evaluating using replay strategy: 4it [00:44, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 9.332559, time: 0.4s\n",
      "epoch 10, training loss: 1.148323, time: 0.4s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=51, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 9.365357, time: 0.4s\n",
      "epoch 10, training loss: 1.148879, time: 0.4s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing:   0%|          | 0/103 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 103/103 [00:00<00:00, 684.71it/s][A\n",
      "\n",
      "testing:   0%|          | 0/103 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 103/103 [00:00<00:00, 685.83it/s][A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 683.19it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 680.19it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  41%|████      | 69/168 [00:00<00:00, 682.71it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 679.16it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 680.54it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 679.24it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 206/370 [00:00<00:00, 679.13it/s]\u001b[A\n",
      "testing:  74%|███████▍  | 274/370 [00:00<00:00, 678.95it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 678.11it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  19%|█▊        | 69/370 [00:00<00:00, 683.40it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/370 [00:00<00:00, 682.60it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 207/370 [00:00<00:00, 682.31it/s]\u001b[A\n",
      "testing:  75%|███████▍  | 276/370 [00:00<00:00, 681.96it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 680.52it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 68/375 [00:00<00:00, 678.35it/s]\u001b[A\n",
      "testing:  37%|███▋      | 137/375 [00:00<00:00, 679.74it/s]\u001b[A\n",
      "testing:  55%|█████▍    | 206/375 [00:00<00:00, 680.02it/s]\u001b[A\n",
      "testing:  73%|███████▎  | 275/375 [00:00<00:00, 679.47it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 678.51it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  18%|█▊        | 69/375 [00:00<00:00, 687.07it/s]\u001b[A\n",
      "testing:  37%|███▋      | 138/375 [00:00<00:00, 684.51it/s]\u001b[A\n",
      "testing:  55%|█████▌    | 207/375 [00:00<00:00, 683.08it/s]\u001b[A\n",
      "testing:  74%|███████▎  | 276/375 [00:00<00:00, 681.84it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 681.47it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 683.16it/s]\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 689.84it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▊       | 68/238 [00:00<00:00, 678.69it/s]\u001b[A\n",
      "testing:  57%|█████▋    | 136/238 [00:00<00:00, 677.74it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 677.67it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  29%|██▉       | 69/238 [00:00<00:00, 684.09it/s]\u001b[A\n",
      "testing:  58%|█████▊    | 138/238 [00:00<00:00, 684.71it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 681.72it/s]\u001b[A\n",
      "Evaluating using replay strategy: 5it [00:57, 11.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.3699878547155736, BWT: 0.29572369486164496, FWT: 0.3692735205720691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_replay = evaluation_protocol(T, E, Y, ICL(epochs=10), strategy=\"replay\", replay_buffer_size=5000)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_replay)}, BWT: {BWT(R_replay)}, FWT: {FWT(R_replay)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7694dfa-3a80-431a-a5fb-363df9d5ee02",
   "metadata": {},
   "source": [
    "# RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a873ad7-face-4d9d-9a8b-d20c3a6fa2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3fc7318-cfd4-4160-98c9-b9f3e5014864",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using SSF strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.129436, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.283179, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 28.15it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 28.02it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 27.93it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.02it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.01it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.00it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.00it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.00it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.00it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.98it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.99it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.99it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.99it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.16it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.17it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.17it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.17it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.17it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.13it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.13it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.13it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.13it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.13it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.13it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.13it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.09it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.17it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.19it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.21it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.18it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.96it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.93it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.95it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.95it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.95it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.95it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 299.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.176405, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.286861, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 28.14it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 28.07it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 27.96it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.00it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  6.98it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  6.98it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  6.99it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.99it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.99it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.99it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.99it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.99it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.98it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.19it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.18it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.18it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.18it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.18it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.18it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.14it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.14it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.14it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.01it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.05it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.10it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.28it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.23it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.27it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.28it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.24it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.92it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.91it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.90it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.91it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.92it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.93it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.93it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.93it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.94it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.91it/s]\u001b[A\n",
      "Optimizing Sample Selection:   3%|▎         | 3/100 [00:00<00:00, 255.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.127915, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.297795, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 27.75it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 27.50it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 27.45it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.07it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.03it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.02it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.01it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.01it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.01it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  7.00it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  7.01it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  7.01it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.00it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.17it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.17it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.18it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.18it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.13it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.14it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.29it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.30it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.32it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.35it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.32it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.91it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.92it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.94it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.95it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.95it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.94it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 334.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.143658, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.301785, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 27.48it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 27.46it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 27.39it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.08it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.06it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.06it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.06it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.05it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.05it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  7.05it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  7.04it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  7.04it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.04it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.18it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.19it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.18it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.19it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.20it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.21it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.21it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.20it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.15it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.16it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.16it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.16it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.16it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.40it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.31it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.35it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.38it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.37it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  5.01it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  5.00it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.99it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.99it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.98it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.98it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.98it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.98it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.98it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.98it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 151.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.156713, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.324469, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 27.28it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 27.11it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 26.95it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.03it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.01it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.02it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.06it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.07it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.07it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  7.05it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  7.05it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  7.03it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.04it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.20it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.19it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.18it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.18it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.19it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.20it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.19it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.13it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.15it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.14it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.37it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.28it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.27it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.28it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.27it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.98it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.94it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.95it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.95it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.96it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.95it/s]\u001b[A\n",
      "Evaluating using SSF strategy: 5it [01:07, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.3150596094401886, BWT: 0.008468256555611004, FWT: 0.40685438222971354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_ssf = evaluation_protocol(T, E, Y, RCA(epochs=10), strategy=\"SSF\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_ssf)}, BWT: {BWT(R_ssf)}, FWT: {FWT(R_ssf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d89cd0b8-76b6-416d-ae38-03026f1e0879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.133825, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.283720, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 28.19it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 28.08it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 28.00it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.05it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.05it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.05it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.05it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.06it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.06it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  7.05it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  7.05it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  7.04it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.04it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.18it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.19it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.19it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.19it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.19it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.19it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.19it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.16it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.15it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.15it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.15it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.45it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.37it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.38it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.40it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.38it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.98it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.94it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.95it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.95it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.96it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.97it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.96it/s]\u001b[A\n",
      "Evaluating using naive strategy: 1it [00:12, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.653978, time: 0.1s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.213133, time: 0.1s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 32.78it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 32.58it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.05it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.04it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.01it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.01it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.01it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.01it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  7.02it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  7.02it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  7.01it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.01it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.18it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.19it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.19it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.19it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.19it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.19it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.13it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.14it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.02it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.06it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.09it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.09it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.10it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.34it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.32it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.31it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.32it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.27it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.98it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.96it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.96it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.96it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.96it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.96it/s]\u001b[A\n",
      "Evaluating using naive strategy: 2it [00:24, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.755487, time: 0.3s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.274268, time: 0.3s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 14.65it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 14.60it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 14.60it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 14.58it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.56it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.03it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.02it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.03it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.02it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.01it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.02it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  7.02it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  7.02it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  7.01it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.01it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.17it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.18it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.19it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.19it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.19it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.19it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.18it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.14it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.15it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.15it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.33it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.35it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.37it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.38it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.35it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.93it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.94it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.93it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.93it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.95it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.97it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.97it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.95it/s]\u001b[A\n",
      "Evaluating using naive strategy: 3it [00:38, 13.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.928987, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.268703, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 26.06it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 25.91it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 25.68it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.12it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.13it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.12it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.09it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.06it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.04it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  7.03it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  7.02it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  7.02it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.04it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.21it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.18it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.19it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.19it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.19it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.19it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.18it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.19it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.19it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.14it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.15it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.15it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.14it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.31it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.24it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.29it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.32it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.28it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.98it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.97it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.97it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.98it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.97it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.97it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.96it/s]\u001b[A\n",
      "Evaluating using naive strategy: 4it [00:50, 12.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.633695, time: 0.1s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.381846, time: 0.1s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00, 49.04it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 48.77it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.08it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.08it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.10it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.11it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.11it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.11it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  7.10it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.59it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  6.72it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.91it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.20it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.20it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.20it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.20it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.20it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.20it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.20it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.16it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.16it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.16it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.15it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.37it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.29it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.28it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.28it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.26it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.95it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.95it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.95it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.96it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.96it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.96it/s]\u001b[A\n",
      "Evaluating using naive strategy: 5it [01:02, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.4184634705864608, BWT: 0.2998736935141256, FWT: 0.4351211109995251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_naive = evaluation_protocol(T, E, Y, RCA(epochs=10), strategy=\"naive\")\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_naive)}, BWT: {BWT(R_naive)}, FWT: {FWT(R_naive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7206648-d043-47f2-b7a8-629528b60176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.133825, time: 0.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.283720, time: 0.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00, 28.54it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 28.45it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 28.34it/s][A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.13it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.10it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.11it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.11it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.11it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.11it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  7.11it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  7.11it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  7.11it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.10it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.22it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.23it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.22it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.21it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.20it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.20it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.20it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.15it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.15it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.24it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.22it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.23it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.26it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.23it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.98it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.97it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.96it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.96it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.97it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.95it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.95it/s]\u001b[A\n",
      "Evaluating using replay strategy: 1it [00:12, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.771072, time: 0.3s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.281382, time: 0.3s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 14.83it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 14.98it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 15.04it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 15.07it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 15.03it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.01it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.00it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.01it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.01it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.00it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.00it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  7.00it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  7.00it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  7.00it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.00it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:05,  1.69it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:03,  2.33it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:02,  2.67it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.86it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  2.97it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:02<00:01,  3.05it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.09it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.13it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:03<00:00,  3.15it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.94it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.14it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.15it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.16it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.16it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.16it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.16it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.14it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.15it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.39it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.34it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.35it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.32it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.29it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.94it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.93it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.93it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.93it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.95it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.97it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.98it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.96it/s]\u001b[A\n",
      "Evaluating using replay strategy: 2it [00:26, 13.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.777492, time: 0.6s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.337077, time: 0.6s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.55it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.48it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.48it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.47it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.48it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.47it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  7.48it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  7.48it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  7.49it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.48it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.10it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.06it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.04it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.03it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.04it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.04it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  7.03it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  7.03it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  7.03it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.03it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.21it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.18it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.18it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.19it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.19it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.19it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.19it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.17it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.15it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.15it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.15it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.35it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.15it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.23it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.26it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.23it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.98it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.97it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.97it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.97it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.97it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.98it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.98it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.98it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.97it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.97it/s]\u001b[A\n",
      "Evaluating using replay strategy: 3it [00:44, 15.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.835143, time: 0.5s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.337040, time: 0.5s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:00,  9.64it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00,  9.60it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  9.61it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  9.62it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  9.63it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  9.63it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  9.64it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00,  9.62it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:00<00:00,  9.62it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.61it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.14it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.13it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.14it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.12it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.12it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.12it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  7.10it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  7.08it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  7.06it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.08it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.23it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.21it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.22it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.21it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.22it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.22it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.22it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.22it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.22it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.22it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.18it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.17it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.17it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.16it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.16it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.16it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.16it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.41it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.34it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.31it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.33it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.29it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.92it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.93it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  4.94it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.94it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.96it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.97it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.97it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.96it/s]\u001b[A\n",
      "Evaluating using replay strategy: 4it [01:00, 15.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.008612, time: 0.4s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.444617, time: 0.4s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 11.56it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 11.52it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 11.52it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 11.51it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 11.49it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  7.03it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  7.03it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  7.04it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.03it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  7.03it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  7.03it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:00<00:00,  7.02it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  7.03it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  7.03it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.03it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.21it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.19it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.19it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.20it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.20it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.20it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.20it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.20it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:03,  2.87it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:02,  3.04it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:02,  3.09it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:01,  3.12it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  3.13it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:01,  3.14it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:02<00:00,  3.15it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  3.16it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.13it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:00, 19.36it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 19.36it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 19.35it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:00<00:00, 19.33it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.29it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.99it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  4.99it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:00<00:01,  5.00it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:01,  5.00it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  5.00it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:01<00:00,  5.00it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.99it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.99it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:01<00:00,  4.99it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.99it/s]\u001b[A\n",
      "Evaluating using replay strategy: 5it [01:15, 15.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.38759839235676985, BWT: 0.2463374375288844, FWT: 0.3641182664095414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_replay = evaluation_protocol(T, E, Y, RCA(epochs=10), strategy=\"replay\", replay_buffer_size=5000)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_replay)}, BWT: {BWT(R_replay)}, FWT: {FWT(R_replay)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d01ba4-0b27-4be0-9e4d-5550bc5fed96",
   "metadata": {},
   "source": [
    "# RDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbff48e6-6200-42e9-9075-0f3d6ee92df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import RDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f74a9f1-07b2-451a-a98b-19f725e1deb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using SSF strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000017, time: 0.5s\n",
      "epoch 10, training loss: 0.000017, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 1133.13it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1115.31it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  31%|███       | 114/370 [00:00<00:00, 1132.22it/s]\u001b[A\n",
      "testing:  62%|██████▏   | 228/370 [00:00<00:00, 1124.40it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1119.47it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|███       | 113/375 [00:00<00:00, 1120.07it/s]\u001b[A\n",
      "testing:  60%|██████    | 226/375 [00:00<00:00, 1121.82it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1119.63it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1111.58it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  47%|████▋     | 113/238 [00:00<00:00, 1123.36it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1117.06it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 323.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000026, time: 0.3s\n",
      "epoch 10, training loss: 0.000018, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 1124.95it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1115.64it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  31%|███       | 113/370 [00:00<00:00, 1122.06it/s]\u001b[A\n",
      "testing:  61%|██████    | 226/370 [00:00<00:00, 1121.92it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1119.64it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|██▉       | 112/375 [00:00<00:00, 1119.33it/s]\u001b[A\n",
      "testing:  60%|██████    | 225/375 [00:00<00:00, 1121.42it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1120.76it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1111.33it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  47%|████▋     | 113/238 [00:00<00:00, 1125.01it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1121.87it/s]\u001b[A\n",
      "Optimizing Sample Selection:   3%|▎         | 3/100 [00:00<00:00, 263.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000022, time: 0.4s\n",
      "epoch 10, training loss: 0.000023, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 43/43 [00:00<00:00, 993.51it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1012.41it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  28%|██▊       | 104/370 [00:00<00:00, 1030.88it/s]\u001b[A\n",
      "testing:  56%|█████▌    | 208/370 [00:00<00:00, 1013.37it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 998.95it/s] \u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  26%|██▌       | 98/375 [00:00<00:00, 979.49it/s]\u001b[A\n",
      "testing:  53%|█████▎    | 197/375 [00:00<00:00, 981.62it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 984.11it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 965.16it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  42%|████▏     | 100/238 [00:00<00:00, 997.74it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1005.48it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 204.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000018, time: 0.5s\n",
      "epoch 10, training loss: 0.000024, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 43/43 [00:00<00:00, 1128.31it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1124.53it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  31%|███       | 113/370 [00:00<00:00, 1123.56it/s]\u001b[A\n",
      "testing:  61%|██████▏   | 227/370 [00:00<00:00, 1130.03it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1126.28it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|███       | 113/375 [00:00<00:00, 1121.29it/s]\u001b[A\n",
      "testing:  60%|██████    | 226/375 [00:00<00:00, 1124.34it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1122.44it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1119.02it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  47%|████▋     | 113/238 [00:00<00:00, 1128.08it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1125.11it/s]\u001b[A\n",
      "Optimizing Sample Selection:   1%|          | 1/100 [00:00<00:00, 315.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000022, time: 0.5s\n",
      "epoch 10, training loss: 0.000026, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 44/44 [00:00<00:00, 1134.36it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1123.64it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  31%|███       | 113/370 [00:00<00:00, 1121.11it/s]\u001b[A\n",
      "testing:  61%|██████    | 226/370 [00:00<00:00, 1122.00it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1119.28it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|██▉       | 112/375 [00:00<00:00, 1117.21it/s]\u001b[A\n",
      "testing:  60%|██████    | 226/375 [00:00<00:00, 1124.46it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1120.79it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1117.02it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  48%|████▊     | 114/238 [00:00<00:00, 1133.37it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1122.85it/s]\u001b[A\n",
      "Evaluating using SSF strategy: 5it [00:30,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.22137051134872962, BWT: 0.04914431520735178, FWT: 0.31390066909618175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_ssf = evaluation_protocol(T, E, Y, RDP(epochs=10), strategy=\"SSF\", memory_size=5000, alpha=0.05)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_ssf)}, BWT: {BWT(R_ssf)}, FWT: {FWT(R_ssf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97bc0bc5-9043-401a-9c18-1fc8beb1f9c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using naive strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000016, time: 0.5s\n",
      "epoch 10, training loss: 0.000018, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 1129.05it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1126.35it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|███       | 112/370 [00:00<00:00, 1118.48it/s]\u001b[A\n",
      "testing:  61%|██████    | 225/370 [00:00<00:00, 1119.62it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1120.05it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|███       | 113/375 [00:00<00:00, 1120.18it/s]\u001b[A\n",
      "testing:  60%|██████    | 226/375 [00:00<00:00, 1123.55it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1121.42it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1111.03it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  47%|████▋     | 113/238 [00:00<00:00, 1124.47it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1119.22it/s]\u001b[A\n",
      "Evaluating using naive strategy: 1it [00:05,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000014, time: 0.4s\n",
      "epoch 10, training loss: 0.000022, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 36/36 [00:00<00:00, 1122.00it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1116.15it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|███       | 112/370 [00:00<00:00, 1116.31it/s]\u001b[A\n",
      "testing:  61%|██████    | 224/370 [00:00<00:00, 1114.08it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1106.72it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|██▉       | 112/375 [00:00<00:00, 1114.77it/s]\u001b[A\n",
      "testing:  60%|█████▉    | 224/375 [00:00<00:00, 1115.45it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1111.66it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1106.74it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  47%|████▋     | 113/238 [00:00<00:00, 1120.59it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1115.47it/s]\u001b[A\n",
      "Evaluating using naive strategy: 2it [00:08,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000009, time: 0.2s\n",
      "epoch 10, training loss: 0.000030, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 81/81 [00:00<00:00, 1129.16it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1086.33it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|███       | 112/370 [00:00<00:00, 1115.37it/s]\u001b[A\n",
      "testing:  61%|██████    | 224/370 [00:00<00:00, 1111.97it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1109.17it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|██▉       | 112/375 [00:00<00:00, 1114.72it/s]\u001b[A\n",
      "testing:  60%|█████▉    | 224/375 [00:00<00:00, 1115.00it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1111.31it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1104.02it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  47%|████▋     | 112/238 [00:00<00:00, 1116.56it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1108.78it/s]\u001b[A\n",
      "Evaluating using naive strategy: 3it [00:16,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000022, time: 0.1s\n",
      "epoch 10, training loss: 0.000026, time: 0.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 46/46 [00:00<00:00, 1123.59it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1122.09it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  31%|███       | 113/370 [00:00<00:00, 1122.93it/s]\u001b[A\n",
      "testing:  61%|██████    | 226/370 [00:00<00:00, 1125.84it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1119.42it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|██▉       | 112/375 [00:00<00:00, 1115.81it/s]\u001b[A\n",
      "testing:  60%|█████▉    | 224/375 [00:00<00:00, 1117.29it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1117.66it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1118.85it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  47%|████▋     | 113/238 [00:00<00:00, 1122.24it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1116.55it/s]\u001b[A\n",
      "Evaluating using naive strategy: 4it [00:18,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000041, time: 0.3s\n",
      "epoch 10, training loss: 0.000014, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 24/24 [00:00<00:00, 1104.42it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1122.34it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|███       | 112/370 [00:00<00:00, 1118.52it/s]\u001b[A\n",
      "testing:  61%|██████    | 225/370 [00:00<00:00, 1121.36it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1122.71it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|███       | 113/375 [00:00<00:00, 1120.68it/s]\u001b[A\n",
      "testing:  60%|██████    | 226/375 [00:00<00:00, 1122.46it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1116.94it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1120.44it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  47%|████▋     | 112/238 [00:00<00:00, 1119.42it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1114.80it/s]\u001b[A\n",
      "Evaluating using naive strategy: 5it [00:22,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.39524095441962026, BWT: 0.3392051136682391, FWT: 0.38131470018108704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_naive = evaluation_protocol(T, E, Y, RDP(epochs=10), strategy=\"naive\")\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_naive)}, BWT: {BWT(R_naive)}, FWT: {FWT(R_naive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "076a1086-24d9-4cb9-b6cb-0395f08dd5b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating using replay strategy: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000016, time: 0.5s\n",
      "epoch 10, training loss: 0.000018, time: 0.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 42/42 [00:00<00:00, 1099.73it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1125.93it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  31%|███       | 113/370 [00:00<00:00, 1128.87it/s]\u001b[A\n",
      "testing:  61%|██████    | 226/370 [00:00<00:00, 1127.04it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1126.68it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|███       | 113/375 [00:00<00:00, 1124.49it/s]\u001b[A\n",
      "testing:  61%|██████    | 227/375 [00:00<00:00, 1129.32it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1125.56it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1112.12it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  47%|████▋     | 113/238 [00:00<00:00, 1128.89it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1123.85it/s]\u001b[A\n",
      "Evaluating using replay strategy: 1it [00:05,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000015, time: 0.2s\n",
      "epoch 10, training loss: 0.000026, time: 0.9s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 78/78 [00:00<00:00, 1126.67it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1119.22it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  31%|███       | 113/370 [00:00<00:00, 1118.47it/s]\u001b[A\n",
      "testing:  61%|██████    | 226/370 [00:00<00:00, 1121.84it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1120.04it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|██▉       | 112/375 [00:00<00:00, 1119.37it/s]\u001b[A\n",
      "testing:  60%|██████    | 225/375 [00:00<00:00, 1123.79it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1123.69it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1110.51it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  47%|████▋     | 113/238 [00:00<00:00, 1120.45it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1119.22it/s]\u001b[A\n",
      "Evaluating using replay strategy: 2it [00:13,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000015, time: 1.9s\n",
      "epoch 10, training loss: 0.000045, time: 1.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing:   0%|          | 0/158 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 158/158 [00:00<00:00, 1067.30it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1120.69it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|███       | 112/370 [00:00<00:00, 1119.66it/s]\u001b[A\n",
      "testing:  61%|██████    | 224/370 [00:00<00:00, 1117.57it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1111.94it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|██▉       | 112/375 [00:00<00:00, 1112.01it/s]\u001b[A\n",
      "testing:  60%|█████▉    | 224/375 [00:00<00:00, 1115.50it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1115.07it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1104.26it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  47%|████▋     | 112/238 [00:00<00:00, 1119.90it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1115.13it/s]\u001b[A\n",
      "Evaluating using replay strategy: 3it [00:34, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000015, time: 0.5s\n",
      "epoch 10, training loss: 0.000042, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing:   0%|          | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 124/124 [00:00<00:00, 1093.03it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1110.57it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|███       | 111/370 [00:00<00:00, 1107.54it/s]\u001b[A\n",
      "testing:  60%|██████    | 223/370 [00:00<00:00, 1111.21it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1109.07it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|██▉       | 112/375 [00:00<00:00, 1114.68it/s]\u001b[A\n",
      "testing:  60%|██████    | 225/375 [00:00<00:00, 1123.50it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1114.06it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1113.00it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  47%|████▋     | 112/238 [00:00<00:00, 1118.83it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1116.74it/s]\u001b[A\n",
      "Evaluating using replay strategy: 4it [00:38,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=61, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000017, time: 1.3s\n",
      "epoch 10, training loss: 0.000045, time: 1.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "testing: 100%|██████████| 103/103 [00:00<00:00, 1135.33it/s]\n",
      "\n",
      "testing:   0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "testing: 100%|██████████| 168/168 [00:00<00:00, 1124.26it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|███       | 112/370 [00:00<00:00, 1116.21it/s]\u001b[A\n",
      "testing:  61%|██████    | 225/370 [00:00<00:00, 1119.31it/s]\u001b[A\n",
      "testing: 100%|██████████| 370/370 [00:00<00:00, 1117.86it/s]\u001b[A\n",
      "\n",
      "testing:   0%|          | 0/375 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  30%|██▉       | 112/375 [00:00<00:00, 1117.41it/s]\u001b[A\n",
      "testing:  60%|██████    | 226/375 [00:00<00:00, 1125.90it/s]\u001b[A\n",
      "testing: 100%|██████████| 375/375 [00:00<00:00, 1120.64it/s]\u001b[A\n",
      "\n",
      "testing: 100%|██████████| 61/61 [00:00<00:00, 1117.39it/s]\n",
      "\n",
      "testing:   0%|          | 0/238 [00:00<?, ?it/s]\u001b[A\n",
      "testing:  47%|████▋     | 113/238 [00:00<00:00, 1124.05it/s]\u001b[A\n",
      "testing: 100%|██████████| 238/238 [00:00<00:00, 1120.21it/s]\u001b[A\n",
      "Evaluating using replay strategy: 5it [00:52, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.39267806177273507, BWT: 0.2900278717009567, FWT: 0.4353395144027494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "R_replay = evaluation_protocol(T, E, Y, RDP(epochs=10), strategy=\"replay\", replay_buffer_size=5000)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_replay)}, BWT: {BWT(R_replay)}, FWT: {FWT(R_replay)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b89e81-c7b8-48de-91c0-790a5ff3876b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
