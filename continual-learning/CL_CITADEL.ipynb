{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "421755df-c4c3-4adb-b0c1-74c5910777b9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e609f474-dd80-40fd-b456-a953f6253fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import optuna\n",
    "from copy import deepcopy\n",
    "from pyDeepInsight import ImageTransformer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.base import clone\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e23bcc-3c21-48cb-aa68-49dcd56a5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('data/x_train.npy')\n",
    "y_train = np.load('data/y_train.npy')\n",
    "\n",
    "X_test = np.load('data/x_test.npy')\n",
    "y_test = np.load('data/y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4288166-7929-4afd-bc24-c2ecf3659c72",
   "metadata": {},
   "source": [
    "## MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08acf3e3-f1e1-4a8b-8e87-49aae4b2a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, img_channels=1, feature_dim=32, latent_dim=2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(img_channels, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(32 * 2 * 2, feature_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))  # Output: (batch_size, 16, 8, 8)\n",
    "        x = self.pool(x)              # Output: (batch_size, 16, 4, 4)\n",
    "        x = self.relu(self.conv2(x))  # Output: (batch_size, 32, 4, 4)\n",
    "        x = self.pool(x)              # Output: (batch_size, 32, 2, 2)\n",
    "        x = x.view(x.size(0), -1)     # Flatten to (batch_size, 128)\n",
    "        x = self.fc1(x)               # Output: (batch_size, feature_dim)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, img_channels=1, feature_dim=32):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc2 = nn.Linear(feature_dim, 32 * 2 * 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(16, img_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.relu(self.fc2(z))           # Output: (batch_size, 128)\n",
    "        x = x.view(x.size(0), 32, 2, 2)      # Reshape to (batch_size, 32, 2, 2)\n",
    "        x = self.upsample(x)                 # Upsample to (batch_size, 32, 4, 4)\n",
    "        x = self.relu(self.deconv1(x))       # Output: (batch_size, 16, 4, 4)\n",
    "        x = self.upsample(x)                 # Upsample to (batch_size, 16, 8, 8)\n",
    "        x = self.sigmoid(self.deconv2(x))    # Output: (batch_size, img_channels, 8, 8)\n",
    "        return x\n",
    "\n",
    "class MAE(nn.Module):\n",
    "    def __init__(self, img_channels=1, feature_dim=32, latent_dim=2):\n",
    "        super(MAE, self).__init__()\n",
    "        self.encoder = Encoder(img_channels, feature_dim, latent_dim)\n",
    "        self.decoder = Decoder(img_channels, feature_dim)\n",
    "\n",
    "    def mask_input(self, x, mask_ratio=0.25):\n",
    "        # Generate a mask with 0s and 1s, keeping only (1-mask_ratio) of the original input\n",
    "        mask = torch.rand(x.shape, device=x.device) > mask_ratio\n",
    "        x_masked = x * mask\n",
    "        return x_masked, mask\n",
    "\n",
    "    def forward(self, x, mask_ratio=0.25):\n",
    "        x_masked, mask = self.mask_input(x, mask_ratio)  # Apply masking to input\n",
    "        z = self.encoder(x_masked)\n",
    "        reconstructed = self.decoder(z)\n",
    "        return reconstructed, mask\n",
    "\n",
    "def mae_loss_function(reconstructed, original, mask):\n",
    "    # Only calculate reconstruction loss on the masked parts\n",
    "    masked_original = original * mask\n",
    "    reconstruction_loss = F.mse_loss(reconstructed, masked_original, reduction='sum')\n",
    "    return reconstruction_loss\n",
    "\n",
    "def extract_latent_features(model, data_loader, device='cuda'):\n",
    "    model.eval() \n",
    "    latent_features = []  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader: #tqdm(data_loader, total=len(data_loader), desc=\"Extracting features\"):\n",
    "            if len(batch) == 2:\n",
    "                data, _ = batch  \n",
    "            else:\n",
    "                (data,) = batch  \n",
    "            \n",
    "            data = data.to(device)\n",
    "\n",
    "            latent_feature = model.encoder(data)\n",
    "            latent_features.append(latent_feature.cpu().numpy())\n",
    "\n",
    "    latent_features = np.concatenate(latent_features, axis=0)\n",
    "    \n",
    "    return latent_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b5b75-554e-4024-98a9-9c96e42f455b",
   "metadata": {},
   "source": [
    "## Creation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f992c3-e4de-49be-bfac-47bdce14e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_phi(normal_data, c):\n",
    "    kmeans = KMeans(n_clusters=c, random_state=42)\n",
    "    labels = kmeans.fit_predict(normal_data)\n",
    "    \n",
    "    normal_concepts = [normal_data[labels == i] for i in range(c)]\n",
    "    print(\"Finished creating normal concepts\")\n",
    "    \n",
    "    return normal_concepts\n",
    "\n",
    "\n",
    "def create_gamma(anomaly_data, c):\n",
    "    kmeans = KMeans(n_clusters=c, random_state=42)\n",
    "    labels = kmeans.fit_predict(anomaly_data)\n",
    "    \n",
    "    anomaly_concepts = [anomaly_data[labels == i] for i in range(c)]\n",
    "    print(\"Finished creating anomaly concepts\")\n",
    "    \n",
    "    return anomaly_concepts\n",
    "    \n",
    "def match_lambda(anomaly_concepts, normal_concepts):\n",
    "    pairs = []\n",
    "    remaining_anomalies = anomaly_concepts.copy()\n",
    "\n",
    "    for normal_concept in normal_concepts:\n",
    "        normal_centroid = np.mean(normal_concept, axis=0)\n",
    "        anomaly_centroids = [np.mean(ac, axis=0) for ac in remaining_anomalies]\n",
    "\n",
    "        distances = cdist([normal_centroid], anomaly_centroids, metric='euclidean')[0]\n",
    "        closest_idx = np.argmin(distances)\n",
    "\n",
    "        pairs.append((normal_concept, remaining_anomalies[closest_idx]))\n",
    "        remaining_anomalies.pop(closest_idx)\n",
    "\n",
    "    print(\"Finished matching concept pairs\")\n",
    "    \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d08c06-732c-4eac-9e63-cfcd3691290a",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f9bdeb1-c8e5-41da-a84b-f166c1cc130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lifelong_roc_auc(R):\n",
    "    N = R.shape[0]\n",
    "    lower_triangular_sum = np.sum(np.tril(R))\n",
    "    normalization_factor = (N * (N + 1)) / 2\n",
    "\n",
    "    return lower_triangular_sum / normalization_factor\n",
    "\n",
    "def BWT(R):\n",
    "    N = R.shape[0]\n",
    "    backward_transfer = 0\n",
    "    count = 0\n",
    "\n",
    "    for i in range(1, N):\n",
    "        for j in range(i):\n",
    "            backward_transfer += (R[i, j] - R[j, j])\n",
    "            count += 1\n",
    "\n",
    "    return backward_transfer / count if count > 0 else 0\n",
    "\n",
    "def FWT(R):\n",
    "    N = R.shape[0]\n",
    "    forward_transfer = 0\n",
    "    count = 0\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(i + 1, N): \n",
    "            forward_transfer += R[i, j]\n",
    "            count += 1\n",
    "\n",
    "    return forward_transfer / count if count > 0 else 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669576fe-cbe8-4f1e-918b-e2d4ed5bfadb",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71703029-8cad-4317-be17-d74f2a4a252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_feature_selection(X, k, explained_variance_threshold=0.95):\n",
    "\n",
    "    pca = PCA()\n",
    "    pca.fit(X)\n",
    "    cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "    n_components = np.argmax(cumulative_variance >= explained_variance_threshold) + 1\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X)\n",
    "\n",
    "    feature_importance = np.abs(pca.components_).sum(axis=0)\n",
    "    top_k_indices = np.argsort(feature_importance)[-k:]\n",
    "    \n",
    "    return top_k_indices\n",
    "\n",
    "def kolmogorov_smirnov_test(X_old, X_new, alpha=0.05):\n",
    "    p_values = [ks_2samp(X_old[:, i], X_new[:, i]).pvalue for i in range(X_old.shape[1])]\n",
    "    return np.any(np.array(p_values) < alpha)\n",
    "\n",
    "def histogram_binning(X, bins=25):\n",
    "    return np.array([np.histogram(X[:, i], bins=bins, density=True)[0] for i in range(X.shape[1])]).T\n",
    "\n",
    "def weighted_histogram_binning(X, weights, bins=25):\n",
    "    histograms = []\n",
    "    for i in range(X.shape[1]):\n",
    "        hist, _ = np.histogram(X[:, i], bins=bins, density=True, weights=weights)\n",
    "        histograms.append(hist)\n",
    "    return np.array(histograms).T  # shape: (bins, n_features)\n",
    "\n",
    "def kl_divergence(P, Q):\n",
    "    P, Q = np.clip(P, 1e-10, None), np.clip(Q, 1e-10, None)  # Avoid log(0)\n",
    "    return np.sum(P * np.log(P / Q))\n",
    "\n",
    "def strategic_sample_selection(X_old, X_new, top_k=100, learning_rate=0.01, num_iterations=100):\n",
    "    H_old, H_new = histogram_binning(X_old), histogram_binning(X_new)\n",
    "    m_n = np.random.rand(H_new.shape[0])  \n",
    "\n",
    "    def loss_function(m_n):\n",
    "        weighted_H_new = H_new * m_n[:, np.newaxis]  \n",
    "        combined_H = (H_old + weighted_H_new) / 2 \n",
    "        return kl_divergence(H_new, combined_H) \n",
    "\n",
    "    progress_bar = tqdm(total=num_iterations, desc=\"Optimizing Sample Selection\", position=0, leave=True)\n",
    "\n",
    "    def callback(xk):\n",
    "        progress_bar.update(1)  \n",
    "\n",
    "    result = minimize(loss_function, m_n, method=\"L-BFGS-B\", bounds=[(0, 1)] * len(m_n), \n",
    "                      options={\"maxiter\": num_iterations, \"ftol\": 1e-10}, callback=callback)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    selected_indices = np.argsort(result.x)[-top_k:]\n",
    "\n",
    "    return X_new[selected_indices] \n",
    "\n",
    "def strategic_forgetting_update_opt(memory_buffer, X_new, drop_k=100, bins=25, num_iterations=100):\n",
    "    m0 = np.random.uniform(0.5, 1.0, size=memory_buffer.shape[0])\n",
    "    \n",
    "    H_new = histogram_binning(X_new, bins=bins)\n",
    "    H_new = H_new / (np.sum(H_new, axis=0, keepdims=True) + 1e-10)\n",
    "    \n",
    "    def loss_function(m):\n",
    "        H_weighted = weighted_histogram_binning(memory_buffer, m, bins=bins)\n",
    "        H_weighted = H_weighted / (np.sum(H_weighted, axis=0, keepdims=True) + 1e-10)\n",
    "        loss = 0\n",
    "        for j in range(H_new.shape[1]):\n",
    "            loss += kl_divergence(H_new[:, j], H_weighted[:, j])\n",
    "        return loss\n",
    "\n",
    "    progress_bar = tqdm(total=num_iterations, desc=\"Optimizing Forgetting\", position=0, leave=True)\n",
    "\n",
    "    def callback(xk):\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    result = minimize(loss_function, m0, method=\"L-BFGS-B\", bounds=[(0, 1)] * len(m0), \n",
    "                      options={\"maxiter\": num_iterations, \"ftol\": 1e-10}, callback=callback)\n",
    "    \n",
    "    progress_bar.close()\n",
    "    \n",
    "    optimized_m = result.x\n",
    "    print(f\"Optimized loss: {result.fun:.5f}\")\n",
    "    \n",
    "    non_rep_indices = np.where(optimized_m < 0.5)[0]\n",
    "    \n",
    "    if len(non_rep_indices) < drop_k:\n",
    "        additional_needed = drop_k - len(non_rep_indices)\n",
    "        remaining_indices = np.setdiff1d(np.arange(memory_buffer.shape[0]), non_rep_indices)\n",
    "        additional_indices = remaining_indices[np.argsort(optimized_m[remaining_indices])[:additional_needed]]\n",
    "        drop_indices = np.concatenate([non_rep_indices, additional_indices])\n",
    "    else:\n",
    "        drop_indices = non_rep_indices[np.argsort(optimized_m[non_rep_indices])[:drop_k]]\n",
    "    \n",
    "    updated_buffer = np.delete(memory_buffer, drop_indices, axis=0)\n",
    "    print(f\"Strategic Forgetting: Dropped {len(drop_indices)} samples based on the optimized mask.\")\n",
    "    return updated_buffer\n",
    "\n",
    "\n",
    "def update_memory_buffer(X_old, X_new_selected, memory_size=3000):\n",
    "    updated_buffer = np.vstack((X_old, X_new_selected))  \n",
    "\n",
    "    if updated_buffer.shape[0] > memory_size:\n",
    "        updated_buffer = updated_buffer[-memory_size:]\n",
    "\n",
    "    return updated_buffer\n",
    "\n",
    "class HierarchicalMemory:\n",
    "    def __init__(self, memory_limit=5000, pyramid_factor=2, centroids_per_concept=10):\n",
    "        self.memory_limit = memory_limit\n",
    "        self.pyramid_factor = pyramid_factor\n",
    "        self.centroids_per_concept = centroids_per_concept\n",
    "        self.memory = {}  # level: [concept1, concept2, ...]\n",
    "\n",
    "    def add_concept(self, data, level=1):\n",
    "        if level not in self.memory:\n",
    "            self.memory[level] = []\n",
    "        self.memory[level].append(np.array(data))\n",
    "        self._summarize_memory()\n",
    "\n",
    "    def _pyramidal_allocation(self):\n",
    "        levels = sorted(self.memory.keys())\n",
    "        weights = np.array([1 / (self.pyramid_factor ** (lvl - 1)) for lvl in levels])\n",
    "        total_weight = weights.sum()\n",
    "        allocations = (weights / total_weight) * self.memory_limit\n",
    "        return {lvl: int(alloc) for lvl, alloc in zip(levels, allocations)}\n",
    "\n",
    "    def _summarize_concept(self, concept, n_samples):\n",
    "        if len(concept) <= n_samples:\n",
    "            return concept\n",
    "        kmeans = KMeans(n_clusters=min(self.centroids_per_concept, len(concept)), random_state=42).fit(concept)\n",
    "        centroids = kmeans.cluster_centers_\n",
    "        distances = np.linalg.norm(concept[:, None] - centroids, axis=2)\n",
    "        closest_indices = np.argmin(distances, axis=0)\n",
    "        summarized = concept[closest_indices]\n",
    "        return summarized\n",
    "\n",
    "    def _summarize_memory(self):\n",
    "        allocations = self._pyramidal_allocation()\n",
    "        for level, concepts in self.memory.items():\n",
    "            summarized_level = []\n",
    "            alloc_per_concept = max(1, allocations[level] // len(concepts))\n",
    "            for concept in concepts:\n",
    "                summarized = self._summarize_concept(concept, alloc_per_concept)\n",
    "                summarized_level.append(summarized)\n",
    "            self.memory[level] = summarized_level\n",
    "\n",
    "    def get_all_memory(self):\n",
    "        all_data = []\n",
    "        for level_concepts in self.memory.values():\n",
    "            for concept in level_concepts:\n",
    "                all_data.append(concept)\n",
    "        return np.vstack(all_data) if all_data else np.empty((0,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf727f9-dbc5-4216-8a1b-4fadc5419337",
   "metadata": {},
   "source": [
    "## Scenario Design + Evaluation Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d267b4db-ae8f-4c28-b0f9-4f9a580a70fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario_design(normal_data, anomaly_data, c):\n",
    "    normal_concepts = create_phi(normal_data, c)\n",
    "    anomaly_concepts = create_gamma(anomaly_data, c)\n",
    "    \n",
    "    scenario = match_lambda(anomaly_concepts, normal_concepts)\n",
    "    \n",
    "    return scenario\n",
    "\n",
    "def evaluation_protocol(model, strategy=\"SSF\", replay_buffer_size=5000, memory_size=5000, alpha=0.05, forgetting_quota=100):\n",
    "\n",
    "    if strategy == \"SSF\":\n",
    "        hier_memory = None\n",
    "\n",
    "    # PREPROCESS\n",
    "    X = np.vstack((X_train, X_test))\n",
    "    y = np.hstack((y_train, y_test))\n",
    "    y = np.where(y == 11, 0, 1)\n",
    "\n",
    "    num_concepts = 5\n",
    "    X_normal = X[y == 0]  \n",
    "    X_anomaly = X[y == 1]\n",
    "\n",
    "    normal_concepts = create_phi(X_normal, num_concepts)\n",
    "    anomaly_concepts = create_gamma(X_anomaly, num_concepts)\n",
    "    concept_pairs = match_lambda(anomaly_concepts, normal_concepts)\n",
    "\n",
    "    T, E, Y_t, Y = [], [], [], []\n",
    "    for normal, anomaly in concept_pairs:\n",
    "        normal_train, normal_test = train_test_split(normal, test_size=0.3, random_state=42)\n",
    "        anomaly_train, anomaly_test = train_test_split(anomaly, test_size=0.3, random_state=42)  \n",
    "\n",
    "        T.append((normal_train, anomaly_train))\n",
    "        E.append((normal_test, anomaly_test))\n",
    "\n",
    "        y_normal_train = np.zeros(len(normal_train))\n",
    "        y_anomaly_train = np.ones(len(anomaly_train))\n",
    "        y_normal_test = np.zeros(len(normal_test))\n",
    "        y_anomaly_test = np.ones(len(anomaly_test))\n",
    "\n",
    "        Y_t.append((y_normal_train, y_anomaly_train))\n",
    "        Y.append((y_normal_test, y_anomaly_test))\n",
    "\n",
    "    print(\"Finished creating concepts\")\n",
    "    N = len(T)\n",
    "    R = np.zeros((N, N))\n",
    "\n",
    "    for i, Ti in tqdm(enumerate(T), desc=f\"Evaluating using {strategy} strategy\"):\n",
    "        Ti_full = np.vstack((Ti[0], Ti[1]))\n",
    "        Ti_n = Ti[1]\n",
    "        Y_ti = np.hstack((Y_t[i][0], Y_t[i][1]))\n",
    "\n",
    "        k = 31\n",
    "        top_features_indices = pca_feature_selection(Ti_full, k)\n",
    "        Ti_n_selected = Ti_n[:, top_features_indices]\n",
    "\n",
    "        if strategy == \"SSF\":\n",
    "            if hier_memory is None:\n",
    "                hier_memory = HierarchicalMemory(memory_limit=memory_size, pyramid_factor=2, centroids_per_concept=10)\n",
    "                selected = Ti_n_selected[:memory_size]\n",
    "                hier_memory.add_concept(selected, level=1)\n",
    "            else:\n",
    "                current_memory = hier_memory.get_all_memory()\n",
    "                drift_detected = kolmogorov_smirnov_test(current_memory, Ti_n_selected, alpha)\n",
    "                if drift_detected:\n",
    "                    print(\"Drift detected — applying strategic forgetting and selection (level 2)\")\n",
    "                    current_memory = strategic_forgetting_update_opt(current_memory, Ti_n_selected, drop_k=forgetting_quota)\n",
    "                    selected = strategic_sample_selection(current_memory, Ti_n_selected, top_k=forgetting_quota)\n",
    "                    hier_memory.add_concept(selected, level=2)\n",
    "                else:\n",
    "                    print(\"No drift — applying strategic selection (level 1)\")\n",
    "                    selected = strategic_sample_selection(current_memory, Ti_n_selected, top_k=forgetting_quota)\n",
    "                    hier_memory.add_concept(selected, level=1)\n",
    "\n",
    "            Ti_n_selected = hier_memory.get_all_memory()\n",
    "\n",
    "        it = ImageTransformer(pixels=8, feature_extractor='tsne', discretization='lsa')\n",
    "        it.fit(Ti_n_selected)\n",
    "        Ti_n_images = it.transform(Ti_n_selected, 'pytorch')\n",
    "\n",
    "        X_train_tensor = torch.tensor(Ti_n_images, dtype=torch.float32)\n",
    "        train_dataset = TensorDataset(X_train_tensor)\n",
    "        batch_size = 32\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        if i > 0:\n",
    "            mae_model = deepcopy(prev_mae_model)\n",
    "        else:\n",
    "            mae_model = MAE(img_channels=Ti_n_images.shape[1], feature_dim=32, latent_dim=16).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(mae_model.parameters(), lr=1e-3)\n",
    "        num_epochs = 20\n",
    "        mask_ratio = 0.75\n",
    "\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            mae_model.train()\n",
    "            for batch_idx, (data,) in enumerate(train_loader):\n",
    "                data = data.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, mask = mae_model(data, mask_ratio=mask_ratio)\n",
    "                loss = mae_loss_function(reconstructed, data, mask)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        prev_mae_model = deepcopy(mae_model)\n",
    "        mae_model_curr = mae_model\n",
    "\n",
    "        Ti_n_latent = extract_latent_features(mae_model_curr, train_loader, device)\n",
    "        current_model = clone(model)\n",
    "        current_model.fit(Ti_n_latent)\n",
    "\n",
    "        for j, ((Ej_normal, Ej_anomaly), (y_normal, y_anomaly)) in enumerate(zip(E, Y)):\n",
    "            test_data = np.vstack((Ej_normal, Ej_anomaly))\n",
    "            test_labels = np.hstack((y_normal, y_anomaly))\n",
    "            test_data_selected = test_data[:, top_features_indices]\n",
    "            test_data_images = it.transform(test_data_selected, 'pytorch')\n",
    "            X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
    "            test_dataset = TensorDataset(X_test_tensor, torch.tensor(test_labels, dtype=torch.long))\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            test_latent_features = extract_latent_features(mae_model_curr, test_loader, device)\n",
    "            scores = -current_model.decision_function(test_latent_features)\n",
    "            entry = roc_auc_score(test_labels, scores)\n",
    "            R[i, j] = entry\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6461297b-598d-4ea0-9e43-5ba502595a3e",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4063dd-99f8-4046-bad5-bd70653d3ca3",
   "metadata": {},
   "source": [
    "## LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "070dd790-8620-4479-8f98-21899c3d55a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating normal concepts\n",
      "Finished creating anomaly concepts\n",
      "Finished matching concept pairs\n",
      "Finished creating concepts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3bb9db57c8a4bc897ec0b9afd3d806f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating using SSF strategy: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2475/3243368550.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(Ti_n_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift detected — applying strategic forgetting and selection (level 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867fe6eb0e144fc586a386dd54962365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimizing Forgetting:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized loss: 214.95916\n",
      "Strategic Forgetting: Dropped 1000 samples based on the optimized mask.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d891628a52b94a518d7b034424f257c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimizing Sample Selection:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2475/3243368550.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(Ti_n_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift detected — applying strategic forgetting and selection (level 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cacb490f2524aa1b824aeafb8b3f37e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimizing Forgetting:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized loss: 211.31894\n",
      "Strategic Forgetting: Dropped 35 samples based on the optimized mask.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/numpy/lib/histograms.py:885: RuntimeWarning: invalid value encountered in divide\n",
      "  return n/db/n.sum(), bin_edges\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555c9088402e434ebc46d3c0a63707ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimizing Sample Selection:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2475/3243368550.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(Ti_n_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift detected — applying strategic forgetting and selection (level 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af44393c1e444bbad89711631afbcf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimizing Forgetting:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized loss: 273.99698\n",
      "Strategic Forgetting: Dropped 60 samples based on the optimized mask.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/numpy/lib/histograms.py:885: RuntimeWarning: invalid value encountered in divide\n",
      "  return n/db/n.sum(), bin_edges\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1422d5a29aba4c44875a2905c736494c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimizing Sample Selection:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2475/3243368550.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(Ti_n_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift detected — applying strategic forgetting and selection (level 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdaad371e8984a67ad7159cb0f026394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimizing Forgetting:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized loss: 208.93037\n",
      "Strategic Forgetting: Dropped 85 samples based on the optimized mask.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/numpy/lib/histograms.py:885: RuntimeWarning: invalid value encountered in divide\n",
      "  return n/db/n.sum(), bin_edges\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0964f1d1336a4ab09191aa3b631c6213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimizing Sample Selection:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2475/3243368550.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(Ti_n_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_2475/3243368550.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(test_data_images, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifelong ROC-AUC: 0.6776868664589615, BWT: 0.31546886894322534, FWT: 0.7980023104643891\n"
     ]
    }
   ],
   "source": [
    "R_ssf = evaluation_protocol(LocalOutlierFactor(n_neighbors=20, novelty=True, algorithm=\"ball_tree\"), memory_size=5000, alpha=0.05, forgetting_quota=1000)\n",
    "print(f\"Lifelong ROC-AUC: {lifelong_roc_auc(R_ssf)}, BWT: {BWT(R_ssf)}, FWT: {FWT(R_ssf)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
