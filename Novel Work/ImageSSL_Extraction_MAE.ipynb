{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ea0899-2874-4ff9-9f00-bfe8b19fca4f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a37aa6-e3d7-44c3-8510-20c402764c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "695de822-452d-4201-af27-0c377d4cf604",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf8e9a68-a3ca-4ca0-ac15-52f73656fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('data/x_train.npy')\n",
    "y_train = np.load('data/y_train.npy')\n",
    "\n",
    "X_test = np.load('data/x_test.npy')\n",
    "y_test = np.load('data/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a55d9859-b8ff-49ac-afa6-e16777d50ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.concatenate([X_train, X_test], axis=0)\n",
    "y = np.concatenate([y_train, y_test], axis=0)\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.2, random_state=42, stratify=y_trainval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca733982-495a-4f11-a652-d8e1adc08e57",
   "metadata": {},
   "source": [
    "# DT Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3979a317-ee84-4457-a53c-1ff36e43f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdddbad4-9a71-4b65-bb43-f3dd665eb8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds: 13.777572631835938\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Seconds: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce62ccb-5240-4cb5-ac9e-26ff631a8ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.00004054e-04, 2.32275550e-01, 5.81909506e-02, 3.15756934e-03,\n",
       "       4.25585385e-03, 1.86017758e-02, 0.00000000e+00, 1.12297756e-02,\n",
       "       2.06835319e-05, 9.79839366e-03, 1.15726586e-01, 1.34670186e-02,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.43275550e-02, 2.18915803e-02,\n",
       "       3.91414866e-04, 4.75027837e-03, 3.65356642e-02, 1.32100357e-02,\n",
       "       5.00913271e-04, 3.91093578e-03, 5.11511835e-03, 7.93200920e-04,\n",
       "       2.34232585e-02, 1.96728413e-03, 1.04062365e-02, 2.28049606e-03,\n",
       "       2.02199228e-02, 7.92317940e-04, 4.56055299e-03, 5.57995821e-04,\n",
       "       4.78700630e-04, 3.42492400e-04, 9.83732939e-04, 4.60169183e-04,\n",
       "       6.02096419e-04, 1.69953029e-03, 4.71636494e-04, 4.61407254e-04,\n",
       "       2.67645972e-03, 5.45862347e-03, 7.71917457e-04, 1.34210533e-03,\n",
       "       1.03829418e-02, 6.80623431e-04, 9.44982666e-03, 4.95269719e-03,\n",
       "       2.20453066e-01, 9.10046114e-04, 1.58227505e-05, 9.75562496e-03,\n",
       "       4.32497780e-02, 9.80924519e-05, 1.05137128e-04, 1.38389582e-04,\n",
       "       5.09774296e-02, 1.22728758e-04])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = clf.feature_importances_\n",
    "feature_importances = np.array(feature_importances)\n",
    "\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa02c2e7-b544-4fce-8f07-86416fed6943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features selected: 31\n"
     ]
    }
   ],
   "source": [
    "top_n = 31\n",
    "selected_indices = np.argsort(feature_importances)[-top_n:]\n",
    "\n",
    "# Sort the selected indices so that they are in the original order of features\n",
    "selected_indices = np.sort(selected_indices)\n",
    "\n",
    "print(f\"Number of features selected: {len(selected_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e830f895-375b-4e03-810a-8e24009a486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = X_train[:, selected_indices]\n",
    "X_test_selected = X_test[:, selected_indices]\n",
    "X_val_selected = X_val[:, selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e655460-d4ce-4ec0-8a9f-ecb1e5570257",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.where(y_train == 4, 0, 1)\n",
    "y_test = np.where(y_test == 4, 0, 1)\n",
    "y_val = np.where(y_val == 4, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0508401d-a76e-419b-bef4-be7c204f2b53",
   "metadata": {},
   "source": [
    "# PyDeepInsight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fdd1d8d-faeb-496d-9f8c-9c043ec5cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDeepInsight import ImageTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f30af3f2-0e04-4b2f-a2eb-96d262846b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = ImageTransformer(\n",
    "    pixels=8,\n",
    "    feature_extractor='tsne',\n",
    "    discretization='lsa'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cfe54ce-0775-4491-a80c-feb99153a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "it.fit(X_train_selected)\n",
    "X_train_images = it.transform(X_train_selected, 'pytorch')\n",
    "\n",
    "X_test_images = it.transform(X_test_selected, 'pytorch')\n",
    "\n",
    "X_val_images = it.transform(X_val_selected, 'pytorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e2cb7-61f4-4b11-8b1d-9c9345327caa",
   "metadata": {},
   "source": [
    "# MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d921a69-f2a9-46ca-84c4-b3a9587864ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples, channels, img_height, img_width = X_train_images.shape\n",
    "latent_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93d47b2c-847b-458f-b914-5ee0e30c5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, img_channels=1, feature_dim=32, latent_dim=2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(img_channels, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(32 * 2 * 2, feature_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))  # Output: (batch_size, 16, 8, 8)\n",
    "        x = self.pool(x)              # Output: (batch_size, 16, 4, 4)\n",
    "        x = self.relu(self.conv2(x))  # Output: (batch_size, 32, 4, 4)\n",
    "        x = self.pool(x)              # Output: (batch_size, 32, 2, 2)\n",
    "        x = x.view(x.size(0), -1)     # Flatten to (batch_size, 128)\n",
    "        x = self.fc1(x)               # Output: (batch_size, feature_dim)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04caf141-2602-4a0e-86a7-1064e127a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, img_channels=1, feature_dim=32):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc2 = nn.Linear(feature_dim, 32 * 2 * 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(16, img_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.relu(self.fc2(z))           # Output: (batch_size, 128)\n",
    "        x = x.view(x.size(0), 32, 2, 2)      # Reshape to (batch_size, 32, 2, 2)\n",
    "        x = self.upsample(x)                 # Upsample to (batch_size, 32, 4, 4)\n",
    "        x = self.relu(self.deconv1(x))       # Output: (batch_size, 16, 4, 4)\n",
    "        x = self.upsample(x)                 # Upsample to (batch_size, 16, 8, 8)\n",
    "        x = self.sigmoid(self.deconv2(x))    # Output: (batch_size, img_channels, 8, 8)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dc81be8-c7c6-4ee9-a28a-125ae58c172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAE(nn.Module):\n",
    "    def __init__(self, img_channels=1, feature_dim=32, latent_dim=2):\n",
    "        super(MAE, self).__init__()\n",
    "        self.encoder = Encoder(img_channels, feature_dim, latent_dim)\n",
    "        self.decoder = Decoder(img_channels, feature_dim)\n",
    "\n",
    "    def mask_input(self, x, mask_ratio=0.25):\n",
    "        # Generate a mask with 0s and 1s, keeping only (1-mask_ratio) of the original input\n",
    "        mask = torch.rand(x.shape, device=x.device) > mask_ratio\n",
    "        x_masked = x * mask\n",
    "        return x_masked, mask\n",
    "\n",
    "    def forward(self, x, mask_ratio=0.25):\n",
    "        x_masked, mask = self.mask_input(x, mask_ratio)  # Apply masking to input\n",
    "        z = self.encoder(x_masked)\n",
    "        reconstructed = self.decoder(z)\n",
    "        return reconstructed, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42c77a18-9e8f-4403-9a61-4a62dca55b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_loss_function(reconstructed, original, mask):\n",
    "    # Only calculate reconstruction loss on the masked parts\n",
    "    masked_original = original * mask\n",
    "    reconstruction_loss = F.mse_loss(reconstructed, masked_original, reduction='sum')\n",
    "    return reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae30c592-8fc1-4bed-9fef-83d42fad2468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MAE(img_channels=3, feature_dim=32, latent_dim=16).to(device)\n",
    "model.load_state_dict(torch.load(\"deepinsight_mae_normal.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7643352c-a46e-4545-ba7a-6f9ac0a73666",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4692a90-e22d-454c-997c-b393d6e1d901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_165/2967385897.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train_normal, dtype=torch.float32)\n",
      "/tmp/ipykernel_165/2967385897.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test_images, dtype=torch.float32)\n",
      "/tmp/ipykernel_165/2967385897.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_tensor = torch.tensor(X_val_images, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "normal_indices = np.where(y_train == 0)[0]\n",
    "X_train_normal = X_train_images[normal_indices]\n",
    "y_train_normal = y_train[normal_indices]\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_normal, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_images, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_images, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, torch.tensor(y_test, dtype=torch.long))\n",
    "val_dataset = TensorDataset(X_val_tensor, torch.tensor(y_val, dtype=torch.long))\n",
    "\n",
    "batch_size = 32 \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acfc7fe2-0a19-4882-a84e-d6e68ad7b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_latent_features(model, data_loader, device='cuda'):\n",
    "    model.eval() \n",
    "    latent_features = []  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, total=len(data_loader), desc=\"Extracting features\"):\n",
    "            if len(batch) == 2:\n",
    "                data, _ = batch  \n",
    "            else:\n",
    "                (data,) = batch  \n",
    "            \n",
    "            data = data.to(device)\n",
    "\n",
    "            latent_feature = model.encoder(data)\n",
    "            latent_features.append(latent_feature.cpu().numpy())\n",
    "\n",
    "    latent_features = np.concatenate(latent_features, axis=0)\n",
    "    \n",
    "    return latent_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0d8ae98-d2c0-4932-b250-14c1d7433876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 372/372 [00:00<00:00, 765.09it/s]\n",
      "Extracting features: 100%|██████████| 2945/2945 [00:02<00:00, 1186.65it/s]\n",
      "Extracting features: 100%|██████████| 3682/3682 [00:03<00:00, 1194.01it/s]\n"
     ]
    }
   ],
   "source": [
    "train_latent_features = extract_latent_features(model, train_loader, device)\n",
    "val_latent_features = extract_latent_features(model, val_loader, device)\n",
    "test_latent_features = extract_latent_features(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d49fafa-2efe-4166-8f38-79e3b42e0a01",
   "metadata": {},
   "source": [
    "# SGDOCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec4ea3d8-2406-4307-ba39-6a3392b3c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDOneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f761e90-8a6d-4a85-a220-605a5f077a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 21:49:16,302] A new study created in memory with name: no-name-2f23dbef-df18-42e7-a055-e3eb77ab15e1\n",
      "[I 2024-10-06 21:49:16,406] Trial 0 finished with value: 0.4018367538187611 and parameters: {'nu': 0.13533588259048898, 'learning_rate': 'constant', 'eta0': 0.2606531130399098, 'power_t': 1.8124905047071218}. Best is trial 0 with value: 0.4018367538187611.\n",
      "[I 2024-10-06 21:49:16,511] Trial 1 finished with value: 0.3402415916627191 and parameters: {'nu': 0.2964838317451876, 'learning_rate': 'invscaling', 'eta0': 0.11711903193790155, 'power_t': 0.43929890351241063}. Best is trial 0 with value: 0.4018367538187611.\n",
      "[I 2024-10-06 21:49:16,611] Trial 2 finished with value: 0.23798792756539236 and parameters: {'nu': 0.07893476787233185, 'learning_rate': 'optimal', 'eta0': 0.33172961198079504, 'power_t': 0.8589611793227387}. Best is trial 0 with value: 0.4018367538187611.\n",
      "[I 2024-10-06 21:49:16,684] Trial 3 finished with value: 0.06120769468161712 and parameters: {'nu': 0.1678360440643423, 'learning_rate': 'invscaling', 'eta0': 0.08675008453921614, 'power_t': -2.278878525378816}. Best is trial 0 with value: 0.4018367538187611.\n",
      "[I 2024-10-06 21:49:16,766] Trial 4 finished with value: 0.37833356363133896 and parameters: {'nu': 0.06985908011834326, 'learning_rate': 'constant', 'eta0': 0.07962454652790658, 'power_t': -1.7262891525295498}. Best is trial 0 with value: 0.4018367538187611.\n",
      "[I 2024-10-06 21:49:16,817] Trial 5 finished with value: 0.06120769468161712 and parameters: {'nu': 0.2617267137761606, 'learning_rate': 'invscaling', 'eta0': 0.37390759347107017, 'power_t': -0.36759082868722803}. Best is trial 0 with value: 0.4018367538187611.\n",
      "[I 2024-10-06 21:49:16,901] Trial 6 finished with value: 0.11910536243600107 and parameters: {'nu': 0.287340899681747, 'learning_rate': 'constant', 'eta0': 0.3321973180640127, 'power_t': -0.6573506151791584}. Best is trial 0 with value: 0.4018367538187611.\n",
      "[I 2024-10-06 21:49:17,048] Trial 7 finished with value: 0.3871703492516037 and parameters: {'nu': 0.09383000473571611, 'learning_rate': 'adaptive', 'eta0': 0.21688669855679155, 'power_t': -1.7816007780581709}. Best is trial 0 with value: 0.4018367538187611.\n",
      "[I 2024-10-06 21:49:17,300] Trial 8 finished with value: 0.4596907785753727 and parameters: {'nu': 0.4260271414765203, 'learning_rate': 'adaptive', 'eta0': 0.4499035137365129, 'power_t': -1.322488720252277}. Best is trial 8 with value: 0.4596907785753727.\n",
      "[I 2024-10-06 21:49:17,396] Trial 9 finished with value: 0.36894401425340917 and parameters: {'nu': 0.062467104442621116, 'learning_rate': 'constant', 'eta0': 0.3196682154469963, 'power_t': 1.8056317169049185}. Best is trial 8 with value: 0.4596907785753727.\n",
      "[I 2024-10-06 21:49:17,657] Trial 10 finished with value: 0.4509716659249369 and parameters: {'nu': 0.4703131050251376, 'learning_rate': 'adaptive', 'eta0': 0.46480119077787624, 'power_t': -0.9560207472118699}. Best is trial 8 with value: 0.4596907785753727.\n",
      "[I 2024-10-06 21:49:17,906] Trial 11 finished with value: 0.45849683066706914 and parameters: {'nu': 0.48778705969364056, 'learning_rate': 'adaptive', 'eta0': 0.4878708860202811, 'power_t': -0.9576742298173799}. Best is trial 8 with value: 0.4596907785753727.\n",
      "[I 2024-10-06 21:49:18,148] Trial 12 finished with value: 0.46219512195121953 and parameters: {'nu': 0.49966244069913757, 'learning_rate': 'adaptive', 'eta0': 0.48312594134575937, 'power_t': -2.950009850386304}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:18,369] Trial 13 finished with value: 0.44535374868004224 and parameters: {'nu': 0.38395492842532875, 'learning_rate': 'adaptive', 'eta0': 0.4279400294404451, 'power_t': -2.9775458719807317}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:18,601] Trial 14 finished with value: 0.44363439989199405 and parameters: {'nu': 0.3973875422195516, 'learning_rate': 'adaptive', 'eta0': 0.42002936716462264, 'power_t': -2.9167238078627036}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:18,694] Trial 15 finished with value: 0.3464874770922419 and parameters: {'nu': 0.40401246569397803, 'learning_rate': 'optimal', 'eta0': 0.493779129660506, 'power_t': 2.961095403464797}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:18,931] Trial 16 finished with value: 0.4567735641994879 and parameters: {'nu': 0.3537582809598042, 'learning_rate': 'adaptive', 'eta0': 0.21794160919298833, 'power_t': -1.9379112587928584}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:19,160] Trial 17 finished with value: 0.4602378564264221 and parameters: {'nu': 0.4472337787107168, 'learning_rate': 'adaptive', 'eta0': 0.41932441084858274, 'power_t': -2.432166162191018}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:19,426] Trial 18 finished with value: 0.4605543710021322 and parameters: {'nu': 0.4996853923546064, 'learning_rate': 'adaptive', 'eta0': 0.39829888435850236, 'power_t': -2.305465369038787}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:19,523] Trial 19 finished with value: 0.3347694457382394 and parameters: {'nu': 0.3386667278925757, 'learning_rate': 'optimal', 'eta0': 0.00513042688976581, 'power_t': -2.5764809628702037}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:19,752] Trial 20 finished with value: 0.4585870889159562 and parameters: {'nu': 0.49333563331274216, 'learning_rate': 'adaptive', 'eta0': 0.37319070992462866, 'power_t': 0.24386718313720807}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:20,004] Trial 21 finished with value: 0.44725987035945786 and parameters: {'nu': 0.4597922456131188, 'learning_rate': 'adaptive', 'eta0': 0.3941010009876766, 'power_t': -2.3035515248934866}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:20,242] Trial 22 finished with value: 0.45660163980774665 and parameters: {'nu': 0.439384787353049, 'learning_rate': 'adaptive', 'eta0': 0.28076970992129385, 'power_t': -2.5001117841507883}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:20,553] Trial 23 finished with value: 0.46118859915100063 and parameters: {'nu': 0.4972508221732581, 'learning_rate': 'adaptive', 'eta0': 0.4089279849757852, 'power_t': -1.6517178162232002}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:20,929] Trial 24 finished with value: 0.3843224153451977 and parameters: {'nu': 0.18597169817546882, 'learning_rate': 'adaptive', 'eta0': 0.4543132892530434, 'power_t': -1.2879223970798275}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:21,161] Trial 25 finished with value: 0.45735963581183614 and parameters: {'nu': 0.49061223757195355, 'learning_rate': 'adaptive', 'eta0': 0.3654118606293899, 'power_t': -1.544233901624819}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:21,393] Trial 26 finished with value: 0.44786581549630744 and parameters: {'nu': 0.3519079332943986, 'learning_rate': 'adaptive', 'eta0': 0.49587544492788566, 'power_t': -2.9842230003033587}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:21,487] Trial 27 finished with value: 0.34734716357628054 and parameters: {'nu': 0.4127321923296853, 'learning_rate': 'optimal', 'eta0': 0.4059853996401508, 'power_t': -1.9354627003937959}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:21,583] Trial 28 finished with value: 0.06120769468161712 and parameters: {'nu': 0.020825972581773128, 'learning_rate': 'invscaling', 'eta0': 0.29907425045416813, 'power_t': -0.3009738321663171}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:21,738] Trial 29 finished with value: 0.4366035570854848 and parameters: {'nu': 0.1986282028720349, 'learning_rate': 'adaptive', 'eta0': 0.17657114900954102, 'power_t': -2.1902172315388544}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:21,839] Trial 30 finished with value: 0.20045989449479237 and parameters: {'nu': 0.4483381199002454, 'learning_rate': 'constant', 'eta0': 0.44627539626114404, 'power_t': -2.6665898325411055}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:22,134] Trial 31 finished with value: 0.46200607902735563 and parameters: {'nu': 0.49833470418676534, 'learning_rate': 'adaptive', 'eta0': 0.40263801535116645, 'power_t': -2.1143603428652655}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:22,354] Trial 32 finished with value: 0.4481044126786824 and parameters: {'nu': 0.49920918201446696, 'learning_rate': 'adaptive', 'eta0': 0.347979649162156, 'power_t': -2.0762066192511024}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:22,616] Trial 33 finished with value: 0.4514903565166569 and parameters: {'nu': 0.45425935490243385, 'learning_rate': 'adaptive', 'eta0': 0.3809662242578089, 'power_t': 0.7141248942765778}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:22,712] Trial 34 finished with value: 0.0 and parameters: {'nu': 0.38434769748588526, 'learning_rate': 'invscaling', 'eta0': 0.46731659183083907, 'power_t': -1.3972246699535347}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:22,966] Trial 35 finished with value: 0.4505413020910574 and parameters: {'nu': 0.4710396054751738, 'learning_rate': 'adaptive', 'eta0': 0.26604689374253243, 'power_t': -1.001179633116251}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:23,069] Trial 36 finished with value: 0.3545437346282399 and parameters: {'nu': 0.42994916974443964, 'learning_rate': 'optimal', 'eta0': 0.4013692362293115, 'power_t': -1.7017252315176343}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:23,145] Trial 37 finished with value: 0.06120769468161712 and parameters: {'nu': 0.3132709534812861, 'learning_rate': 'invscaling', 'eta0': 0.31043639987365546, 'power_t': 1.298579623226817}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:23,247] Trial 38 finished with value: 0.27087764727642655 and parameters: {'nu': 0.2291194093105094, 'learning_rate': 'constant', 'eta0': 0.4351512419941817, 'power_t': -2.644180744327458}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:23,524] Trial 39 finished with value: 0.4469006721433906 and parameters: {'nu': 0.4698590320832387, 'learning_rate': 'adaptive', 'eta0': 0.35434658141903924, 'power_t': -0.5905983968822093}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:23,752] Trial 40 finished with value: 0.4513015873015873 and parameters: {'nu': 0.3730748025478401, 'learning_rate': 'adaptive', 'eta0': 0.33833242078394443, 'power_t': -2.1726264524425343}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:23,964] Trial 41 finished with value: 0.4510135135135135 and parameters: {'nu': 0.4298299422239128, 'learning_rate': 'adaptive', 'eta0': 0.4104246996002987, 'power_t': -2.38082862048602}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:24,261] Trial 42 finished with value: 0.4578423871461362 and parameters: {'nu': 0.4995327396950414, 'learning_rate': 'adaptive', 'eta0': 0.46783715321337016, 'power_t': -2.6773943256749178}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:24,517] Trial 43 finished with value: 0.46083627797408716 and parameters: {'nu': 0.47102071314233607, 'learning_rate': 'adaptive', 'eta0': 0.3899832628292413, 'power_t': -1.695874353230011}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:24,760] Trial 44 finished with value: 0.4505445322989706 and parameters: {'nu': 0.4738939491265028, 'learning_rate': 'adaptive', 'eta0': 0.39418897416948206, 'power_t': -1.669596683470533}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:25,076] Trial 45 finished with value: 0.3743099501817692 and parameters: {'nu': 0.12053102383060671, 'learning_rate': 'adaptive', 'eta0': 0.4761005795391873, 'power_t': -1.1927645889316718}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:25,179] Trial 46 finished with value: 0.0 and parameters: {'nu': 0.4150053670348003, 'learning_rate': 'constant', 'eta0': 0.43702525345369514, 'power_t': -1.8903380309098052}. Best is trial 12 with value: 0.46219512195121953.\n",
      "[I 2024-10-06 21:49:25,589] Trial 47 finished with value: 0.48576688854269934 and parameters: {'nu': 0.47044992418610637, 'learning_rate': 'adaptive', 'eta0': 0.33004870308906176, 'power_t': -1.5853196027005136}. Best is trial 47 with value: 0.48576688854269934.\n",
      "[I 2024-10-06 21:49:25,680] Trial 48 finished with value: 0.0 and parameters: {'nu': 0.47229338360706913, 'learning_rate': 'invscaling', 'eta0': 0.23198905248124968, 'power_t': -0.7147327267621111}. Best is trial 47 with value: 0.48576688854269934.\n",
      "[I 2024-10-06 21:49:25,926] Trial 49 finished with value: 0.47188811188811186 and parameters: {'nu': 0.44310114579011234, 'learning_rate': 'adaptive', 'eta0': 0.33112239904342367, 'power_t': -0.07955377864340574}. Best is trial 47 with value: 0.48576688854269934.\n",
      "[I 2024-10-06 21:49:26,203] Trial 50 finished with value: 0.45651554034787567 and parameters: {'nu': 0.4419039051537555, 'learning_rate': 'adaptive', 'eta0': 0.2879861170635756, 'power_t': 1.243692440699115}. Best is trial 47 with value: 0.48576688854269934.\n",
      "[I 2024-10-06 21:49:26,678] Trial 51 finished with value: 0.4841654778887304 and parameters: {'nu': 0.48087149398598317, 'learning_rate': 'adaptive', 'eta0': 0.3245856220836713, 'power_t': -0.1712455846419729}. Best is trial 47 with value: 0.48576688854269934.\n",
      "[I 2024-10-06 21:49:26,889] Trial 52 finished with value: 0.4604161037557417 and parameters: {'nu': 0.4198156149224062, 'learning_rate': 'adaptive', 'eta0': 0.3102596712132654, 'power_t': -0.1067201672077983}. Best is trial 47 with value: 0.48576688854269934.\n",
      "[I 2024-10-06 21:49:27,130] Trial 53 finished with value: 0.4425778863775199 and parameters: {'nu': 0.48050933882523095, 'learning_rate': 'adaptive', 'eta0': 0.3393417551638302, 'power_t': 0.49675161705143434}. Best is trial 47 with value: 0.48576688854269934.\n",
      "[I 2024-10-06 21:49:27,668] Trial 54 finished with value: 0.4882880471155133 and parameters: {'nu': 0.4544741187099828, 'learning_rate': 'adaptive', 'eta0': 0.24596518534137665, 'power_t': 0.10066608382546419}. Best is trial 54 with value: 0.4882880471155133.\n",
      "[I 2024-10-06 21:49:27,772] Trial 55 finished with value: 0.3493923878847696 and parameters: {'nu': 0.4014044077282286, 'learning_rate': 'optimal', 'eta0': 0.18377296862266262, 'power_t': -0.026759751981742824}. Best is trial 54 with value: 0.4882880471155133.\n",
      "[I 2024-10-06 21:49:28,358] Trial 56 finished with value: 0.4856213402732596 and parameters: {'nu': 0.4527782762766092, 'learning_rate': 'adaptive', 'eta0': 0.2571080117655541, 'power_t': 0.1280605963604996}. Best is trial 54 with value: 0.4882880471155133.\n",
      "[I 2024-10-06 21:49:28,814] Trial 57 finished with value: 0.4886155456686731 and parameters: {'nu': 0.4510762322041181, 'learning_rate': 'adaptive', 'eta0': 0.25195533499728545, 'power_t': 0.22916751775673502}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:29,038] Trial 58 finished with value: 0.457270804826471 and parameters: {'nu': 0.37829582446276033, 'learning_rate': 'adaptive', 'eta0': 0.24621114788774717, 'power_t': 0.3801749809565267}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:29,138] Trial 59 finished with value: 0.0 and parameters: {'nu': 0.2638226360260871, 'learning_rate': 'constant', 'eta0': 0.19282853818002002, 'power_t': 0.17881110279477347}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:29,314] Trial 60 finished with value: 0.4547769290379719 and parameters: {'nu': 0.3138715212350997, 'learning_rate': 'adaptive', 'eta0': 0.1554172471024707, 'power_t': 0.9137475650701796}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:29,858] Trial 61 finished with value: 0.48705882352941177 and parameters: {'nu': 0.450203992663166, 'learning_rate': 'adaptive', 'eta0': 0.2497935617331621, 'power_t': -0.3580508001130485}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:30,113] Trial 62 finished with value: 0.44757709251101324 and parameters: {'nu': 0.45762697274819464, 'learning_rate': 'adaptive', 'eta0': 0.26594823843736715, 'power_t': -0.23358252110461247}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:30,337] Trial 63 finished with value: 0.4740720524017467 and parameters: {'nu': 0.4338374028091027, 'learning_rate': 'adaptive', 'eta0': 0.249648675638816, 'power_t': -0.5092895255635869}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:30,589] Trial 64 finished with value: 0.4684807876384521 and parameters: {'nu': 0.43051955846667805, 'learning_rate': 'adaptive', 'eta0': 0.21874417853042644, 'power_t': -0.4971983821975503}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:30,858] Trial 65 finished with value: 0.4593577521324636 and parameters: {'nu': 0.395150394391388, 'learning_rate': 'adaptive', 'eta0': 0.24335183229185928, 'power_t': -0.7873437836750605}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:31,120] Trial 66 finished with value: 0.44961697112551563 and parameters: {'nu': 0.4607592327570528, 'learning_rate': 'adaptive', 'eta0': 0.2760251337351979, 'power_t': -0.39837284189267563}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:31,301] Trial 67 finished with value: 0.461374154503382 and parameters: {'nu': 0.35776015605745426, 'learning_rate': 'adaptive', 'eta0': 0.13817845242146937, 'power_t': 0.23248147256573287}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:31,398] Trial 68 finished with value: 0.351094845232926 and parameters: {'nu': 0.42045632592867405, 'learning_rate': 'optimal', 'eta0': 0.20778630185135666, 'power_t': 0.6629367781742181}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:31,626] Trial 69 finished with value: 0.46336917562724017 and parameters: {'nu': 0.4517242146979079, 'learning_rate': 'adaptive', 'eta0': 0.2942997153149588, 'power_t': 0.10825728355455524}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:32,067] Trial 70 finished with value: 0.44964730601831004 and parameters: {'nu': 0.4844925311332237, 'learning_rate': 'adaptive', 'eta0': 0.25917802265552004, 'power_t': 0.44653226839149107}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:32,289] Trial 71 finished with value: 0.4683103496308678 and parameters: {'nu': 0.43732202197728137, 'learning_rate': 'adaptive', 'eta0': 0.31932138983238767, 'power_t': -0.11766142621041892}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:32,546] Trial 72 finished with value: 0.4612352168199737 and parameters: {'nu': 0.4090260137650167, 'learning_rate': 'adaptive', 'eta0': 0.23916864491431764, 'power_t': -0.2298269896922289}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:32,767] Trial 73 finished with value: 0.4702565548350719 and parameters: {'nu': 0.44652129004283586, 'learning_rate': 'adaptive', 'eta0': 0.22640164035694468, 'power_t': 0.07054887196238344}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:32,982] Trial 74 finished with value: 0.47468354430379744 and parameters: {'nu': 0.4635236929515361, 'learning_rate': 'adaptive', 'eta0': 0.32377573234979024, 'power_t': 2.647513477995126}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:33,050] Trial 75 finished with value: 0.06120769468161712 and parameters: {'nu': 0.46075528993523746, 'learning_rate': 'invscaling', 'eta0': 0.2561161924748564, 'power_t': 2.3737021451416}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:33,270] Trial 76 finished with value: 0.4732981220657277 and parameters: {'nu': 0.4796500803989642, 'learning_rate': 'adaptive', 'eta0': 0.2015771299057276, 'power_t': 2.07078905951599}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:33,600] Trial 77 finished with value: 0.4666666666666667 and parameters: {'nu': 0.38873783050086363, 'learning_rate': 'adaptive', 'eta0': 0.2793957139655545, 'power_t': 2.7782218194699966}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:33,861] Trial 78 finished with value: 0.4607083563918096 and parameters: {'nu': 0.42841311713847363, 'learning_rate': 'adaptive', 'eta0': 0.2995923270582484, 'power_t': 1.126311078574982}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:33,948] Trial 79 finished with value: 0.0 and parameters: {'nu': 0.48542221541660596, 'learning_rate': 'constant', 'eta0': 0.3236914089421659, 'power_t': 1.7215752415047287}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:34,171] Trial 80 finished with value: 0.4460537984037836 and parameters: {'nu': 0.45951701002235007, 'learning_rate': 'adaptive', 'eta0': 0.358576991339321, 'power_t': -0.9003691979466913}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:34,397] Trial 81 finished with value: 0.46850044365572313 and parameters: {'nu': 0.48187984855738114, 'learning_rate': 'adaptive', 'eta0': 0.19685967457435447, 'power_t': 2.298381892363284}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:34,590] Trial 82 finished with value: 0.44891320419931985 and parameters: {'nu': 0.4644799875900766, 'learning_rate': 'adaptive', 'eta0': 0.1655920053330024, 'power_t': 2.5933287290518416}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:34,817] Trial 83 finished with value: 0.4672482626053526 and parameters: {'nu': 0.4804829665142284, 'learning_rate': 'adaptive', 'eta0': 0.2068100824914743, 'power_t': -0.4658699115470489}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:35,117] Trial 84 finished with value: 0.48521523861917204 and parameters: {'nu': 0.44863445683498265, 'learning_rate': 'adaptive', 'eta0': 0.2342844002354753, 'power_t': 1.6607575728756552}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:35,355] Trial 85 finished with value: 0.4502932341582034 and parameters: {'nu': 0.43961778158501336, 'learning_rate': 'adaptive', 'eta0': 0.27316454887372743, 'power_t': -1.0927643770027835}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:35,588] Trial 86 finished with value: 0.4630633011761596 and parameters: {'nu': 0.41458787386840923, 'learning_rate': 'adaptive', 'eta0': 0.22757188773951428, 'power_t': 1.8044805553236918}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:35,684] Trial 87 finished with value: 0.3387706855791962 and parameters: {'nu': 0.3660701928138964, 'learning_rate': 'optimal', 'eta0': 0.25528425218582157, 'power_t': 0.8305157584984605}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:35,937] Trial 88 finished with value: 0.46508960573476704 and parameters: {'nu': 0.45209755610195, 'learning_rate': 'adaptive', 'eta0': 0.30562170376585646, 'power_t': 0.3655046069020633}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:36,009] Trial 89 finished with value: 0.06120769468161712 and parameters: {'nu': 0.4063003870648584, 'learning_rate': 'invscaling', 'eta0': 0.24332580931991873, 'power_t': 1.504205696100187}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:36,156] Trial 90 finished with value: 0.4472286258394307 and parameters: {'nu': 0.43261448704277106, 'learning_rate': 'adaptive', 'eta0': 0.005770376841262664, 'power_t': -1.4232398279735774}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:36,369] Trial 91 finished with value: 0.461654817728029 and parameters: {'nu': 0.4913008117739289, 'learning_rate': 'adaptive', 'eta0': 0.2864506976661051, 'power_t': 2.179759820760993}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:36,581] Trial 92 finished with value: 0.47161572052401746 and parameters: {'nu': 0.471576706850416, 'learning_rate': 'adaptive', 'eta0': 0.21550402030466015, 'power_t': 2.9894330635927218}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:36,811] Trial 93 finished with value: 0.4473569244211446 and parameters: {'nu': 0.44784643843535593, 'learning_rate': 'adaptive', 'eta0': 0.2684596287592778, 'power_t': 2.03798812871652}. Best is trial 57 with value: 0.4886155456686731.\n",
      "[I 2024-10-06 21:49:37,203] Trial 94 finished with value: 0.49678501537601344 and parameters: {'nu': 0.47562102961452357, 'learning_rate': 'adaptive', 'eta0': 0.23508170305633402, 'power_t': 2.7128925959926202}. Best is trial 94 with value: 0.49678501537601344.\n",
      "[I 2024-10-06 21:49:37,420] Trial 95 finished with value: 0.47597122302158273 and parameters: {'nu': 0.46432610739360347, 'learning_rate': 'adaptive', 'eta0': 0.2323165460780347, 'power_t': 2.7197001002524788}. Best is trial 94 with value: 0.49678501537601344.\n",
      "[I 2024-10-06 21:49:37,973] Trial 96 finished with value: 0.4889196675900277 and parameters: {'nu': 0.46524396897218834, 'learning_rate': 'adaptive', 'eta0': 0.22991686007251252, 'power_t': 2.7026932501005545}. Best is trial 94 with value: 0.49678501537601344.\n",
      "[I 2024-10-06 21:49:38,349] Trial 97 finished with value: 0.4945776255707763 and parameters: {'nu': 0.49163482460921343, 'learning_rate': 'adaptive', 'eta0': 0.2277650560264976, 'power_t': 2.726963365014583}. Best is trial 94 with value: 0.49678501537601344.\n",
      "[I 2024-10-06 21:49:38,533] Trial 98 finished with value: 0.43105466990903357 and parameters: {'nu': 0.16572380866472425, 'learning_rate': 'adaptive', 'eta0': 0.2133682152531607, 'power_t': 2.4949384442363756}. Best is trial 94 with value: 0.49678501537601344.\n",
      "[I 2024-10-06 21:49:38,721] Trial 99 finished with value: 0.0 and parameters: {'nu': 0.4929469922918654, 'learning_rate': 'constant', 'eta0': 0.18660279487067963, 'power_t': 2.82689528880421}. Best is trial 94 with value: 0.49678501537601344.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'nu': 0.47562102961452357, 'learning_rate': 'adaptive', 'eta0': 0.23508170305633402, 'power_t': 2.7128925959926202}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    nu = trial.suggest_float('nu', 0.01, 0.5)  \n",
    "    learning_rate = trial.suggest_categorical('learning_rate', ['constant', 'optimal', 'invscaling', 'adaptive'])\n",
    "    eta0 = trial.suggest_float('eta0', 1e-6, 0.5)\n",
    "    power_t = trial.suggest_float('power_t', -3, 3)\n",
    "\n",
    "    sgdocsvm = SGDOneClassSVM(nu=nu, learning_rate=learning_rate, eta0=eta0, power_t=power_t)\n",
    "    sgdocsvm.fit(train_latent_features)\n",
    "\n",
    "    val_predictions = sgdocsvm.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 1, -1)\n",
    "\n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=1, average='binary')\n",
    "\n",
    "    return f1 \n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d89118e-8269-41ec-adcd-8bd4677b8545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9612\n",
      "Test Precision: 0.4183\n",
      "Test Recall: 0.5861\n",
      "Test F1 Score: 0.4882\n"
     ]
    }
   ],
   "source": [
    "best_sgdocsvm = SGDOneClassSVM(nu=best_params['nu'], \n",
    "                               learning_rate=best_params['learning_rate'], \n",
    "                               eta0=best_params['eta0'], \n",
    "                               random_state=42)\n",
    "\n",
    "best_sgdocsvm.fit(train_latent_features)\n",
    "\n",
    "test_predictions = best_sgdocsvm.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 1, -1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b521b47-305c-48fd-b20a-f0b764722ed3",
   "metadata": {},
   "source": [
    "# LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3cc2aae-3699-4c98-a567-ed96c7f69434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13e65e0c-779a-4538-a935-4f2ae57b2af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 21:50:15,977] A new study created in memory with name: no-name-5c2db3fb-0f3a-4f48-a917-426f334bc6dc\n",
      "[I 2024-10-06 21:50:20,007] Trial 0 finished with value: 0.9283320031923384 and parameters: {'n_neighbors': 24, 'leaf_size': 38, 'metric': 'chebyshev'}. Best is trial 0 with value: 0.9283320031923384.\n",
      "[I 2024-10-06 21:50:21,248] Trial 1 finished with value: 0.9879231161762204 and parameters: {'n_neighbors': 36, 'leaf_size': 39, 'metric': 'minkowski'}. Best is trial 1 with value: 0.9879231161762204.\n",
      "[I 2024-10-06 21:50:22,437] Trial 2 finished with value: 0.9874063989108237 and parameters: {'n_neighbors': 34, 'leaf_size': 33, 'metric': 'minkowski'}. Best is trial 1 with value: 0.9879231161762204.\n",
      "[I 2024-10-06 21:50:23,652] Trial 3 finished with value: 0.9767441860465116 and parameters: {'n_neighbors': 30, 'leaf_size': 38, 'metric': 'euclidean'}. Best is trial 1 with value: 0.9879231161762204.\n",
      "[I 2024-10-06 21:50:27,632] Trial 4 finished with value: 0.9879272232613501 and parameters: {'n_neighbors': 11, 'leaf_size': 50, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9879272232613501.\n",
      "[I 2024-10-06 21:50:31,555] Trial 5 finished with value: 0.9780627742153223 and parameters: {'n_neighbors': 49, 'leaf_size': 38, 'metric': 'manhattan'}. Best is trial 4 with value: 0.9879272232613501.\n",
      "[I 2024-10-06 21:50:35,663] Trial 6 finished with value: 0.9875786966139186 and parameters: {'n_neighbors': 32, 'leaf_size': 43, 'metric': 'chebyshev'}. Best is trial 4 with value: 0.9879272232613501.\n",
      "[I 2024-10-06 21:50:36,853] Trial 7 finished with value: 0.9767441860465116 and parameters: {'n_neighbors': 30, 'leaf_size': 30, 'metric': 'euclidean'}. Best is trial 4 with value: 0.9879272232613501.\n",
      "[I 2024-10-06 21:50:40,725] Trial 8 finished with value: 0.9880952380952381 and parameters: {'n_neighbors': 40, 'leaf_size': 49, 'metric': 'manhattan'}. Best is trial 8 with value: 0.9880952380952381.\n",
      "[I 2024-10-06 21:50:44,861] Trial 9 finished with value: 0.9877509356924123 and parameters: {'n_neighbors': 39, 'leaf_size': 38, 'metric': 'chebyshev'}. Best is trial 8 with value: 0.9880952380952381.\n",
      "[I 2024-10-06 21:50:48,839] Trial 10 finished with value: 0.9780627742153223 and parameters: {'n_neighbors': 49, 'leaf_size': 21, 'metric': 'manhattan'}. Best is trial 8 with value: 0.9880952380952381.\n",
      "[I 2024-10-06 21:50:52,551] Trial 11 finished with value: 0.9218303145853194 and parameters: {'n_neighbors': 9, 'leaf_size': 49, 'metric': 'manhattan'}. Best is trial 8 with value: 0.9880952380952381.\n",
      "[I 2024-10-06 21:50:56,266] Trial 12 finished with value: 0.8749050007599939 and parameters: {'n_neighbors': 7, 'leaf_size': 50, 'metric': 'manhattan'}. Best is trial 8 with value: 0.9880952380952381.\n",
      "[I 2024-10-06 21:51:00,336] Trial 13 finished with value: 0.9884393063583815 and parameters: {'n_neighbors': 19, 'leaf_size': 45, 'metric': 'chebyshev'}. Best is trial 13 with value: 0.9884393063583815.\n",
      "[I 2024-10-06 21:51:04,111] Trial 14 finished with value: 0.9889549702633815 and parameters: {'n_neighbors': 16, 'leaf_size': 45, 'metric': 'manhattan'}. Best is trial 14 with value: 0.9889549702633815.\n",
      "[I 2024-10-06 21:51:08,189] Trial 15 finished with value: 0.9891267414203194 and parameters: {'n_neighbors': 18, 'leaf_size': 45, 'metric': 'chebyshev'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:09,330] Trial 16 finished with value: 0.9887831407205983 and parameters: {'n_neighbors': 18, 'leaf_size': 45, 'metric': 'euclidean'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:10,460] Trial 17 finished with value: 0.9884393063583815 and parameters: {'n_neighbors': 15, 'leaf_size': 27, 'metric': 'minkowski'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:14,256] Trial 18 finished with value: 0.9188846641318125 and parameters: {'n_neighbors': 24, 'leaf_size': 42, 'metric': 'manhattan'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:18,330] Trial 19 finished with value: 0.9884393063583815 and parameters: {'n_neighbors': 14, 'leaf_size': 46, 'metric': 'chebyshev'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:22,408] Trial 20 finished with value: 0.9283320031923384 and parameters: {'n_neighbors': 24, 'leaf_size': 34, 'metric': 'chebyshev'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:23,555] Trial 21 finished with value: 0.9887831407205983 and parameters: {'n_neighbors': 19, 'leaf_size': 46, 'metric': 'euclidean'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:24,702] Trial 22 finished with value: 0.9887831407205983 and parameters: {'n_neighbors': 19, 'leaf_size': 42, 'metric': 'euclidean'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:25,805] Trial 23 finished with value: 0.7215777262180975 and parameters: {'n_neighbors': 5, 'leaf_size': 44, 'metric': 'euclidean'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:26,951] Trial 24 finished with value: 0.9880952380952381 and parameters: {'n_neighbors': 13, 'leaf_size': 47, 'metric': 'euclidean'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:28,103] Trial 25 finished with value: 0.9887831407205983 and parameters: {'n_neighbors': 17, 'leaf_size': 41, 'metric': 'euclidean'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:31,893] Trial 26 finished with value: 0.9882673014793403 and parameters: {'n_neighbors': 22, 'leaf_size': 47, 'metric': 'manhattan'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:33,005] Trial 27 finished with value: 0.9877551020408163 and parameters: {'n_neighbors': 11, 'leaf_size': 40, 'metric': 'minkowski'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:37,127] Trial 28 finished with value: 0.9312169312169312 and parameters: {'n_neighbors': 28, 'leaf_size': 44, 'metric': 'chebyshev'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:40,949] Trial 29 finished with value: 0.9190897597977244 and parameters: {'n_neighbors': 23, 'leaf_size': 21, 'metric': 'manhattan'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:42,083] Trial 30 finished with value: 0.9884393063583815 and parameters: {'n_neighbors': 16, 'leaf_size': 36, 'metric': 'euclidean'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:43,237] Trial 31 finished with value: 0.9886112527621962 and parameters: {'n_neighbors': 20, 'leaf_size': 47, 'metric': 'euclidean'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:44,416] Trial 32 finished with value: 0.9098887321736405 and parameters: {'n_neighbors': 26, 'leaf_size': 45, 'metric': 'euclidean'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:45,558] Trial 33 finished with value: 0.9887831407205983 and parameters: {'n_neighbors': 18, 'leaf_size': 48, 'metric': 'euclidean'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:46,715] Trial 34 finished with value: 0.9880952380952381 and parameters: {'n_neighbors': 21, 'leaf_size': 40, 'metric': 'minkowski'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:47,829] Trial 35 finished with value: 0.9880952380952381 and parameters: {'n_neighbors': 12, 'leaf_size': 36, 'metric': 'euclidean'}. Best is trial 15 with value: 0.9891267414203194.\n",
      "[I 2024-10-06 21:51:51,974] Trial 36 finished with value: 0.9894701086956522 and parameters: {'n_neighbors': 16, 'leaf_size': 43, 'metric': 'chebyshev'}. Best is trial 36 with value: 0.9894701086956522.\n",
      "[I 2024-10-06 21:51:56,027] Trial 37 finished with value: 0.9789455954185615 and parameters: {'n_neighbors': 10, 'leaf_size': 43, 'metric': 'chebyshev'}. Best is trial 36 with value: 0.9894701086956522.\n",
      "[I 2024-10-06 21:52:00,173] Trial 38 finished with value: 0.9303219605958674 and parameters: {'n_neighbors': 27, 'leaf_size': 39, 'metric': 'chebyshev'}. Best is trial 36 with value: 0.9894701086956522.\n",
      "[I 2024-10-06 21:52:04,260] Trial 39 finished with value: 0.9886112527621962 and parameters: {'n_neighbors': 15, 'leaf_size': 31, 'metric': 'chebyshev'}. Best is trial 36 with value: 0.9894701086956522.\n",
      "[I 2024-10-06 21:52:08,308] Trial 40 finished with value: 0.9882673014793403 and parameters: {'n_neighbors': 9, 'leaf_size': 42, 'metric': 'chebyshev'}. Best is trial 36 with value: 0.9894701086956522.\n",
      "[I 2024-10-06 21:52:12,396] Trial 41 finished with value: 0.9891267414203194 and parameters: {'n_neighbors': 17, 'leaf_size': 45, 'metric': 'chebyshev'}. Best is trial 36 with value: 0.9894701086956522.\n",
      "[I 2024-10-06 21:52:16,460] Trial 42 finished with value: 0.9891267414203194 and parameters: {'n_neighbors': 17, 'leaf_size': 44, 'metric': 'chebyshev'}. Best is trial 36 with value: 0.9894701086956522.\n",
      "[I 2024-10-06 21:52:20,506] Trial 43 finished with value: 0.9886112527621962 and parameters: {'n_neighbors': 13, 'leaf_size': 43, 'metric': 'chebyshev'}. Best is trial 36 with value: 0.9894701086956522.\n",
      "[I 2024-10-06 21:52:24,609] Trial 44 finished with value: 0.9894701086956522 and parameters: {'n_neighbors': 16, 'leaf_size': 48, 'metric': 'chebyshev'}. Best is trial 36 with value: 0.9894701086956522.\n",
      "[I 2024-10-06 21:52:28,725] Trial 45 finished with value: 0.9889549702633815 and parameters: {'n_neighbors': 22, 'leaf_size': 50, 'metric': 'chebyshev'}. Best is trial 36 with value: 0.9894701086956522.\n",
      "[I 2024-10-06 21:52:32,943] Trial 46 finished with value: 0.9874063989108237 and parameters: {'n_neighbors': 45, 'leaf_size': 48, 'metric': 'chebyshev'}. Best is trial 36 with value: 0.9894701086956522.\n",
      "[I 2024-10-06 21:52:36,963] Trial 47 finished with value: 0.9400424767194903 and parameters: {'n_neighbors': 7, 'leaf_size': 49, 'metric': 'chebyshev'}. Best is trial 36 with value: 0.9894701086956522.\n",
      "[I 2024-10-06 21:52:41,111] Trial 48 finished with value: 0.9875786966139186 and parameters: {'n_neighbors': 33, 'leaf_size': 44, 'metric': 'chebyshev'}. Best is trial 36 with value: 0.9894701086956522.\n",
      "[I 2024-10-06 21:52:45,196] Trial 49 finished with value: 0.9894701086956522 and parameters: {'n_neighbors': 16, 'leaf_size': 48, 'metric': 'chebyshev'}. Best is trial 36 with value: 0.9894701086956522.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_neighbors': 16, 'leaf_size': 43, 'metric': 'chebyshev'}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 5, 50)  \n",
    "    leaf_size = trial.suggest_int('leaf_size', 20, 50) \n",
    "    metric = trial.suggest_categorical('metric', ['euclidean', 'manhattan', 'chebyshev', 'minkowski'])  \n",
    "\n",
    "    lof = LocalOutlierFactor(n_neighbors=n_neighbors, leaf_size=leaf_size, metric=metric, novelty=True)\n",
    "    lof.fit(train_latent_features)\n",
    "\n",
    "    val_predictions = lof.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 1, -1)\n",
    "\n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=1, average='binary')\n",
    "\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91fac012-f694-45cb-91d7-39b027c95cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9993\n",
      "Test Precision: 1.0000\n",
      "Test Recall: 0.9766\n",
      "Test F1 Score: 0.9882\n"
     ]
    }
   ],
   "source": [
    "best_lof = LocalOutlierFactor(n_neighbors=best_params['n_neighbors'], \n",
    "                              leaf_size=best_params['leaf_size'], \n",
    "                              metric=best_params['metric'], \n",
    "                              novelty=True)\n",
    "\n",
    "best_lof.fit(train_latent_features)\n",
    "\n",
    "test_predictions = best_lof.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 1, -1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8441d28b-5b9c-4a4c-89bb-a3cbc7355fbd",
   "metadata": {},
   "source": [
    "# IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "911a9fdb-288c-45d1-bdaf-39215145a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23c70397-b155-4e23-a55e-a5991a950e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 21:54:30,124] A new study created in memory with name: no-name-84192326-0c20-4bf9-958a-27938b42298d\n",
      "[I 2024-10-06 21:54:32,069] Trial 0 finished with value: 0.758347245409015 and parameters: {'n_estimators': 90, 'max_samples': 0.6522849072667373, 'contamination': 0.36391882009091236, 'max_features': 0.9862815306458456}. Best is trial 0 with value: 0.758347245409015.\n",
      "[I 2024-10-06 21:54:36,835] Trial 1 finished with value: 0.7984652665589661 and parameters: {'n_estimators': 294, 'max_samples': 0.6358450534687283, 'contamination': 0.3178252827344318, 'max_features': 0.5760135291257376}. Best is trial 1 with value: 0.7984652665589661.\n",
      "[I 2024-10-06 21:54:42,756] Trial 2 finished with value: 0.9739610277634075 and parameters: {'n_estimators': 279, 'max_samples': 0.65011658278168, 'contamination': 0.041538543008933435, 'max_features': 0.9843608667509698}. Best is trial 2 with value: 0.9739610277634075.\n",
      "[I 2024-10-06 21:54:45,659] Trial 3 finished with value: 0.9671931956257594 and parameters: {'n_estimators': 192, 'max_samples': 0.5053117479779835, 'contamination': 0.05370965493840306, 'max_features': 0.5029784977148802}. Best is trial 2 with value: 0.9739610277634075.\n",
      "[I 2024-10-06 21:54:47,264] Trial 4 finished with value: 0.7663280116110305 and parameters: {'n_estimators': 100, 'max_samples': 0.6640577868142725, 'contamination': 0.3635647646285686, 'max_features': 0.5313414895793368}. Best is trial 2 with value: 0.9739610277634075.\n",
      "[I 2024-10-06 21:54:50,956] Trial 5 finished with value: 0.7110051993067591 and parameters: {'n_estimators': 200, 'max_samples': 0.5240448773695595, 'contamination': 0.43452388664754227, 'max_features': 0.7919207140149548}. Best is trial 2 with value: 0.9739610277634075.\n",
      "[I 2024-10-06 21:54:53,169] Trial 6 finished with value: 0.7950587282300526 and parameters: {'n_estimators': 114, 'max_samples': 0.7066596121312716, 'contamination': 0.3217469179110466, 'max_features': 0.7973021944558404}. Best is trial 2 with value: 0.9739610277634075.\n",
      "[I 2024-10-06 21:54:58,500] Trial 7 finished with value: 0.8886813597310422 and parameters: {'n_estimators': 260, 'max_samples': 0.7421983349711225, 'contamination': 0.1868520696414993, 'max_features': 0.8930547051056177}. Best is trial 2 with value: 0.9739610277634075.\n",
      "[I 2024-10-06 21:55:01,071] Trial 8 finished with value: 0.7259100642398287 and parameters: {'n_estimators': 124, 'max_samples': 0.9452298038822039, 'contamination': 0.41342240147246745, 'max_features': 0.8894668111796318}. Best is trial 2 with value: 0.9739610277634075.\n",
      "[I 2024-10-06 21:55:04,936] Trial 9 finished with value: 0.9173944687045124 and parameters: {'n_estimators': 185, 'max_samples': 0.8118834378602158, 'contamination': 0.1430365581837177, 'max_features': 0.931005287517774}. Best is trial 2 with value: 0.9739610277634075.\n",
      "[I 2024-10-06 21:55:09,417] Trial 10 finished with value: 0.9904988123515439 and parameters: {'n_estimators': 245, 'max_samples': 0.8642254194212065, 'contamination': 0.018329527236164968, 'max_features': 0.7040954474342587}. Best is trial 10 with value: 0.9904988123515439.\n",
      "[I 2024-10-06 21:55:13,938] Trial 11 finished with value: 0.9911834520176331 and parameters: {'n_estimators': 250, 'max_samples': 0.8517257351186874, 'contamination': 0.016324198821552595, 'max_features': 0.6936589802865923}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:55:18,087] Trial 12 finished with value: 0.9335006273525721 and parameters: {'n_estimators': 235, 'max_samples': 0.8949515651792769, 'contamination': 0.1122624552744533, 'max_features': 0.656784274891147}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:55:22,313] Trial 13 finished with value: 0.9875786966139186 and parameters: {'n_estimators': 237, 'max_samples': 0.8381918396646223, 'contamination': 0.021392500912025263, 'max_features': 0.6900692584926688}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:55:26,336] Trial 14 finished with value: 0.8938464398587098 and parameters: {'n_estimators': 232, 'max_samples': 0.9986690308772257, 'contamination': 0.17579033852677664, 'max_features': 0.6679403130308424}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:55:27,349] Trial 15 finished with value: 0.6468046395269502 and parameters: {'n_estimators': 52, 'max_samples': 0.830809098629533, 'contamination': 0.49678866003140976, 'max_features': 0.7330648149249261}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:55:29,962] Trial 16 finished with value: 0.9508023276318109 and parameters: {'n_estimators': 152, 'max_samples': 0.897005251103745, 'contamination': 0.08601303652162134, 'max_features': 0.6098239015127367}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:55:34,816] Trial 17 finished with value: 0.8636363636363636 and parameters: {'n_estimators': 261, 'max_samples': 0.7839575249394524, 'contamination': 0.23334624643275428, 'max_features': 0.7607526038170471}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:55:39,108] Trial 18 finished with value: 0.9911834520176331 and parameters: {'n_estimators': 220, 'max_samples': 0.8810928907688701, 'contamination': 0.01621656102300251, 'max_features': 0.8343951833031098}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:55:42,161] Trial 19 finished with value: 0.9455963140173667 and parameters: {'n_estimators': 159, 'max_samples': 0.9437402500165197, 'contamination': 0.0919677450478758, 'max_features': 0.8121367572822769}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:55:46,181] Trial 20 finished with value: 0.8540061633281972 and parameters: {'n_estimators': 204, 'max_samples': 0.7546638981240625, 'contamination': 0.24469046698890018, 'max_features': 0.843900062307414}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:55:50,162] Trial 21 finished with value: 0.9849880586830433 and parameters: {'n_estimators': 216, 'max_samples': 0.8761568892259842, 'contamination': 0.02436477619391053, 'max_features': 0.7189503691705258}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:55:54,448] Trial 22 finished with value: 0.9588801399825022 and parameters: {'n_estimators': 255, 'max_samples': 0.8638407749158644, 'contamination': 0.06765109447017492, 'max_features': 0.6209212693813468}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:55:59,600] Trial 23 finished with value: 0.9191643960036331 and parameters: {'n_estimators': 290, 'max_samples': 0.9405300094623243, 'contamination': 0.1405917805793893, 'max_features': 0.7105460395048471}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:56:03,778] Trial 24 finished with value: 0.962695152013147 and parameters: {'n_estimators': 228, 'max_samples': 0.9984464361889027, 'contamination': 0.01297994170683936, 'max_features': 0.7564079233432551}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:56:07,185] Trial 25 finished with value: 0.9261866089153582 and parameters: {'n_estimators': 170, 'max_samples': 0.7953329282594671, 'contamination': 0.12446782940867243, 'max_features': 0.8465934557260555}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:56:11,923] Trial 26 finished with value: 0.9599720328613879 and parameters: {'n_estimators': 271, 'max_samples': 0.9073706014270844, 'contamination': 0.0675165104379869, 'max_features': 0.6482870572620021}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:56:16,586] Trial 27 finished with value: 0.8822092804809318 and parameters: {'n_estimators': 246, 'max_samples': 0.9277173461966279, 'contamination': 0.19900342153688252, 'max_features': 0.7713777100420038}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:56:20,839] Trial 28 finished with value: 0.9215809284818067 and parameters: {'n_estimators': 216, 'max_samples': 0.8488852877246387, 'contamination': 0.01003111396423829, 'max_features': 0.8375813788971865}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:56:24,464] Trial 29 finished with value: 0.9429738852371646 and parameters: {'n_estimators': 220, 'max_samples': 0.7545551192975196, 'contamination': 0.09774691547428035, 'max_features': 0.5751335376618244}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:56:29,367] Trial 30 finished with value: 0.9637756879136189 and parameters: {'n_estimators': 272, 'max_samples': 0.9746441681972366, 'contamination': 0.05774300908971432, 'max_features': 0.6963174133939329}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:56:33,619] Trial 31 finished with value: 0.9783653846153846 and parameters: {'n_estimators': 244, 'max_samples': 0.8359020860070603, 'contamination': 0.033388240143949324, 'max_features': 0.674612040417474}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:56:37,745] Trial 32 finished with value: 0.9741379310344828 and parameters: {'n_estimators': 244, 'max_samples': 0.8691546466163766, 'contamination': 0.04129861127114048, 'max_features': 0.6189434108851792}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:56:43,061] Trial 33 finished with value: 0.956140350877193 and parameters: {'n_estimators': 300, 'max_samples': 0.8109021600439223, 'contamination': 0.07452331133145199, 'max_features': 0.685554031145499}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:56:46,866] Trial 34 finished with value: 0.9702479338842975 and parameters: {'n_estimators': 205, 'max_samples': 0.7780563574087537, 'contamination': 0.01058769217088405, 'max_features': 0.7224954992247745}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:56:51,518] Trial 35 finished with value: 0.8161559888579387 and parameters: {'n_estimators': 283, 'max_samples': 0.8430907155513057, 'contamination': 0.28981817397805004, 'max_features': 0.5614366984802782}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:56:55,006] Trial 36 finished with value: 0.9716557207051504 and parameters: {'n_estimators': 184, 'max_samples': 0.713187729847998, 'contamination': 0.043273944275700055, 'max_features': 0.7383486781454917}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:57:00,579] Trial 37 finished with value: 0.909057572423909 and parameters: {'n_estimators': 266, 'max_samples': 0.6004949823672625, 'contamination': 0.1560461910774039, 'max_features': 0.995311355868626}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:57:04,936] Trial 38 finished with value: 0.9319691258301921 and parameters: {'n_estimators': 248, 'max_samples': 0.9156416049032894, 'contamination': 0.1171451556866342, 'max_features': 0.6423653398014828}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:57:09,402] Trial 39 finished with value: 0.9744915546363323 and parameters: {'n_estimators': 231, 'max_samples': 0.8842044995459214, 'contamination': 0.038867010864739156, 'max_features': 0.7773834989240596}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:57:13,741] Trial 40 finished with value: 0.9635951924751786 and parameters: {'n_estimators': 200, 'max_samples': 0.8129066783453686, 'contamination': 0.05950310364811611, 'max_features': 0.9537438044947167}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:57:17,772] Trial 41 finished with value: 0.9813388118472864 and parameters: {'n_estimators': 218, 'max_samples': 0.8767718194757381, 'contamination': 0.028468850554123768, 'max_features': 0.7016298613247364}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:57:21,843] Trial 42 finished with value: 0.9489499192245557 and parameters: {'n_estimators': 210, 'max_samples': 0.8653013960796847, 'contamination': 0.011196827983213729, 'max_features': 0.8087129842993626}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:57:26,408] Trial 43 finished with value: 0.9470890107945497 and parameters: {'n_estimators': 225, 'max_samples': 0.8283951820925101, 'contamination': 0.08976540609656775, 'max_features': 0.8744610085339675}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:57:30,068] Trial 44 finished with value: 0.9773117909934685 and parameters: {'n_estimators': 193, 'max_samples': 0.9137272743697649, 'contamination': 0.034694814109496624, 'max_features': 0.723812405953862}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:57:34,442] Trial 45 finished with value: 0.7586063008554141 and parameters: {'n_estimators': 235, 'max_samples': 0.9629760195649885, 'contamination': 0.3650841298840074, 'max_features': 0.7478638064267777}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:57:39,019] Trial 46 finished with value: 0.9652173913043478 and parameters: {'n_estimators': 256, 'max_samples': 0.8504252378103933, 'contamination': 0.05437940271607741, 'max_features': 0.68428901385811}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:57:43,925] Trial 47 finished with value: 0.9359799713876967 and parameters: {'n_estimators': 279, 'max_samples': 0.8900902717873753, 'contamination': 0.10924106644459075, 'max_features': 0.6343673439157815}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:57:47,116] Trial 48 finished with value: 0.9533861037818822 and parameters: {'n_estimators': 176, 'max_samples': 0.7275376048792098, 'contamination': 0.07805948303951178, 'max_features': 0.6624610717678686}. Best is trial 11 with value: 0.9911834520176331.\n",
      "[I 2024-10-06 21:57:51,666] Trial 49 finished with value: 0.9855072463768116 and parameters: {'n_estimators': 238, 'max_samples': 0.6774365812866697, 'contamination': 0.023861268824058358, 'max_features': 0.7877080329748082}. Best is trial 11 with value: 0.9911834520176331.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 250, 'max_samples': 0.8517257351186874, 'contamination': 0.016324198821552595, 'max_features': 0.6936589802865923}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)  \n",
    "    max_samples = trial.suggest_float('max_samples', 0.5, 1.0)  \n",
    "    contamination = trial.suggest_float('contamination', 0.01, 0.5) \n",
    "    max_features = trial.suggest_float('max_features', 0.5, 1.0)\n",
    "\n",
    "    iso_forest = IsolationForest(n_estimators=n_estimators, \n",
    "                                 max_samples=max_samples, \n",
    "                                 contamination=contamination, \n",
    "                                 max_features=max_features, \n",
    "                                 random_state=42)\n",
    "\n",
    "    iso_forest.fit(train_latent_features)\n",
    "    \n",
    "    val_predictions = iso_forest.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 1, -1)\n",
    "\n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=1, average='binary')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a3644c6-1377-47c0-8ee4-c20004ebfbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9994\n",
      "Test Precision: 1.0000\n",
      "Test Recall: 0.9809\n",
      "Test F1 Score: 0.9904\n"
     ]
    }
   ],
   "source": [
    "best_iso_forest = IsolationForest(n_estimators=best_params['n_estimators'], \n",
    "                                  max_samples=best_params['max_samples'], \n",
    "                                  contamination=best_params['contamination'], \n",
    "                                  max_features=best_params['max_features'], \n",
    "                                  random_state=42)\n",
    "\n",
    "best_iso_forest.fit(train_latent_features)\n",
    "test_predictions = best_iso_forest.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 1, -1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ef4cde-53bb-4472-bd95-1bb2f7006af8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# PCA Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24b7360e-1ebb-4321-9001-47d18424a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c1875ce-4f29-4126-b38f-d1ac2f46ccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 21:45:07,540] A new study created in memory with name: no-name-4b18c0c0-f91b-4f6a-bc0e-8ce6082fa2cd\n",
      "[I 2024-10-06 21:45:08,024] Trial 0 finished with value: 0.9951021786860328 and parameters: {'n_components': 12, 'percentile': 99.0548960557335}. Best is trial 0 with value: 0.9951021786860328.\n",
      "[I 2024-10-06 21:45:08,170] Trial 1 finished with value: 0.9838414126270199 and parameters: {'n_components': 30, 'percentile': 99.31137426890074}. Best is trial 0 with value: 0.9951021786860328.\n",
      "[I 2024-10-06 21:45:08,447] Trial 2 finished with value: 0.9581509367886535 and parameters: {'n_components': 10, 'percentile': 92.45417905922538}. Best is trial 0 with value: 0.9951021786860328.\n",
      "[I 2024-10-06 21:45:08,630] Trial 3 finished with value: 0.9427860696517413 and parameters: {'n_components': 11, 'percentile': 90.19347730839459}. Best is trial 0 with value: 0.9951021786860328.\n",
      "[I 2024-10-06 21:45:08,757] Trial 4 finished with value: 0.9677307425399029 and parameters: {'n_components': 23, 'percentile': 94.42857118006403}. Best is trial 0 with value: 0.9951021786860328.\n",
      "[I 2024-10-06 21:45:08,894] Trial 5 finished with value: 0.9961194533490805 and parameters: {'n_components': 13, 'percentile': 99.33718440376941}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:09,023] Trial 6 finished with value: 0.9557739557739557 and parameters: {'n_components': 4, 'percentile': 92.2081270188922}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:09,226] Trial 7 finished with value: 0.9879231161762204 and parameters: {'n_components': 26, 'percentile': 97.81574337867384}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:09,381] Trial 8 finished with value: 0.9588801399825022 and parameters: {'n_components': 29, 'percentile': 92.72455980084091}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:09,531] Trial 9 finished with value: 0.9819348303224718 and parameters: {'n_components': 30, 'percentile': 97.94048230390118}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:09,673] Trial 10 finished with value: 0.9769601100412655 and parameters: {'n_components': 19, 'percentile': 96.10442324941685}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:09,836] Trial 11 finished with value: 0.7485836585672919 and parameters: {'n_components': 13, 'percentile': 99.86904749370449}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:10,005] Trial 12 finished with value: 0.9870616275110657 and parameters: {'n_components': 5, 'percentile': 97.37520347217205}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:10,165] Trial 13 finished with value: 0.9737840634701621 and parameters: {'n_components': 17, 'percentile': 95.87412395409518}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:10,350] Trial 14 finished with value: 0.9923793395427604 and parameters: {'n_components': 17, 'percentile': 98.84461270939508}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:10,496] Trial 15 finished with value: 0.9806407401062189 and parameters: {'n_components': 9, 'percentile': 96.40453117159706}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:10,636] Trial 16 finished with value: 0.9677307425399029 and parameters: {'n_components': 14, 'percentile': 94.3498787777494}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:10,771] Trial 17 finished with value: 0.9913544668587896 and parameters: {'n_components': 7, 'percentile': 98.54867928149514}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:10,942] Trial 18 finished with value: 0.9837745516652434 and parameters: {'n_components': 21, 'percentile': 96.97034184478075}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:11,080] Trial 19 finished with value: 0.20883138799043735 and parameters: {'n_components': 2, 'percentile': 99.84860334423477}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:11,219] Trial 20 finished with value: 0.9720110573600553 and parameters: {'n_components': 14, 'percentile': 95.33440346038395}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:11,356] Trial 21 finished with value: 0.9922086720867209 and parameters: {'n_components': 16, 'percentile': 98.7246644739612}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:11,520] Trial 22 finished with value: 0.9908412483039348 and parameters: {'n_components': 19, 'percentile': 98.70486888784458}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:11,656] Trial 23 finished with value: 0.993912749408184 and parameters: {'n_components': 12, 'percentile': 98.88826634900937}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:11,805] Trial 24 finished with value: 0.9882673014793403 and parameters: {'n_components': 8, 'percentile': 97.71129101537828}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:11,945] Trial 25 finished with value: 0.9961194533490805 and parameters: {'n_components': 12, 'percentile': 99.37883855074368}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:12,083] Trial 26 finished with value: 0.9830798154161682 and parameters: {'n_components': 7, 'percentile': 97.03585700504908}. Best is trial 5 with value: 0.9961194533490805.\n",
      "[I 2024-10-06 21:45:12,221] Trial 27 finished with value: 0.9969656102494943 and parameters: {'n_components': 15, 'percentile': 99.53809306019872}. Best is trial 27 with value: 0.9969656102494943.\n",
      "[I 2024-10-06 21:45:12,385] Trial 28 finished with value: 0.9991589571068125 and parameters: {'n_components': 23, 'percentile': 99.81924259670136}. Best is trial 28 with value: 0.9991589571068125.\n",
      "[I 2024-10-06 21:45:12,513] Trial 29 finished with value: 0.9896417048734929 and parameters: {'n_components': 22, 'percentile': 98.10265617687358}. Best is trial 28 with value: 0.9991589571068125.\n",
      "[I 2024-10-06 21:45:12,643] Trial 30 finished with value: 0.9991600873509155 and parameters: {'n_components': 25, 'percentile': 99.89039759436925}. Best is trial 30 with value: 0.9991600873509155.\n",
      "[I 2024-10-06 21:45:12,773] Trial 31 finished with value: 0.9993272788429196 and parameters: {'n_components': 26, 'percentile': 99.84689895110925}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:12,948] Trial 32 finished with value: 0.9984851035179263 and parameters: {'n_components': 26, 'percentile': 99.68000755673887}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:13,123] Trial 33 finished with value: 0.9993272788429196 and parameters: {'n_components': 26, 'percentile': 99.84546021761177}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:13,257] Trial 34 finished with value: 0.0619708198728912 and parameters: {'n_components': 32, 'percentile': 98.38375603789576}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:13,431] Trial 35 finished with value: 0.9450354609929078 and parameters: {'n_components': 25, 'percentile': 90.03786303839748}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:13,607] Trial 36 finished with value: 0.9949324324324325 and parameters: {'n_components': 24, 'percentile': 99.18089678820846}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:13,781] Trial 37 finished with value: 0.9626917712691772 and parameters: {'n_components': 28, 'percentile': 93.21435371107005}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:13,947] Trial 38 finished with value: 0.9961194533490805 and parameters: {'n_components': 27, 'percentile': 99.21185185103403}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:14,110] Trial 39 finished with value: 0.9882673014793403 and parameters: {'n_components': 20, 'percentile': 98.396896419193}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:14,276] Trial 40 finished with value: 0.9511722192843293 and parameters: {'n_components': 23, 'percentile': 91.54820425693045}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:14,465] Trial 41 finished with value: 0.9991589571068125 and parameters: {'n_components': 26, 'percentile': 99.77348737973108}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:14,659] Trial 42 finished with value: 0.7216545012165451 and parameters: {'n_components': 31, 'percentile': 99.77656750719119}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:14,836] Trial 43 finished with value: 0.9957834373418789 and parameters: {'n_components': 29, 'percentile': 99.27706779361249}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:15,003] Trial 44 finished with value: 0.993912749408184 and parameters: {'n_components': 25, 'percentile': 99.05762713723618}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:15,179] Trial 45 finished with value: 0.9906700593723494 and parameters: {'n_components': 28, 'percentile': 98.16498230690783}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:15,347] Trial 46 finished with value: 0.9993272788429196 and parameters: {'n_components': 23, 'percentile': 99.83069212802839}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:15,537] Trial 47 finished with value: 0.9860259032038173 and parameters: {'n_components': 22, 'percentile': 97.52289548324997}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:15,756] Trial 48 finished with value: 0.9966273187183811 and parameters: {'n_components': 24, 'percentile': 99.34373613315137}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:15,931] Trial 49 finished with value: 0.968625411683134 and parameters: {'n_components': 19, 'percentile': 94.48880699782572}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:16,097] Trial 50 finished with value: 0.9832775919732442 and parameters: {'n_components': 30, 'percentile': 98.87948598918153}. Best is trial 31 with value: 0.9993272788429196.\n",
      "[I 2024-10-06 21:45:16,261] Trial 51 finished with value: 0.9993275050437121 and parameters: {'n_components': 26, 'percentile': 99.888456047197}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:16,427] Trial 52 finished with value: 0.9991592399529174 and parameters: {'n_components': 27, 'percentile': 99.85300601110275}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:16,608] Trial 53 finished with value: 0.9976502181940249 and parameters: {'n_components': 27, 'percentile': 99.8985707263105}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:16,773] Trial 54 finished with value: 0.9971356360572873 and parameters: {'n_components': 28, 'percentile': 99.46400107896824}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:16,947] Trial 55 finished with value: 0.991867163673331 and parameters: {'n_components': 25, 'percentile': 98.52252002250857}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:17,107] Trial 56 finished with value: 0.9465297450424929 and parameters: {'n_components': 27, 'percentile': 91.08915363710642}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:17,275] Trial 57 finished with value: 0.9942567567567567 and parameters: {'n_components': 29, 'percentile': 98.9745785215268}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:17,424] Trial 58 finished with value: 0.9967964930028663 and parameters: {'n_components': 21, 'percentile': 99.45384456544738}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:17,596] Trial 59 finished with value: 0.9884393063583815 and parameters: {'n_components': 26, 'percentile': 97.91684441664597}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:17,766] Trial 60 finished with value: 0.993061431714334 and parameters: {'n_components': 24, 'percentile': 98.64252104929842}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:17,934] Trial 61 finished with value: 0.9984851035179263 and parameters: {'n_components': 23, 'percentile': 99.64208158050512}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:18,100] Trial 62 finished with value: 0.9952718676122931 and parameters: {'n_components': 22, 'percentile': 99.0777831108274}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:18,283] Trial 63 finished with value: 0.9991589571068125 and parameters: {'n_components': 25, 'percentile': 99.8131925813822}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:18,452] Trial 64 finished with value: 0.9827299900365327 and parameters: {'n_components': 30, 'percentile': 99.45417791526692}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:18,632] Trial 65 finished with value: 0.9993272788429196 and parameters: {'n_components': 24, 'percentile': 99.8686051577133}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:18,808] Trial 66 finished with value: 0.9940828402366864 and parameters: {'n_components': 27, 'percentile': 98.8681746048002}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:18,978] Trial 67 finished with value: 0.9896417048734929 and parameters: {'n_components': 21, 'percentile': 98.19695179812452}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:19,145] Trial 68 finished with value: 0.9976415094339622 and parameters: {'n_components': 24, 'percentile': 99.50712550760285}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:19,310] Trial 69 finished with value: 0.9605171208944794 and parameters: {'n_components': 26, 'percentile': 93.26342298661268}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:19,454] Trial 70 finished with value: 0.0616451228934784 and parameters: {'n_components': 32, 'percentile': 99.12875151883559}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:19,636] Trial 71 finished with value: 0.9993272788429196 and parameters: {'n_components': 24, 'percentile': 99.84265545400416}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:19,818] Trial 72 finished with value: 0.9978110793062805 and parameters: {'n_components': 28, 'percentile': 99.5829160921391}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:19,979] Trial 73 finished with value: 0.9951021786860328 and parameters: {'n_components': 25, 'percentile': 99.20869966237814}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:20,137] Trial 74 finished with value: 0.9993272788429196 and parameters: {'n_components': 23, 'percentile': 99.86470143567506}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:20,310] Trial 75 finished with value: 0.9993275050437121 and parameters: {'n_components': 18, 'percentile': 99.88954545364979}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:20,488] Trial 76 finished with value: 0.9906700593723494 and parameters: {'n_components': 18, 'percentile': 98.72460984822912}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:20,665] Trial 77 finished with value: 0.9973036737445231 and parameters: {'n_components': 20, 'percentile': 99.55548849297936}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:20,831] Trial 78 finished with value: 0.9962887989203779 and parameters: {'n_components': 22, 'percentile': 99.26374594303867}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:21,003] Trial 79 finished with value: 0.9908412483039348 and parameters: {'n_components': 23, 'percentile': 98.38134211447917}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:21,142] Trial 80 finished with value: 0.9787161002403021 and parameters: {'n_components': 16, 'percentile': 96.66871032028898}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:21,321] Trial 81 finished with value: 0.9993275050437121 and parameters: {'n_components': 24, 'percentile': 99.87954163442363}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:21,495] Trial 82 finished with value: 0.998653651969034 and parameters: {'n_components': 23, 'percentile': 99.64994416179373}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:21,655] Trial 83 finished with value: 0.9937426010485371 and parameters: {'n_components': 18, 'percentile': 98.99608094103252}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:21,842] Trial 84 finished with value: 0.9962887989203779 and parameters: {'n_components': 24, 'percentile': 99.31662457419148}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:22,014] Trial 85 finished with value: 0.9767841788478074 and parameters: {'n_components': 21, 'percentile': 95.61854841663698}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:22,187] Trial 86 finished with value: 0.9976415094339622 and parameters: {'n_components': 26, 'percentile': 99.62208815003387}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:22,350] Trial 87 finished with value: 0.9991595226088418 and parameters: {'n_components': 20, 'percentile': 99.89247115773584}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:22,540] Trial 88 finished with value: 0.993061431714334 and parameters: {'n_components': 22, 'percentile': 98.73975225281607}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:22,714] Trial 89 finished with value: 0.9966273187183811 and parameters: {'n_components': 24, 'percentile': 99.35627054907081}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:22,855] Trial 90 finished with value: 0.9952718676122931 and parameters: {'n_components': 10, 'percentile': 99.12096397642938}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:23,043] Trial 91 finished with value: 0.9989905787348586 and parameters: {'n_components': 25, 'percentile': 99.69023400733364}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:23,221] Trial 92 finished with value: 0.9991589571068125 and parameters: {'n_components': 26, 'percentile': 99.81218917689405}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:23,397] Trial 93 finished with value: 0.997134670487106 and parameters: {'n_components': 24, 'percentile': 99.4592396114064}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:23,579] Trial 94 finished with value: 0.9935723951285521 and parameters: {'n_components': 25, 'percentile': 98.98571223545675}. Best is trial 51 with value: 0.9993275050437121.\n",
      "[I 2024-10-06 21:45:23,749] Trial 95 finished with value: 0.9996637525218561 and parameters: {'n_components': 23, 'percentile': 99.88986337834315}. Best is trial 95 with value: 0.9996637525218561.\n",
      "[I 2024-10-06 21:45:23,927] Trial 96 finished with value: 0.9981478363360835 and parameters: {'n_components': 23, 'percentile': 99.60189929297312}. Best is trial 95 with value: 0.9996637525218561.\n",
      "[I 2024-10-06 21:45:24,110] Trial 97 finished with value: 0.9967964930028663 and parameters: {'n_components': 22, 'percentile': 99.31959564792454}. Best is trial 95 with value: 0.9996637525218561.\n",
      "[I 2024-10-06 21:45:24,287] Trial 98 finished with value: 0.991867163673331 and parameters: {'n_components': 23, 'percentile': 98.5481904975855}. Best is trial 95 with value: 0.9996637525218561.\n",
      "[I 2024-10-06 21:45:24,453] Trial 99 finished with value: 0.9978103419235304 and parameters: {'n_components': 27, 'percentile': 99.690799723121}. Best is trial 95 with value: 0.9996637525218561.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_components': 23, 'percentile': 99.88986337834315}\n"
     ]
    }
   ],
   "source": [
    "def reconstruction_error(X, pca):\n",
    "    X_pca = pca.transform(X)\n",
    "    X_reconstructed = pca.inverse_transform(X_pca)\n",
    "    return np.mean((X - X_reconstructed) ** 2, axis=1)\n",
    "    \n",
    "def objective(trial):\n",
    "    n_components = trial.suggest_int('n_components', 2, min(train_latent_features.shape[1], 50))\n",
    "    percentile = trial.suggest_float('percentile', 90.0, 99.9)  \n",
    "\n",
    "    pca = PCA(n_components=n_components, whiten=True, svd_solver='auto')\n",
    "\n",
    "    normal_data_pca = pca.fit_transform(train_latent_features)\n",
    "    normal_data_reconstructed = pca.inverse_transform(normal_data_pca)\n",
    "\n",
    "    reconstruction_errors = np.mean((train_latent_features - normal_data_reconstructed) ** 2, axis=1)\n",
    "    threshold = np.percentile(reconstruction_errors, percentile)\n",
    "    val_reconstruction_errors = reconstruction_error(val_latent_features, pca)\n",
    "    val_predictions = np.where(val_reconstruction_errors > threshold, -1, 1)\n",
    "\n",
    "    val_true_labels = np.where(y_val == 0, 1, -1)\n",
    "\n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=1, average='binary')\n",
    "\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "283e41bb-dbaa-40ff-b9a8-593c994a7314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0000\n",
      "Test Precision: 1.0000\n",
      "Test Recall: 0.9992\n",
      "Test F1 Score: 0.9996\n"
     ]
    }
   ],
   "source": [
    "best_pca = PCA(n_components=best_params['n_components'], whiten=True, svd_solver='auto')\n",
    "\n",
    "normal_data_pca = best_pca.fit_transform(train_latent_features)\n",
    "normal_data_reconstructed = best_pca.inverse_transform(normal_data_pca)\n",
    "\n",
    "reconstruction_errors = np.mean((train_latent_features - normal_data_reconstructed) ** 2, axis=1)\n",
    "\n",
    "threshold = np.percentile(reconstruction_errors, best_params['percentile'])\n",
    "\n",
    "test_pca = best_pca.transform(test_latent_features)\n",
    "test_reconstructed = best_pca.inverse_transform(test_pca)\n",
    "test_reconstruction_errors = np.mean((test_latent_features - test_reconstructed) ** 2, axis=1)\n",
    "\n",
    "test_predictions = np.where(test_reconstruction_errors > threshold, -1, 1) \n",
    "\n",
    "test_true_labels = np.where(y_test == 0, 1, -1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a10a22-863d-4329-8b37-625a88390c9f",
   "metadata": {},
   "source": [
    "# SLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2577f03-0cbc-4b7c-80a1-66dccd34acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import SLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c95fef30-c09f-4386-b4f4-e723a00c3ac8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:09:17,097] A new study created in memory with name: no-name-5638df5c-6ce7-4c30-a734-d1db508714eb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 18\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.546880, time: 0.8s\n",
      "epoch 10, training loss: 0.525268, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:10:16,255] Trial 0 finished with value: 0.9420341394025604 and parameters: {'epochs': 19, 'hidden_dims': 85, 'n_slad_ensemble': 18}. Best is trial 0 with value: 0.9420341394025604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.574282, time: 0.5s\n",
      "epoch 10, training loss: 0.555246, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:11:27,673] Trial 1 finished with value: 0.9416577730345073 and parameters: {'epochs': 19, 'hidden_dims': 121, 'n_slad_ensemble': 20}. Best is trial 0 with value: 0.9420341394025604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 46\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.604720, time: 0.5s\n",
      "epoch 10, training loss: 0.575029, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:13:35,592] Trial 2 finished with value: 0.9450354609929078 and parameters: {'epochs': 18, 'hidden_dims': 112, 'n_slad_ensemble': 46}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 27\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.602454, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:14:48,645] Trial 3 finished with value: 0.9437244807385052 and parameters: {'epochs': 4, 'hidden_dims': 61, 'n_slad_ensemble': 27}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 43\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.614494, time: 0.5s\n",
      "epoch 10, training loss: 0.576331, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:16:57,551] Trial 4 finished with value: 0.9420341394025604 and parameters: {'epochs': 16, 'hidden_dims': 88, 'n_slad_ensemble': 43}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 11\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.549502, time: 0.7s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:17:34,613] Trial 5 finished with value: 0.940149625935162 and parameters: {'epochs': 5, 'hidden_dims': 85, 'n_slad_ensemble': 11}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 15\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.631303, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:18:24,721] Trial 6 finished with value: 0.9384478144513827 and parameters: {'epochs': 8, 'hidden_dims': 140, 'n_slad_ensemble': 15}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 46\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.606754, time: 0.5s\n",
      "epoch 10, training loss: 0.575114, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:20:47,051] Trial 7 finished with value: 0.9437244807385052 and parameters: {'epochs': 19, 'hidden_dims': 93, 'n_slad_ensemble': 46}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 28\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.603501, time: 0.6s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:22:14,489] Trial 8 finished with value: 0.9448483773718744 and parameters: {'epochs': 4, 'hidden_dims': 124, 'n_slad_ensemble': 28}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 50\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.570713, time: 0.5s\n",
      "epoch 10, training loss: 0.537132, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:24:24,971] Trial 9 finished with value: 0.9433493162848517 and parameters: {'epochs': 17, 'hidden_dims': 116, 'n_slad_ensemble': 50}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 38\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.614227, time: 0.6s\n",
      "epoch 10, training loss: 0.578234, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:26:23,448] Trial 10 finished with value: 0.9429738852371646 and parameters: {'epochs': 12, 'hidden_dims': 57, 'n_slad_ensemble': 38}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 32\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.605320, time: 0.7s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:28:02,578] Trial 11 finished with value: 0.9414694894146949 and parameters: {'epochs': 1, 'hidden_dims': 147, 'n_slad_ensemble': 32}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 28\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.605510, time: 0.5s\n",
      "epoch 10, training loss: 0.582747, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:29:36,005] Trial 12 finished with value: 0.9439119630812921 and parameters: {'epochs': 12, 'hidden_dims': 120, 'n_slad_ensemble': 28}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 35\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.611072, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:31:13,899] Trial 13 finished with value: 0.9429738852371646 and parameters: {'epochs': 9, 'hidden_dims': 109, 'n_slad_ensemble': 35}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 25\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.528649, time: 0.5s\n",
      "epoch 10, training loss: 0.507894, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:32:27,350] Trial 14 finished with value: 0.9424102381798791 and parameters: {'epochs': 14, 'hidden_dims': 135, 'n_slad_ensemble': 25}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 39\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.565083, time: 0.6s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:34:15,093] Trial 15 finished with value: 0.9437244807385052 and parameters: {'epochs': 6, 'hidden_dims': 132, 'n_slad_ensemble': 39}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 32\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.607866, time: 0.6s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:35:48,062] Trial 16 finished with value: 0.9437244807385052 and parameters: {'epochs': 3, 'hidden_dims': 102, 'n_slad_ensemble': 32}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 24\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.544181, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:37:04,659] Trial 17 finished with value: 0.9409042363830544 and parameters: {'epochs': 8, 'hidden_dims': 127, 'n_slad_ensemble': 24}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 42\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.577456, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:39:07,427] Trial 18 finished with value: 0.934612031386225 and parameters: {'epochs': 1, 'hidden_dims': 73, 'n_slad_ensemble': 42}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 50\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.572632, time: 0.5s\n",
      "epoch 10, training loss: 0.537129, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:41:49,310] Trial 19 finished with value: 0.9420341394025604 and parameters: {'epochs': 15, 'hidden_dims': 105, 'n_slad_ensemble': 50}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 22\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.552064, time: 0.5s\n",
      "epoch 10, training loss: 0.534214, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:42:57,323] Trial 20 finished with value: 0.9427860696517413 and parameters: {'epochs': 11, 'hidden_dims': 148, 'n_slad_ensemble': 22}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 30\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.605949, time: 0.6s\n",
      "epoch 10, training loss: 0.582007, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:44:36,938] Trial 21 finished with value: 0.9439119630812921 and parameters: {'epochs': 13, 'hidden_dims': 116, 'n_slad_ensemble': 30}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 28\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.605358, time: 0.6s\n",
      "epoch 10, training loss: 0.582842, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:46:07,181] Trial 22 finished with value: 0.9437244807385052 and parameters: {'epochs': 10, 'hidden_dims': 125, 'n_slad_ensemble': 28}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 35\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.609375, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:47:54,870] Trial 23 finished with value: 0.9418459896852214 and parameters: {'epochs': 7, 'hidden_dims': 112, 'n_slad_ensemble': 35}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 35\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.612610, time: 0.6s\n",
      "epoch 10, training loss: 0.586125, time: 0.6s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:49:54,456] Trial 24 finished with value: 0.9414694894146949 and parameters: {'epochs': 17, 'hidden_dims': 100, 'n_slad_ensemble': 35}. Best is trial 2 with value: 0.9450354609929078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 28\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.604424, time: 0.6s\n",
      "epoch 10, training loss: 0.582741, time: 0.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-06 22:50:39,122] Trial 25 failed with parameters: {'epochs': 11, 'hidden_dims': 136, 'n_slad_ensemble': 28} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_165/313744358.py\", line 13, in objective\n",
      "    val_predictions = slad_model.predict(val_latent_features)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/deepod/core/base_model.py\", line 264, in predict\n",
      "    pred_score = self.decision_function(X)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/deepod/models/tabular/slad.py\", line 118, in decision_function\n",
      "    for batch_x in test_loader:\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
      "    self._IterableDataset_len_called is not None and \\\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 675, in _next_data\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
      "    )\n",
      "      \n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
      "    )\n",
      "      \n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 209, in __getitem__\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 209, in <genexpr>\n",
      "KeyboardInterrupt\n",
      "[W 2024-10-06 22:50:39,128] Trial 25 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f1\n\u001b[1;32m     19\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[44], line 13\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      6\u001b[0m slad_model \u001b[38;5;241m=\u001b[39m SLAD(epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m      7\u001b[0m                   hidden_dims\u001b[38;5;241m=\u001b[39mhidden_dims,\n\u001b[1;32m      8\u001b[0m                   n_slad_ensemble\u001b[38;5;241m=\u001b[39mn_slad_ensemble,\n\u001b[1;32m      9\u001b[0m                   random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     11\u001b[0m slad_model\u001b[38;5;241m.\u001b[39mfit(train_latent_features)\n\u001b[0;32m---> 13\u001b[0m val_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mslad_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_latent_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m val_true_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y_val \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(val_true_labels, val_predictions, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/deepod/core/base_model.py:264\u001b[0m, in \u001b[0;36mBaseDeepAD.predict\u001b[0;34m(self, X, return_confidence)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, return_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict if a particular sample is an outlier or not.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m        Only if return_confidence is set to True.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m     pred_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m (pred_score \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold_)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_confidence:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/deepod/models/tabular/slad.py:118\u001b[0m, in \u001b[0;36mSLAD.decision_function\u001b[0;34m(self, X, return_rep)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    117\u001b[0m     score_lst \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 118\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_lst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m--> 631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n\u001b[1;32m    633\u001b[0m     warn_msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of IterableDataset \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was reported to be \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m (when accessing len(dataloader)), but \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    634\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples have been fetched. \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called,\n\u001b[1;32m    635\u001b[0m                                                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded)\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, auto_collation, collate_fn, drop_last):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_MapDatasetFetcher, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     50\u001b[0m         dataset, auto_collation, collate_fn, drop_last\n\u001b[0;32m---> 51\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, auto_collation, collate_fn, drop_last):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_MapDatasetFetcher, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     50\u001b[0m         dataset, auto_collation, collate_fn, drop_last\n\u001b[0;32m---> 51\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataset.py:209\u001b[0m, in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataset.py:209\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    epochs = trial.suggest_int('epochs', 1, 20)\n",
    "    hidden_dims = trial.suggest_int('hidden_dims', 50, 150)\n",
    "    n_slad_ensemble = trial.suggest_int('n_slad_ensemble', 10, 50)\n",
    "\n",
    "    slad_model = SLAD(epochs=epochs,\n",
    "                      hidden_dims=hidden_dims,\n",
    "                      n_slad_ensemble=n_slad_ensemble,\n",
    "                      random_state=42)\n",
    "\n",
    "    slad_model.fit(train_latent_features)\n",
    "    \n",
    "    val_predictions = slad_model.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 0, 1)\n",
    "    \n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=0, average='binary')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "434d901b-e83b-4c99-806f-4ca25d705522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 32, ensemble size: 46\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "epoch  1, training loss: 0.604720, time: 0.5s\n",
      "epoch 10, training loss: 0.575029, time: 0.6s\n",
      "Start Inference on the training data...\n",
      "Test Accuracy: 0.9967\n",
      "Test Precision: 0.9966\n",
      "Test Recall: 1.0000\n",
      "Test F1 Score: 0.9983\n"
     ]
    }
   ],
   "source": [
    "best_slad_model = SLAD(epochs=best_params['epochs'],\n",
    "                      hidden_dims=best_params['hidden_dims'],\n",
    "                      n_slad_ensemble=best_params['n_slad_ensemble'],\n",
    "                      random_state=42)\n",
    "\n",
    "best_slad_model.fit(train_latent_features)\n",
    "test_predictions = best_slad_model.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af788c-a570-4474-bbad-4dde854db763",
   "metadata": {},
   "source": [
    "# ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b87cd445-45a2-45e6-80aa-78576c8acefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81d5bccf-e83b-425b-a33c-86b33bf2bf5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 23:23:19,739] A new study created in memory with name: no-name-e8bc4f88-11e5-4639-9142-9081f1e932a0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.977962, time: 1.1s\n",
      "epoch 10, training loss: 0.016990, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.144904, time: 1.0s\n",
      "epoch 10, training loss: 0.024965, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.007313, time: 1.0s\n",
      "epoch 10, training loss: 0.023104, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 424.44it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 425.99it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 424.00it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 395.67it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 426.71it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 426.26it/s]\n",
      "[I 2024-10-06 23:24:22,499] Trial 0 finished with value: 0.9472753007784855 and parameters: {'epochs': 17, 'rep_dim': 81, 'temperature': 0.0760299845415369}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=107, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=107, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.931543, time: 1.0s\n",
      "epoch 10, training loss: 0.012359, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=107, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=107, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.084916, time: 1.0s\n",
      "epoch 10, training loss: 0.020836, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=107, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=107, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.911327, time: 1.0s\n",
      "epoch 10, training loss: 0.012301, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 428.26it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 430.69it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.83it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 398.70it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 429.69it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 430.39it/s]\n",
      "[I 2024-10-06 23:25:16,293] Trial 1 finished with value: 0.9416577730345073 and parameters: {'epochs': 14, 'rep_dim': 107, 'temperature': 0.07259122025301018}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=120, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=120, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.076359, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=120, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=120, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.916763, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=120, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=120, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.931595, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.78it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.96it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 431.49it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 399.75it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 431.39it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 431.02it/s]\n",
      "[I 2024-10-06 23:25:40,284] Trial 2 finished with value: 0.9442867281760113 and parameters: {'epochs': 4, 'rep_dim': 120, 'temperature': 0.0766664466294853}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=123, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=123, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.068955, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=123, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=123, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.096130, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=123, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=123, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.170599, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 427.89it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.29it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.01it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 398.32it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 428.79it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 428.11it/s]\n",
      "[I 2024-10-06 23:26:07,333] Trial 3 finished with value: 0.9437244807385052 and parameters: {'epochs': 5, 'rep_dim': 123, 'temperature': 0.04544801196510964}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=106, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=106, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 4.168003, time: 1.0s\n",
      "epoch 10, training loss: 0.042935, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=106, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=106, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 3.123611, time: 1.0s\n",
      "epoch 10, training loss: 0.050678, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=106, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=106, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 4.182095, time: 1.0s\n",
      "epoch 10, training loss: 0.046395, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.39it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 427.39it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 427.82it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 397.38it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 394.77it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 424.91it/s]\n",
      "[I 2024-10-06 23:26:55,530] Trial 4 finished with value: 0.9444740109987582 and parameters: {'epochs': 12, 'rep_dim': 106, 'temperature': 0.006371459908374069}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=89, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=89, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.062504, time: 1.0s\n",
      "epoch 10, training loss: 0.015328, time: 1.0s\n",
      "epoch 20, training loss: 0.008720, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=89, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=89, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.219382, time: 1.0s\n",
      "epoch 10, training loss: 0.045529, time: 1.0s\n",
      "epoch 20, training loss: 0.008698, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=89, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=89, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.074838, time: 1.0s\n",
      "epoch 10, training loss: 0.016221, time: 1.0s\n",
      "epoch 20, training loss: 0.009236, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.62it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 431.38it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 432.74it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 403.06it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 432.18it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 432.38it/s]\n",
      "[I 2024-10-06 23:28:07,850] Trial 5 finished with value: 0.9439119630812921 and parameters: {'epochs': 20, 'rep_dim': 89, 'temperature': 0.06439632148942298}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=64, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=64, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.971719, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=64, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=64, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.075491, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=64, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=64, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.960277, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 425.08it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 427.01it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 427.97it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 396.04it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 427.30it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 427.54it/s]\n",
      "[I 2024-10-06 23:28:31,998] Trial 6 finished with value: 0.9422222222222222 and parameters: {'epochs': 4, 'rep_dim': 64, 'temperature': 0.09312711821623763}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=68, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=68, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.212229, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=68, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=68, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.374729, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=68, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=68, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.134042, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 424.60it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 427.16it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 428.24it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 395.37it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 427.34it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 426.85it/s]\n",
      "[I 2024-10-06 23:29:05,169] Trial 7 finished with value: 0.9437244807385052 and parameters: {'epochs': 7, 'rep_dim': 68, 'temperature': 0.03579768469081826}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=115, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=115, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.894028, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=115, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=115, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.879942, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=115, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=115, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.015622, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.87it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 428.09it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.58it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 397.18it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 429.18it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 429.30it/s]\n",
      "[I 2024-10-06 23:29:38,283] Trial 8 finished with value: 0.9399608052734723 and parameters: {'epochs': 7, 'rep_dim': 115, 'temperature': 0.015152460304907509}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=59, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=59, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.246714, time: 1.0s\n",
      "epoch 10, training loss: 0.020210, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=59, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=59, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.139315, time: 1.0s\n",
      "epoch 10, training loss: 0.025434, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=59, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=59, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.067532, time: 1.0s\n",
      "epoch 10, training loss: 0.024247, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 423.37it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.31it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.79it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 394.63it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 426.96it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 429.76it/s]\n",
      "[I 2024-10-06 23:30:29,188] Trial 9 finished with value: 0.9412811387900356 and parameters: {'epochs': 13, 'rep_dim': 59, 'temperature': 0.05471622804229905}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=149, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=149, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.901904, time: 1.0s\n",
      "epoch 10, training loss: 0.012082, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=149, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=149, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.941494, time: 1.0s\n",
      "epoch 10, training loss: 0.011680, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=149, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=149, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.046349, time: 1.0s\n",
      "epoch 10, training loss: 0.035361, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 427.93it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 430.63it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 431.42it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 397.52it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 430.68it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 430.45it/s]\n",
      "[I 2024-10-06 23:31:37,905] Trial 10 finished with value: 0.9454094292803971 and parameters: {'epochs': 19, 'rep_dim': 149, 'temperature': 0.09442691311359701}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=150, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=150, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.895807, time: 1.0s\n",
      "epoch 10, training loss: 0.016461, time: 1.0s\n",
      "epoch 20, training loss: 0.005020, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=150, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=150, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.095167, time: 1.0s\n",
      "epoch 10, training loss: 0.014779, time: 1.0s\n",
      "epoch 20, training loss: 0.005448, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=150, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=150, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.996117, time: 1.0s\n",
      "epoch 10, training loss: 0.034899, time: 1.0s\n",
      "epoch 20, training loss: 0.022238, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 430.27it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 432.86it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 432.82it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 400.09it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 433.12it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 431.52it/s]\n",
      "[I 2024-10-06 23:32:49,421] Trial 11 finished with value: 0.9439119630812921 and parameters: {'epochs': 20, 'rep_dim': 150, 'temperature': 0.09303168401502951}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=88, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=88, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.896443, time: 1.0s\n",
      "epoch 10, training loss: 0.048338, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=88, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=88, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.877997, time: 1.0s\n",
      "epoch 10, training loss: 0.016088, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=88, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=88, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.981956, time: 1.0s\n",
      "epoch 10, training loss: 0.035822, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.33it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.20it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.56it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 397.03it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 428.76it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 427.73it/s]\n",
      "[I 2024-10-06 23:33:52,173] Trial 12 finished with value: 0.9418459896852214 and parameters: {'epochs': 17, 'rep_dim': 88, 'temperature': 0.09782295434976807}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=145, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=145, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.908918, time: 1.0s\n",
      "epoch 10, training loss: 0.011521, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=145, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=145, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.020715, time: 1.0s\n",
      "epoch 10, training loss: 0.014193, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=145, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=145, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.139361, time: 1.0s\n",
      "epoch 10, training loss: 0.039567, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 424.12it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.25it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.68it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 394.50it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 426.18it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 426.53it/s]\n",
      "[I 2024-10-06 23:34:51,996] Trial 13 finished with value: 0.9452224782839922 and parameters: {'epochs': 16, 'rep_dim': 145, 'temperature': 0.07895880484435379}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=84, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=84, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.917392, time: 1.0s\n",
      "epoch 10, training loss: 0.014112, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=84, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=84, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.004389, time: 1.0s\n",
      "epoch 10, training loss: 0.026795, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=84, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=84, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.985542, time: 1.0s\n",
      "epoch 10, training loss: 0.017831, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 427.94it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 431.48it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 431.03it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 398.33it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 430.39it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 430.89it/s]\n",
      "[I 2024-10-06 23:35:54,752] Trial 14 finished with value: 0.9455963140173667 and parameters: {'epochs': 17, 'rep_dim': 84, 'temperature': 0.08238244964319305}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=79, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=79, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.095969, time: 1.0s\n",
      "epoch 10, training loss: 0.018787, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=79, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=79, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.044516, time: 1.0s\n",
      "epoch 10, training loss: 0.052008, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=79, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=79, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.185235, time: 1.1s\n",
      "epoch 10, training loss: 0.021344, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 430.20it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 433.04it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 433.66it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 417.37it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 429.66it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 430.14it/s]\n",
      "[I 2024-10-06 23:36:54,476] Trial 15 finished with value: 0.9440993788819876 and parameters: {'epochs': 16, 'rep_dim': 79, 'temperature': 0.0612459374534487}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.066267, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.002778, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.189955, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 425.58it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.24it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 426.41it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 427.09it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 431.97it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 432.51it/s]\n",
      "[I 2024-10-06 23:37:09,363] Trial 16 finished with value: 0.9461565710237336 and parameters: {'epochs': 1, 'rep_dim': 51, 'temperature': 0.08196225508823195}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=54, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=54, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.387123, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=54, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=54, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.239975, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=54, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=54, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.290880, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 428.19it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 430.43it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 430.92it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 398.22it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 429.77it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 430.41it/s]\n",
      "[I 2024-10-06 23:37:48,197] Trial 17 finished with value: 0.9424102381798791 and parameters: {'epochs': 9, 'rep_dim': 54, 'temperature': 0.036600673008754636}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=72, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=72, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.033883, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=72, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=72, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.109952, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=72, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=72, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.916986, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 423.60it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.46it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 430.69it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 398.40it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 429.70it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 429.40it/s]\n",
      "[I 2024-10-06 23:38:03,378] Trial 18 finished with value: 0.9442867281760113 and parameters: {'epochs': 1, 'rep_dim': 72, 'temperature': 0.06409707765220436}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.060860, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.007660, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=51, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.185869, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 428.93it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 431.24it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 430.74it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 398.88it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 431.01it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:03<00:00, 430.88it/s]\n",
      "[I 2024-10-06 23:38:18,528] Trial 19 finished with value: 0.9457831325301205 and parameters: {'epochs': 1, 'rep_dim': 51, 'temperature': 0.08336224816985124}. Best is trial 0 with value: 0.9472753007784855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'epochs': 17, 'rep_dim': 81, 'temperature': 0.0760299845415369}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    epochs = trial.suggest_int('epochs', 1, 20)\n",
    "    rep_dim = trial.suggest_int('rep_dim', 50, 150)\n",
    "    temperature = trial.suggest_float('temperature', 0.001, 0.1)\n",
    "\n",
    "    icl_model = ICL(epochs=epochs,\n",
    "                      rep_dim=rep_dim,\n",
    "                      temperature=temperature,\n",
    "                      random_state=42)\n",
    "\n",
    "    icl_model.fit(train_latent_features)\n",
    "    \n",
    "    val_predictions = icl_model.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 0, 1)\n",
    "    \n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=0, average='binary')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c48a5ce5-b2b5-4981-ad13-6c7e386f3251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 3\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.977961, time: 1.0s\n",
      "epoch 10, training loss: 0.016990, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.144904, time: 1.0s\n",
      "epoch 10, training loss: 0.024965, time: 1.0s\n",
      "kernel size: 2\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=30, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=2, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=81, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.007313, time: 1.0s\n",
      "epoch 10, training loss: 0.023104, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 429.23it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 431.81it/s]\n",
      "testing: 100%|██████████| 186/186 [00:00<00:00, 432.38it/s]\n",
      "testing: 100%|██████████| 1841/1841 [00:04<00:00, 397.33it/s]\n",
      "testing: 100%|██████████| 1841/1841 [00:04<00:00, 427.12it/s]\n",
      "testing: 100%|██████████| 1841/1841 [00:04<00:00, 431.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9966\n",
      "Test Precision: 0.9965\n",
      "Test Recall: 1.0000\n",
      "Test F1 Score: 0.9983\n"
     ]
    }
   ],
   "source": [
    "best_icl_model = ICL(epochs=best_params['epochs'],\n",
    "                      rep_dim=best_params['rep_dim'],\n",
    "                      temperature=best_params['temperature'],\n",
    "                      random_state=42)\n",
    "\n",
    "best_icl_model.fit(train_latent_features)\n",
    "test_predictions = best_icl_model.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ce91ad-61ac-48f6-84a0-b13a7d744d27",
   "metadata": {},
   "source": [
    "# RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10352c8f-a071-483a-9a66-d482dbab6edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4210c16-4ca8-46b4-8717-3bbf948d8e69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 22:55:43,908] A new study created in memory with name: no-name-86e67b36-3a9b-4ed0-9276-c1c74fa4b4ca\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=67, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=67, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=67, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=67, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.263287, time: 1.1s\n",
      "beta: 0.99730279382521\n",
      "beta: 0.9946055876504201\n",
      "beta: 0.9919083814756301\n",
      "beta: 0.9892111753008401\n",
      "beta: 0.9865139691260502\n",
      "beta: 0.9838167629512602\n",
      "beta: 0.9811195567764702\n",
      "beta: 0.9811195567764701\n",
      "beta: 0.9811195567764701\n",
      "epoch 10, training loss: 0.760622, time: 1.1s\n",
      "beta: 0.9811195567764701\n",
      "beta: 0.9811195567764701\n",
      "beta: 0.9811195567764701\n",
      "beta: 0.9811195567764701\n",
      "beta: 0.9811195567764701\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.17it/s]\n",
      "100%|██████████| 10/10 [00:25<00:00,  2.53s/it]\n",
      "[I 2024-10-06 22:56:27,602] Trial 0 finished with value: 0.7559413690052654 and parameters: {'epochs': 14, 'rep_dim': 67, 'anom_ratio': 0.01888044322352994}. Best is trial 0 with value: 0.7559413690052654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=104, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=104, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=104, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=104, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.233222, time: 1.1s\n",
      "beta: 0.9921755846079604\n",
      "beta: 0.9843511692159208\n",
      "beta: 0.9765267538238812\n",
      "beta: 0.9687023384318416\n",
      "beta: 0.960877923039802\n",
      "beta: 0.9530535076477624\n",
      "beta: 0.9452290922557228\n",
      "beta: 0.9374046768636832\n",
      "beta: 0.9295802614716436\n",
      "epoch 10, training loss: 0.743092, time: 1.0s\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "beta: 0.9256680537756234\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.62it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.22s/it]\n",
      "[I 2024-10-06 22:57:12,413] Trial 1 finished with value: 0.6529569238257483 and parameters: {'epochs': 19, 'rep_dim': 104, 'anom_ratio': 0.07433194622437658}. Best is trial 0 with value: 0.7559413690052654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=79, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=79, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=79, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=79, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.320945, time: 1.0s\n",
      "beta: 0.9817996350129625\n",
      "beta: 0.963599270025925\n",
      "beta: 0.9453989050388876\n",
      "beta: 0.9271985400518501\n",
      "beta: 0.9089981750648127\n",
      "beta: 0.9089981750648127\n",
      "beta: 0.9089981750648127\n",
      "beta: 0.9089981750648127\n",
      "beta: 0.9089981750648127\n",
      "epoch 10, training loss: 0.733890, time: 1.0s\n",
      "beta: 0.9089981750648127\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.61it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.21s/it]\n",
      "[I 2024-10-06 22:57:47,380] Trial 2 finished with value: 0.22217611420034858 and parameters: {'epochs': 10, 'rep_dim': 79, 'anom_ratio': 0.09100182493518726}. Best is trial 0 with value: 0.7559413690052654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=130, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=130, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=130, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=130, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.327385, time: 1.0s\n",
      "beta: 0.9952834785153132\n",
      "beta: 0.9905669570306264\n",
      "beta: 0.9858504355459395\n",
      "beta: 0.9811339140612527\n",
      "beta: 0.9764173925765659\n",
      "beta: 0.9717008710918791\n",
      "beta: 0.9669843496071925\n",
      "beta: 0.9669843496071925\n",
      "beta: 0.9669843496071925\n",
      "epoch 10, training loss: 0.731934, time: 1.0s\n",
      "beta: 0.9669843496071925\n",
      "beta: 0.9669843496071925\n",
      "beta: 0.9669843496071925\n",
      "beta: 0.9669843496071925\n",
      "beta: 0.9669843496071925\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.59it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.23s/it]\n",
      "[I 2024-10-06 22:58:26,526] Trial 3 finished with value: 0.755224735184655 and parameters: {'epochs': 14, 'rep_dim': 130, 'anom_ratio': 0.03301565039280751}. Best is trial 0 with value: 0.7559413690052654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=56, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=56, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=56, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=56, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.294371, time: 1.0s\n",
      "beta: 0.9792913249156269\n",
      "beta: 0.9585826498312537\n",
      "beta: 0.9378739747468806\n",
      "beta: 0.9171652996625075\n",
      "beta: 0.9068109621203209\n",
      "beta: 0.9068109621203209\n",
      "beta: 0.9068109621203209\n",
      "beta: 0.9068109621203209\n",
      "beta: 0.9068109621203209\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.63it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.20s/it]\n",
      "[I 2024-10-06 22:59:00,402] Trial 4 finished with value: 0.20754497968659316 and parameters: {'epochs': 9, 'rep_dim': 56, 'anom_ratio': 0.09318903787967915}. Best is trial 0 with value: 0.7559413690052654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=106, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=106, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=106, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=106, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.220599, time: 1.0s\n",
      "beta: 0.9905737816671508\n",
      "beta: 0.9811475633343016\n",
      "beta: 0.9717213450014525\n",
      "beta: 0.9622951266686033\n",
      "beta: 0.9528689083357541\n",
      "beta: 0.9434426900029049\n",
      "beta: 0.9340164716700557\n",
      "beta: 0.9245902533372066\n",
      "beta: 0.9151640350043574\n",
      "epoch 10, training loss: 0.790301, time: 1.0s\n",
      "beta: 0.9057378166715082\n",
      "beta: 0.905737816671508\n",
      "beta: 0.905737816671508\n",
      "beta: 0.905737816671508\n",
      "beta: 0.905737816671508\n",
      "beta: 0.905737816671508\n",
      "beta: 0.905737816671508\n",
      "beta: 0.905737816671508\n",
      "beta: 0.905737816671508\n",
      "beta: 0.905737816671508\n",
      "epoch 20, training loss: 0.684928, time: 1.0s\n",
      "beta: 0.905737816671508\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.59it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.23s/it]\n",
      "[I 2024-10-06 22:59:45,468] Trial 5 finished with value: 0.7847395451210565 and parameters: {'epochs': 20, 'rep_dim': 106, 'anom_ratio': 0.094262183328492}. Best is trial 5 with value: 0.7847395451210565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=139, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=139, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=139, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=139, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.190404, time: 1.0s\n",
      "beta: 0.9840968252404793\n",
      "beta: 0.9681936504809585\n",
      "beta: 0.9522904757214378\n",
      "beta: 0.936387300961917\n",
      "beta: 0.9204841262023965\n",
      "beta: 0.9204841262023965\n",
      "beta: 0.9204841262023965\n",
      "beta: 0.9204841262023965\n",
      "beta: 0.9204841262023965\n",
      "epoch 10, training loss: 0.725513, time: 1.0s\n",
      "beta: 0.9204841262023965\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.62it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.23s/it]\n",
      "[I 2024-10-06 23:00:20,624] Trial 6 finished with value: 0.2206297858400557 and parameters: {'epochs': 10, 'rep_dim': 139, 'anom_ratio': 0.0795158737976035}. Best is trial 5 with value: 0.7847395451210565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=146, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=146, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=146, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=146, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.335315, time: 1.0s\n",
      "beta: 0.9836796956571804\n",
      "beta: 0.9673593913143608\n",
      "beta: 0.9510390869715412\n",
      "beta: 0.9347187826287215\n",
      "beta: 0.9183984782859019\n",
      "beta: 0.9020781739430823\n",
      "beta: 0.9020781739430821\n",
      "beta: 0.9020781739430821\n",
      "beta: 0.9020781739430821\n",
      "epoch 10, training loss: 0.713542, time: 1.0s\n",
      "beta: 0.9020781739430821\n",
      "beta: 0.9020781739430821\n",
      "beta: 0.9020781739430821\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.58it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.25s/it]\n",
      "[I 2024-10-06 23:00:57,948] Trial 7 finished with value: 0.2228342513770656 and parameters: {'epochs': 12, 'rep_dim': 146, 'anom_ratio': 0.0979218260569179}. Best is trial 5 with value: 0.7847395451210565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=66, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=66, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=66, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=66, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.247700, time: 1.0s\n",
      "beta: 0.9889858668428918\n",
      "beta: 0.9779717336857836\n",
      "beta: 0.9669576005286754\n",
      "beta: 0.9559434673715672\n",
      "beta: 0.9504364007930133\n",
      "beta: 0.9504364007930133\n",
      "beta: 0.9504364007930133\n",
      "beta: 0.9504364007930133\n",
      "beta: 0.9504364007930133\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.63it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.20s/it]\n",
      "[I 2024-10-06 23:01:31,830] Trial 8 finished with value: 0.39871526740364505 and parameters: {'epochs': 9, 'rep_dim': 66, 'anom_ratio': 0.04956359920698668}. Best is trial 5 with value: 0.7847395451210565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=61, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=61, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.254296, time: 1.0s\n",
      "beta: 0.9898748165247435\n",
      "beta: 0.979749633049487\n",
      "beta: 0.9696244495742306\n",
      "beta: 0.9594992660989741\n",
      "beta: 0.9493740826237176\n",
      "beta: 0.9392488991484611\n",
      "beta: 0.9291237156732046\n",
      "beta: 0.9189985321979486\n",
      "beta: 0.9189985321979486\n",
      "epoch 10, training loss: 0.812544, time: 1.0s\n",
      "beta: 0.9189985321979486\n",
      "beta: 0.9189985321979486\n",
      "beta: 0.9189985321979486\n",
      "beta: 0.9189985321979486\n",
      "beta: 0.9189985321979486\n",
      "beta: 0.9189985321979486\n",
      "beta: 0.9189985321979486\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.62it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.20s/it]\n",
      "[I 2024-10-06 23:02:13,116] Trial 9 finished with value: 0.5359398496240602 and parameters: {'epochs': 16, 'rep_dim': 61, 'anom_ratio': 0.08100146780205145}. Best is trial 5 with value: 0.7847395451210565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=109, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=109, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=109, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=109, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.241487, time: 1.0s\n",
      "beta: 0.959951173510064\n",
      "beta: 0.9399267602650959\n",
      "beta: 0.9399267602650959\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.59it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.28s/it]\n",
      "[I 2024-10-06 23:02:41,926] Trial 10 finished with value: 0.2490763690782397 and parameters: {'epochs': 3, 'rep_dim': 109, 'anom_ratio': 0.0600732397349041}. Best is trial 5 with value: 0.7847395451210565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=91, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=91, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=91, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=91, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.253874, time: 1.0s\n",
      "beta: 0.9988366410920575\n",
      "beta: 0.997673282184115\n",
      "beta: 0.9965099232761725\n",
      "beta: 0.99534656436823\n",
      "beta: 0.9941832054602875\n",
      "beta: 0.993019846552345\n",
      "beta: 0.9918564876444025\n",
      "beta: 0.99069312873646\n",
      "beta: 0.9895297698285175\n",
      "epoch 10, training loss: 0.785605, time: 1.0s\n",
      "beta: 0.988366410920575\n",
      "beta: 0.9883664109205748\n",
      "beta: 0.9883664109205748\n",
      "beta: 0.9883664109205748\n",
      "beta: 0.9883664109205748\n",
      "beta: 0.9883664109205748\n",
      "beta: 0.9883664109205748\n",
      "beta: 0.9883664109205748\n",
      "beta: 0.9883664109205748\n",
      "beta: 0.9883664109205748\n",
      "epoch 20, training loss: 0.647848, time: 1.0s\n",
      "beta: 0.9883664109205748\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.60it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.22s/it]\n",
      "[I 2024-10-06 23:03:27,264] Trial 11 finished with value: 0.7854191263282172 and parameters: {'epochs': 20, 'rep_dim': 91, 'anom_ratio': 0.011633589079425279}. Best is trial 11 with value: 0.7854191263282172.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=89, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=89, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=89, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=89, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.305137, time: 1.0s\n",
      "beta: 0.9984012202447049\n",
      "beta: 0.9968024404894098\n",
      "beta: 0.9952036607341147\n",
      "beta: 0.9936048809788196\n",
      "beta: 0.9920061012235245\n",
      "beta: 0.9904073214682294\n",
      "beta: 0.9888085417129343\n",
      "beta: 0.9872097619576392\n",
      "beta: 0.9856109822023441\n",
      "epoch 10, training loss: 0.762094, time: 1.0s\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "epoch 20, training loss: 0.660350, time: 1.0s\n",
      "beta: 0.9840122024470495\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.60it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.21s/it]\n",
      "[I 2024-10-06 23:04:12,348] Trial 12 finished with value: 0.7929502369668247 and parameters: {'epochs': 20, 'rep_dim': 89, 'anom_ratio': 0.01598779755295056}. Best is trial 12 with value: 0.7929502369668247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=86, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=86, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=86, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=86, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.240027, time: 1.0s\n",
      "beta: 0.9986539158285056\n",
      "beta: 0.9973078316570112\n",
      "beta: 0.9959617474855168\n",
      "beta: 0.9946156633140224\n",
      "beta: 0.993269579142528\n",
      "beta: 0.9919234949710336\n",
      "beta: 0.9905774107995392\n",
      "beta: 0.9892313266280448\n",
      "beta: 0.9878852424565504\n",
      "epoch 10, training loss: 0.770260, time: 1.0s\n",
      "beta: 0.9878852424565504\n",
      "beta: 0.9878852424565504\n",
      "beta: 0.9878852424565504\n",
      "beta: 0.9878852424565504\n",
      "beta: 0.9878852424565504\n",
      "beta: 0.9878852424565504\n",
      "beta: 0.9878852424565504\n",
      "beta: 0.9878852424565504\n",
      "beta: 0.9878852424565504\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.63it/s]\n",
      "100%|██████████| 10/10 [00:21<00:00,  2.20s/it]\n",
      "[I 2024-10-06 23:04:55,125] Trial 13 finished with value: 0.7700086680150245 and parameters: {'epochs': 18, 'rep_dim': 86, 'anom_ratio': 0.012114757543449546}. Best is trial 12 with value: 0.7929502369668247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=86, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=86, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=86, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=86, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.240027, time: 1.0s\n",
      "beta: 0.9847637411466861\n",
      "beta: 0.9695274822933722\n",
      "beta: 0.9695274822933722\n",
      "beta: 0.9695274822933722\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.61it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.20s/it]\n",
      "[I 2024-10-06 23:05:24,124] Trial 14 finished with value: 0.2541678574830904 and parameters: {'epochs': 4, 'rep_dim': 86, 'anom_ratio': 0.03047251770662786}. Best is trial 12 with value: 0.7929502369668247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=120, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=120, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=120, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=120, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.218105, time: 1.0s\n",
      "beta: 0.9968074330506259\n",
      "beta: 0.9936148661012518\n",
      "beta: 0.9904222991518777\n",
      "beta: 0.9872297322025037\n",
      "beta: 0.9840371652531296\n",
      "beta: 0.9808445983037555\n",
      "beta: 0.9776520313543814\n",
      "beta: 0.9744594644050073\n",
      "beta: 0.9728631809303203\n",
      "epoch 10, training loss: 0.794312, time: 1.0s\n",
      "beta: 0.9728631809303203\n",
      "beta: 0.9728631809303203\n",
      "beta: 0.9728631809303203\n",
      "beta: 0.9728631809303203\n",
      "beta: 0.9728631809303203\n",
      "beta: 0.9728631809303203\n",
      "beta: 0.9728631809303203\n",
      "beta: 0.9728631809303203\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.61it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.23s/it]\n",
      "[I 2024-10-06 23:06:06,438] Trial 15 finished with value: 0.7832310838445807 and parameters: {'epochs': 17, 'rep_dim': 120, 'anom_ratio': 0.027136819069679678}. Best is trial 12 with value: 0.7929502369668247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=92, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=92, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=92, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=92, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.300288, time: 1.0s\n",
      "beta: 0.985507275060436\n",
      "beta: 0.971014550120872\n",
      "beta: 0.956521825181308\n",
      "beta: 0.9565218251813079\n",
      "beta: 0.9565218251813079\n",
      "beta: 0.9565218251813079\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.63it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.22s/it]\n",
      "[I 2024-10-06 23:06:37,497] Trial 16 finished with value: 0.26464315826017953 and parameters: {'epochs': 6, 'rep_dim': 92, 'anom_ratio': 0.04347817481869205}. Best is trial 12 with value: 0.7929502369668247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=76, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=76, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=76, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=76, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.289157, time: 1.0s\n",
      "beta: 0.9989625735769528\n",
      "beta: 0.9979251471539057\n",
      "beta: 0.9968877207308585\n",
      "beta: 0.9958502943078114\n",
      "beta: 0.9948128678847642\n",
      "beta: 0.993775441461717\n",
      "beta: 0.9927380150386699\n",
      "beta: 0.9917005886156227\n",
      "beta: 0.9906631621925756\n",
      "epoch 10, training loss: 0.779342, time: 1.0s\n",
      "beta: 0.9896257357695284\n",
      "beta: 0.9896257357695281\n",
      "beta: 0.9896257357695281\n",
      "beta: 0.9896257357695281\n",
      "beta: 0.9896257357695281\n",
      "beta: 0.9896257357695281\n",
      "beta: 0.9896257357695281\n",
      "beta: 0.9896257357695281\n",
      "beta: 0.9896257357695281\n",
      "beta: 0.9896257357695281\n",
      "epoch 20, training loss: 0.666561, time: 1.0s\n",
      "beta: 0.9896257357695281\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.63it/s]\n",
      "100%|██████████| 10/10 [00:21<00:00,  2.19s/it]\n",
      "[I 2024-10-06 23:07:22,244] Trial 17 finished with value: 0.7842501106031559 and parameters: {'epochs': 20, 'rep_dim': 76, 'anom_ratio': 0.010374264230471966}. Best is trial 12 with value: 0.7929502369668247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=118, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=118, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=118, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=118, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.285051, time: 1.0s\n",
      "beta: 0.9971706186559257\n",
      "beta: 0.9943412373118514\n",
      "beta: 0.9915118559677771\n",
      "beta: 0.9886824746237028\n",
      "beta: 0.9858530932796286\n",
      "beta: 0.9830237119355543\n",
      "beta: 0.98019433059148\n",
      "beta: 0.9787796399194426\n",
      "beta: 0.9787796399194426\n",
      "epoch 10, training loss: 0.789491, time: 1.0s\n",
      "beta: 0.9787796399194426\n",
      "beta: 0.9787796399194426\n",
      "beta: 0.9787796399194426\n",
      "beta: 0.9787796399194426\n",
      "beta: 0.9787796399194426\n",
      "beta: 0.9787796399194426\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.59it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.23s/it]\n",
      "[I 2024-10-06 23:08:02,432] Trial 18 finished with value: 0.7688740762208376 and parameters: {'epochs': 15, 'rep_dim': 118, 'anom_ratio': 0.021220360080557436}. Best is trial 12 with value: 0.7929502369668247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=93, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=93, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=93, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=93, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.320382, time: 1.0s\n",
      "beta: 0.9609436553060551\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.61it/s]\n",
      "100%|██████████| 10/10 [00:22<00:00,  2.23s/it]\n",
      "[I 2024-10-06 23:08:28,634] Trial 19 finished with value: 0.22894242268921922 and parameters: {'epochs': 1, 'rep_dim': 93, 'anom_ratio': 0.039056344693944894}. Best is trial 12 with value: 0.7929502369668247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'epochs': 20, 'rep_dim': 89, 'anom_ratio': 0.01598779755295056}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    epochs = trial.suggest_int('epochs', 1, 20)\n",
    "    rep_dim = trial.suggest_int('rep_dim', 50, 150)\n",
    "    anom_ratio = trial.suggest_float('anom_ratio', 0.01, 0.1)\n",
    "\n",
    "    rca_model = RCA(epochs=epochs,\n",
    "                      rep_dim=rep_dim,\n",
    "                      anom_ratio=anom_ratio,\n",
    "                      random_state=42)\n",
    "\n",
    "    rca_model.fit(train_latent_features)\n",
    "    \n",
    "    val_predictions = rca_model.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 0, 1)\n",
    "    \n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=0, average='binary')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "875e4fcb-151e-43c4-a8eb-e16c02ebd63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=89, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=89, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=89, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=89, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=32, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 2.305137, time: 1.0s\n",
      "beta: 0.9984012202447049\n",
      "beta: 0.9968024404894098\n",
      "beta: 0.9952036607341147\n",
      "beta: 0.9936048809788196\n",
      "beta: 0.9920061012235245\n",
      "beta: 0.9904073214682294\n",
      "beta: 0.9888085417129343\n",
      "beta: 0.9872097619576392\n",
      "beta: 0.9856109822023441\n",
      "epoch 10, training loss: 0.762094, time: 1.0s\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "beta: 0.9840122024470495\n",
      "epoch 20, training loss: 0.660350, time: 1.0s\n",
      "beta: 0.9840122024470495\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.60it/s]\n",
      "100%|██████████| 10/10 [00:27<00:00,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9849\n",
      "Test Precision: 0.9965\n",
      "Test Recall: 0.9879\n",
      "Test F1 Score: 0.9922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_rca_model = RCA(epochs=best_params['epochs'],\n",
    "                      rep_dim=best_params['rep_dim'],\n",
    "                      anom_ratio=best_params['anom_ratio'],\n",
    "                      random_state=42)\n",
    "\n",
    "best_rca_model.fit(train_latent_features)\n",
    "test_predictions = best_rca_model.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f56a90-0ec5-4709-a6e0-ef43d3365978",
   "metadata": {},
   "source": [
    "# RDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "62292e86-08d3-4b31-92ed-d32b1ce9763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import RDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c499ff32-1b4e-43de-b567-d8f000a5a2ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 23:17:49,587] A new study created in memory with name: no-name-0f409735-4133-4385-ac72-055a082a7845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=63, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000019, time: 0.8s\n",
      "epoch 10, training loss: 0.000012, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 637.03it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 589.77it/s]\n",
      "[I 2024-10-06 23:18:01,555] Trial 0 finished with value: 0.8130859764612008 and parameters: {'epochs': 11, 'rep_dim': 63}. Best is trial 0 with value: 0.8130859764612008.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=93, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000017, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 636.59it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 590.67it/s]\n",
      "[I 2024-10-06 23:18:06,110] Trial 1 finished with value: 0.9363603861279943 and parameters: {'epochs': 2, 'rep_dim': 93}. Best is trial 1 with value: 0.9363603861279943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=82, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000018, time: 0.8s\n",
      "epoch 10, training loss: 0.000013, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 638.33it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 591.66it/s]\n",
      "[I 2024-10-06 23:18:22,974] Trial 2 finished with value: 0.920732813350263 and parameters: {'epochs': 17, 'rep_dim': 82}. Best is trial 1 with value: 0.9363603861279943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=82, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000018, time: 0.8s\n",
      "epoch 10, training loss: 0.000013, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 637.57it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 589.73it/s]\n",
      "[I 2024-10-06 23:18:34,894] Trial 3 finished with value: 0.9265740573696554 and parameters: {'epochs': 11, 'rep_dim': 82}. Best is trial 1 with value: 0.9363603861279943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=126, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000016, time: 0.8s\n",
      "epoch 10, training loss: 0.000015, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 639.99it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 593.20it/s]\n",
      "[I 2024-10-06 23:18:49,311] Trial 4 finished with value: 0.9373102339703518 and parameters: {'epochs': 14, 'rep_dim': 126}. Best is trial 4 with value: 0.9373102339703518.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=119, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000017, time: 0.8s\n",
      "epoch 10, training loss: 0.000014, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 636.05it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 588.57it/s]\n",
      "[I 2024-10-06 23:19:00,499] Trial 5 finished with value: 0.9373102339703518 and parameters: {'epochs': 10, 'rep_dim': 119}. Best is trial 4 with value: 0.9373102339703518.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=103, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000017, time: 0.9s\n",
      "epoch 10, training loss: 0.000014, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 640.03it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 593.85it/s]\n",
      "[I 2024-10-06 23:19:12,453] Trial 6 finished with value: 0.9376896982681664 and parameters: {'epochs': 11, 'rep_dim': 103}. Best is trial 6 with value: 0.9376896982681664.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=70, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000018, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 640.60it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 593.07it/s]\n",
      "[I 2024-10-06 23:19:22,719] Trial 7 finished with value: 0.8801054018445322 and parameters: {'epochs': 9, 'rep_dim': 70}. Best is trial 6 with value: 0.9376896982681664.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=112, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000016, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 637.95it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 593.26it/s]\n",
      "[I 2024-10-06 23:19:26,468] Trial 8 finished with value: 0.9439318665720369 and parameters: {'epochs': 1, 'rep_dim': 112}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=146, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000018, time: 0.8s\n",
      "epoch 10, training loss: 0.000016, time: 0.8s\n",
      "epoch 20, training loss: 0.000019, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 635.57it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 589.32it/s]\n",
      "[I 2024-10-06 23:19:45,889] Trial 9 finished with value: 0.940149625935162 and parameters: {'epochs': 20, 'rep_dim': 146}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=148, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000018, time: 0.9s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 544.96it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 512.47it/s]\n",
      "[I 2024-10-06 23:19:50,183] Trial 10 finished with value: 0.9362451567453328 and parameters: {'epochs': 1, 'rep_dim': 148}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=150, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000018, time: 0.9s\n",
      "epoch 10, training loss: 0.000016, time: 0.9s\n",
      "epoch 20, training loss: 0.000019, time: 0.9s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 637.68it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 590.84it/s]\n",
      "[I 2024-10-06 23:20:10,680] Trial 11 finished with value: 0.9376896982681664 and parameters: {'epochs': 20, 'rep_dim': 150}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=127, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000016, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 635.09it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 589.49it/s]\n",
      "[I 2024-10-06 23:20:17,750] Trial 12 finished with value: 0.9390156918687589 and parameters: {'epochs': 5, 'rep_dim': 127}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=109, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000017, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 635.74it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 590.09it/s]\n",
      "[I 2024-10-06 23:20:25,611] Trial 13 finished with value: 0.9348370927318296 and parameters: {'epochs': 6, 'rep_dim': 109}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=138, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000017, time: 0.8s\n",
      "epoch 10, training loss: 0.000015, time: 0.8s\n",
      "epoch 20, training loss: 0.000019, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 636.35it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 590.50it/s]\n",
      "[I 2024-10-06 23:20:45,042] Trial 14 finished with value: 0.9371204001429082 and parameters: {'epochs': 20, 'rep_dim': 138}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=114, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000015, time: 0.8s\n",
      "epoch 10, training loss: 0.000015, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 632.65it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 586.16it/s]\n",
      "[I 2024-10-06 23:21:00,347] Trial 15 finished with value: 0.9357896619567162 and parameters: {'epochs': 15, 'rep_dim': 114}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=136, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000016, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 632.57it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 586.43it/s]\n",
      "[I 2024-10-06 23:21:07,455] Trial 16 finished with value: 0.9359799713876967 and parameters: {'epochs': 5, 'rep_dim': 136}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=94, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000019, time: 0.8s\n",
      "epoch 10, training loss: 0.000014, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 639.90it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 592.59it/s]\n",
      "[I 2024-10-06 23:21:24,552] Trial 17 finished with value: 0.9285071132721052 and parameters: {'epochs': 17, 'rep_dim': 94}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=50, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000021, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 619.61it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 592.71it/s]\n",
      "[I 2024-10-06 23:21:33,222] Trial 18 finished with value: 0.762993762993763 and parameters: {'epochs': 7, 'rep_dim': 50}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=134, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000018, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 632.99it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:02<00:00, 588.43it/s]\n",
      "[I 2024-10-06 23:21:38,653] Trial 19 finished with value: 0.940149625935162 and parameters: {'epochs': 3, 'rep_dim': 134}. Best is trial 8 with value: 0.9439318665720369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'epochs': 1, 'rep_dim': 112}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    epochs = trial.suggest_int('epochs', 1, 20)\n",
    "    rep_dim = trial.suggest_int('rep_dim', 50, 150)\n",
    "\n",
    "    rdp_model = RDP(epochs=epochs,\n",
    "                      rep_dim=rep_dim,\n",
    "                      random_state=42)\n",
    "\n",
    "    rdp_model.fit(train_latent_features)\n",
    "    \n",
    "    val_predictions = rdp_model.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 0, 1)\n",
    "    \n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=0, average='binary')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9739df84-3e20-4aeb-bdcc-b3e51c9d9bb0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=112, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000016, time: 0.8s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 634.31it/s]\n",
      "testing: 100%|██████████| 1841/1841 [00:03<00:00, 585.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9964\n",
      "Test Precision: 0.9963\n",
      "Test Recall: 0.9999\n",
      "Test F1 Score: 0.9981\n"
     ]
    }
   ],
   "source": [
    "best_rdp_model = RDP(epochs=best_params['epochs'],\n",
    "                      rep_dim=best_params['rep_dim'],\n",
    "                      random_state=42)\n",
    "\n",
    "best_rdp_model.fit(train_latent_features)\n",
    "test_predictions = best_rdp_model.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7427dba-e2f0-4781-9bd5-f915c8154c53",
   "metadata": {},
   "source": [
    "# DeepSVDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e7e030c-8b3f-4ab9-92fa-7f4b0a3f75ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import DeepSVDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bbbb4e19-009b-4592-b09e-c01f863ac2a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-06 23:14:56,567] A new study created in memory with name: no-name-1662ce95-527e-42bc-9244-08bccdbf11de\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=130, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.016776, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1424.48it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1427.19it/s]\n",
      "[I 2024-10-06 23:15:00,238] Trial 0 finished with value: 0.9454094292803971 and parameters: {'epochs': 7, 'rep_dim': 130}. Best is trial 0 with value: 0.9454094292803971.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=112, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.013780, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1319.99it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1325.42it/s]\n",
      "[I 2024-10-06 23:15:04,379] Trial 1 finished with value: 0.9412811387900356 and parameters: {'epochs': 8, 'rep_dim': 112}. Best is trial 0 with value: 0.9454094292803971.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=77, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.008463, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1328.59it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1327.39it/s]\n",
      "[I 2024-10-06 23:15:06,851] Trial 2 finished with value: 0.9418459896852214 and parameters: {'epochs': 3, 'rep_dim': 77}. Best is trial 0 with value: 0.9454094292803971.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=109, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.013614, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1430.00it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1328.19it/s]\n",
      "[I 2024-10-06 23:15:10,552] Trial 3 finished with value: 0.9437244807385052 and parameters: {'epochs': 7, 'rep_dim': 109}. Best is trial 0 with value: 0.9454094292803971.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=140, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.019233, time: 0.3s\n",
      "epoch 10, training loss: 0.000182, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1425.70it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1322.19it/s]\n",
      "[I 2024-10-06 23:15:15,483] Trial 4 finished with value: 0.9424102381798791 and parameters: {'epochs': 11, 'rep_dim': 140}. Best is trial 0 with value: 0.9454094292803971.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=119, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.016428, time: 0.3s\n",
      "epoch 10, training loss: 0.000153, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1423.68it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1322.98it/s]\n",
      "[I 2024-10-06 23:15:22,030] Trial 5 finished with value: 0.9459698848538529 and parameters: {'epochs': 16, 'rep_dim': 119}. Best is trial 5 with value: 0.9459698848538529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=139, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.019586, time: 0.3s\n",
      "epoch 10, training loss: 0.000157, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1310.59it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1321.94it/s]\n",
      "[I 2024-10-06 23:15:29,432] Trial 6 finished with value: 0.9405270655270656 and parameters: {'epochs': 18, 'rep_dim': 139}. Best is trial 5 with value: 0.9459698848538529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=54, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.006558, time: 0.3s\n",
      "epoch 10, training loss: 0.000083, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1322.91it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1327.63it/s]\n",
      "[I 2024-10-06 23:15:34,814] Trial 7 finished with value: 0.9416577730345073 and parameters: {'epochs': 12, 'rep_dim': 54}. Best is trial 5 with value: 0.9459698848538529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=147, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.020169, time: 0.3s\n",
      "epoch 10, training loss: 0.000211, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1427.78it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1325.38it/s]\n",
      "[I 2024-10-06 23:15:40,356] Trial 8 finished with value: 0.9439119630812921 and parameters: {'epochs': 13, 'rep_dim': 147}. Best is trial 5 with value: 0.9459698848538529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.016809, time: 0.3s\n",
      "epoch 10, training loss: 0.000154, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1315.49it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1325.52it/s]\n",
      "[I 2024-10-06 23:15:48,200] Trial 9 finished with value: 0.9483916578296218 and parameters: {'epochs': 19, 'rep_dim': 128}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=87, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.009505, time: 0.3s\n",
      "epoch 10, training loss: 0.000111, time: 0.3s\n",
      "epoch 20, training loss: 0.000083, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1419.25it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1324.89it/s]\n",
      "[I 2024-10-06 23:15:56,216] Trial 10 finished with value: 0.9388264669163545 and parameters: {'epochs': 20, 'rep_dim': 87}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=121, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.015052, time: 0.3s\n",
      "epoch 10, training loss: 0.000148, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1424.55it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1330.24it/s]\n",
      "[I 2024-10-06 23:16:02,967] Trial 11 finished with value: 0.9418459896852214 and parameters: {'epochs': 16, 'rep_dim': 121}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.011678, time: 0.3s\n",
      "epoch 10, training loss: 0.000110, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1225.02it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1137.49it/s]\n",
      "[I 2024-10-06 23:16:09,918] Trial 12 finished with value: 0.940149625935162 and parameters: {'epochs': 16, 'rep_dim': 100}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=124, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.015557, time: 0.4s\n",
      "epoch 10, training loss: 0.000153, time: 0.4s\n",
      "epoch 20, training loss: 0.000117, time: 0.4s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1138.34it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1142.81it/s]\n",
      "[I 2024-10-06 23:16:18,827] Trial 13 finished with value: 0.9403383793410508 and parameters: {'epochs': 20, 'rep_dim': 124}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=94, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.010652, time: 0.4s\n",
      "epoch 10, training loss: 0.000130, time: 0.4s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1231.57it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1140.64it/s]\n",
      "[I 2024-10-06 23:16:25,902] Trial 14 finished with value: 0.9412811387900356 and parameters: {'epochs': 15, 'rep_dim': 94}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=109, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.013614, time: 0.4s\n",
      "epoch 10, training loss: 0.000124, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1430.08it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1337.08it/s]\n",
      "[I 2024-10-06 23:16:33,161] Trial 15 finished with value: 0.9459698848538529 and parameters: {'epochs': 18, 'rep_dim': 109}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=132, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.017385, time: 0.3s\n",
      "epoch 10, training loss: 0.000158, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1431.39it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1328.52it/s]\n",
      "[I 2024-10-06 23:16:39,162] Trial 16 finished with value: 0.9420341394025604 and parameters: {'epochs': 14, 'rep_dim': 132}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=117, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.013745, time: 0.3s\n",
      "epoch 10, training loss: 0.000171, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1324.10it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1337.99it/s]\n",
      "[I 2024-10-06 23:16:46,515] Trial 17 finished with value: 0.9435369318181818 and parameters: {'epochs': 18, 'rep_dim': 117}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=75, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.008782, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1315.66it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1325.32it/s]\n",
      "[I 2024-10-06 23:16:48,355] Trial 18 finished with value: 0.9418459896852214 and parameters: {'epochs': 1, 'rep_dim': 75}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=150, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.018763, time: 0.3s\n",
      "epoch 10, training loss: 0.000197, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1419.63it/s]\n",
      "testing: 100%|██████████| 1473/1473 [00:01<00:00, 1323.42it/s]\n",
      "[I 2024-10-06 23:16:55,259] Trial 19 finished with value: 0.9457831325301205 and parameters: {'epochs': 17, 'rep_dim': 150}. Best is trial 9 with value: 0.9483916578296218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'epochs': 19, 'rep_dim': 128}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    epochs = trial.suggest_int('epochs', 1, 20)\n",
    "    rep_dim = trial.suggest_int('rep_dim', 50, 150)\n",
    "\n",
    "    deepsvdd_model = DeepSVDD(epochs=epochs,\n",
    "                      rep_dim=rep_dim,\n",
    "                      random_state=42)\n",
    "\n",
    "    deepsvdd_model.fit(train_latent_features)\n",
    "    \n",
    "    val_predictions = deepsvdd_model.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 0, 1)\n",
    "    \n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=0, average='binary')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "08e6acf6-d090-43c3-94f3-b370315e9f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.016809, time: 0.3s\n",
      "epoch 10, training loss: 0.000154, time: 0.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 186/186 [00:00<00:00, 1437.26it/s]\n",
      "testing: 100%|██████████| 1841/1841 [00:01<00:00, 1320.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9967\n",
      "Test Precision: 0.9966\n",
      "Test Recall: 1.0000\n",
      "Test F1 Score: 0.9983\n"
     ]
    }
   ],
   "source": [
    "best_deepsvdd_model = DeepSVDD(epochs=best_params['epochs'],\n",
    "                      rep_dim=best_params['rep_dim'],\n",
    "                      random_state=42)\n",
    "\n",
    "best_deepsvdd_model.fit(train_latent_features)\n",
    "test_predictions = best_deepsvdd_model.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e832b6a-ca2d-49ef-b1c3-f4dcc5ebd0d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# NeuTraL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21fd19a-01c4-42e0-baa8-be816b51a7ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# GOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7c96efc0-3481-4ab6-8d1a-b7a6ad790f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import GOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a96b7cf7-422c-4f04-8cac-cf0780f7eab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-30 06:13:24,528] A new study created in memory with name: no-name-905e5c63-ea66-448a-b3f3-53f438593f73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZTIN10cask_cudnn14BaseKernelInfoE, version libcudnn_cnn_infer.so.8\n",
      "[W 2024-09-30 06:14:15,255] Trial 0 failed with parameters: {'epochs': 1, 'hidden_dim': 4, 'trans_dim': 38} because of the following error: RuntimeError('GET was unable to find an engine to execute this computation').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_833/704275057.py\", line 11, in objective\n",
      "    goad_model.fit(train_latent_features)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/deepod/core/base_model.py\", line 185, in fit\n",
      "    self._training()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/deepod/core/base_model.py\", line 339, in _training\n",
      "    loss.backward()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/_tensor.py\", line 525, in backward\n",
      "    )\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 267, in backward\n",
      "    grad,\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n",
      "RuntimeError: GET was unable to find an engine to execute this computation\n",
      "[W 2024-09-30 06:14:15,257] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 transformation done\n",
      "GoadNet(\n",
      "  (enc): ConvNet(\n",
      "    (net): Sequential(\n",
      "      (0): Conv1d(38, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (3): LeakyReLU(negative_slope=0.01)\n",
      "      (4): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (5): LeakyReLU(negative_slope=0.01)\n",
      "      (6): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (7): LeakyReLU(negative_slope=0.01)\n",
      "      (8): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (9): LeakyReLU(negative_slope=0.01)\n",
      "      (10): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (1): Conv1d(4, 256, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "GET was unable to find an engine to execute this computation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f1\n\u001b[1;32m     19\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[70], line 11\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      4\u001b[0m trans_dim \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrans_dim\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m      6\u001b[0m goad_model \u001b[38;5;241m=\u001b[39m GOAD(epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m      7\u001b[0m                   hidden_dim\u001b[38;5;241m=\u001b[39mhidden_dim,\n\u001b[1;32m      8\u001b[0m                   trans_dim\u001b[38;5;241m=\u001b[39mtrans_dim,\n\u001b[1;32m      9\u001b[0m                   random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mgoad_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_latent_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m val_predictions \u001b[38;5;241m=\u001b[39m goad_model\u001b[38;5;241m.\u001b[39mpredict(val_latent_features)\n\u001b[1;32m     14\u001b[0m val_true_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y_val \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/deepod/core/base_model.py:185\u001b[0m, in \u001b[0;36mBaseDeepAD.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_ensemble):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_prepare(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data,\n\u001b[1;32m    184\u001b[0m                                                                         y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_label)\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart Inference on the training data...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/deepod/core/base_model.py:339\u001b[0m, in \u001b[0;36mBaseDeepAD._training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_forward(batch_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 339\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    342\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39mregister_hook, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, hook)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot register a hook on a tensor that \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt require gradient\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 525\u001b[0m     )\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m overridable_args \u001b[38;5;241m=\u001b[39m t_outputs \u001b[38;5;241m+\u001b[39m t_inputs\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(overridable_args):\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m--> 267\u001b[0m         grad,\n\u001b[1;32m    268\u001b[0m         overridable_args,\n\u001b[1;32m    269\u001b[0m         t_outputs,\n\u001b[1;32m    270\u001b[0m         t_inputs,\n\u001b[1;32m    271\u001b[0m         grad_outputs\u001b[38;5;241m=\u001b[39mgrad_outputs,\n\u001b[1;32m    272\u001b[0m         retain_graph\u001b[38;5;241m=\u001b[39mretain_graph,\n\u001b[1;32m    273\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    274\u001b[0m         only_inputs\u001b[38;5;241m=\u001b[39monly_inputs,\n\u001b[1;32m    275\u001b[0m         allow_unused\u001b[38;5;241m=\u001b[39mallow_unused,\n\u001b[1;32m    276\u001b[0m         is_grads_batched\u001b[38;5;241m=\u001b[39mis_grads_batched,\n\u001b[1;32m    277\u001b[0m     )\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m only_inputs:\n\u001b[1;32m    280\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly_inputs argument is deprecated and is ignored now \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(defaults to True). To accumulate gradient for other \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts of the graph, please use torch.autograd.backward.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mRuntimeError\u001b[0m: GET was unable to find an engine to execute this computation"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    epochs = trial.suggest_int('epochs', 1, 20)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 2, 16)\n",
    "    trans_dim = trial.suggest_int('trans_dim', 16, 64)\n",
    "\n",
    "    goad_model = GOAD(epochs=epochs,\n",
    "                      hidden_dim=hidden_dim,\n",
    "                      trans_dim=trans_dim,\n",
    "                      random_state=42)\n",
    "\n",
    "    goad_model.fit(train_latent_features)\n",
    "    \n",
    "    val_predictions = goad_model.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 0, 1)\n",
    "    \n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=0, average='binary')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9c2f99-cdf0-4174-84b2-2c8faecebc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_goad_model = GOAD(epochs=best_params['epochs'],\n",
    "                        hidden_dim=best_params['hidden_dim'],\n",
    "                        trans_dim=best_params['trans_dim'],\n",
    "                        random_state=42)\n",
    "\n",
    "best_goad_model.fit(train_latent_features)\n",
    "test_predictions = best_goad_model.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3c1754-4945-46fb-9c59-61abfc593a44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# REPEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2081586b-94ae-4f5c-9f33-c2e2cbc7549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import REPEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "49d7b345-36fc-421b-be4d-cd9c81f57ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-30 06:14:58,964] A new study created in memory with name: no-name-b34cc522-9d2f-435c-ab94-da5a42064906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=32, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=148, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-09-30 06:23:36,410] Trial 0 failed with parameters: {'epochs': 10, 'rep_dim': 148} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_833/3979886442.py\", line 9, in objective\n",
      "    repen_model.fit(train_latent_features)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/deepod/core/base_model.py\", line 185, in fit\n",
      "    self._training()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/deepod/core/base_model.py\", line 336, in _training\n",
      "    for batch_x in self.train_loader:\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/deepod/models/tabular/repen.py\", line 118, in __next__\n",
      "    examples, positives, negatives = self.triplet_batch_generation()\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/deepod/models/tabular/repen.py\", line 145, in triplet_batch_generation\n",
      "    sid = np.random.choice(len(inlier_ids), 1, p=positive_weights)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-09-30 06:23:36,412] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f1\n\u001b[1;32m     17\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[72], line 9\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      3\u001b[0m rep_dim \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrep_dim\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m150\u001b[39m)\n\u001b[1;32m      5\u001b[0m repen_model \u001b[38;5;241m=\u001b[39m REPEN(epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m      6\u001b[0m                   rep_dim\u001b[38;5;241m=\u001b[39mrep_dim,\n\u001b[1;32m      7\u001b[0m                   random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mrepen_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_latent_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m val_predictions \u001b[38;5;241m=\u001b[39m repen_model\u001b[38;5;241m.\u001b[39mpredict(val_latent_features)\n\u001b[1;32m     12\u001b[0m val_true_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y_val \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/deepod/core/base_model.py:185\u001b[0m, in \u001b[0;36mBaseDeepAD.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_ensemble):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_prepare(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data,\n\u001b[1;32m    184\u001b[0m                                                                         y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_label)\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart Inference on the training data...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/deepod/core/base_model.py:336\u001b[0m, in \u001b[0;36mBaseDeepAD._training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    335\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 336\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/deepod/models/tabular/repen.py:118\u001b[0m, in \u001b[0;36mREPENLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 118\u001b[0m     examples, positives, negatives \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtriplet_batch_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     examples, positives, negatives \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(examples), \\\n\u001b[1;32m    120\u001b[0m                                      torch\u001b[38;5;241m.\u001b[39mfrom_numpy(positives), \\\n\u001b[1;32m    121\u001b[0m                                      torch\u001b[38;5;241m.\u001b[39mfrom_numpy(negatives)\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_epoch:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/deepod/models/tabular/repen.py:145\u001b[0m, in \u001b[0;36mREPENLoader.triplet_batch_generation\u001b[0;34m(self, prior_knowledge)\u001b[0m\n\u001b[1;32m    143\u001b[0m negatives_ids \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros([batch_size])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, batch_size):\n\u001b[0;32m--> 145\u001b[0m     sid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(inlier_ids), \u001b[38;5;241m1\u001b[39m, p\u001b[38;5;241m=\u001b[39mpositive_weights)\n\u001b[1;32m    146\u001b[0m     examples_ids[i] \u001b[38;5;241m=\u001b[39m inlier_ids[sid]\n\u001b[1;32m    147\u001b[0m     sid2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(inlier_ids), \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    epochs = trial.suggest_int('epochs', 1, 20)\n",
    "    rep_dim = trial.suggest_int('rep_dim', 50, 150)\n",
    "\n",
    "    repen_model = REPEN(epochs=epochs,\n",
    "                      rep_dim=rep_dim,\n",
    "                      random_state=42)\n",
    "\n",
    "    repen_model.fit(train_latent_features)\n",
    "    \n",
    "    val_predictions = repen_model.predict(val_latent_features)\n",
    "    val_true_labels = np.where(y_val == 0, 0, 1)\n",
    "    \n",
    "    f1 = f1_score(val_true_labels, val_predictions, pos_label=0, average='binary')\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0617b4-30a9-4641-a51f-f04162afe61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_repen_model = REPEN(epochs=best_params['epochs'],\n",
    "                        rep_dim=best_params['rep_dim'],\n",
    "                        random_state=42)\n",
    "\n",
    "best_repen_model.fit(train_latent_features)\n",
    "test_predictions = best_repen_model.predict(test_latent_features)\n",
    "test_true_labels = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "test_precision = precision_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_recall = recall_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "test_f1 = f1_score(test_true_labels, test_predictions, pos_label=1, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
