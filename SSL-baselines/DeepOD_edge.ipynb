{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "701d42fa-fa25-4f44-babe-7950b1ebad0f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a730eb-6200-45b1-b54a-afb0099f42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, make_scorer\n",
    "from deepod.metrics import tabular_metrics\n",
    "\n",
    "from tqdm import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323c86ac-b77a-4176-a19b-cc254198860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('data/x_train.npy')\n",
    "y_train = np.load('data/y_train.npy')\n",
    "\n",
    "X_test = np.load('data/x_test.npy')\n",
    "y_test = np.load('data/y_test.npy')\n",
    "\n",
    "#X_val = np.load('data/x_val.npy')\n",
    "#y_val = np.load('data/y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f53dd4-c836-4f18-be9f-ead9e15a2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = np.concatenate((X_train, X_val), axis=0)\n",
    "#y_train = np.concatenate((y_train, y_val), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1afcfae-9b3e-418e-8df9-0f41c099a495",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d79e84cd-3e88-43d6-9a90-5834e4d0b646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       " array([ 7928,  8357, 10489,  8184, 11611,   682,   286, 19323,  7913,\n",
       "         7186,  7679,  8258,  8198,  8006,  7656]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26860cb-afc6-462b-a65f-f9c14f733be8",
   "metadata": {},
   "source": [
    "7 is normal class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09299cdd-bdf5-40ed-b95d-82aae54b5284",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_binary = np.where(y_test == 7, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11109899-e1c2-454a-85a9-44b89befaeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = X_train[y_train == 7] # normal class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04c96228-4afc-4ec0-9eec-070308871cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19323"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normal_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d5cb01-b1aa-4bfa-9133-51962151230d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cfb9704-c52b-4c9f-8c23-655eab0d1649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, y_test, y_pred):\n",
    "    positive_class = \"normal\"\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred, pos_label=positive_class)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=positive_class)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=positive_class)\n",
    "    \n",
    "    metrics = {\n",
    "        'model': [model],\n",
    "        'accuracy': [accuracy],\n",
    "        'precision': [precision],\n",
    "        'recall': [recall],\n",
    "        'f1': [f1],\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b50a07-7246-473f-8f6f-531d37acd4b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# DIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b10d8531-be07-4bef-ab71-ff5639fe5dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import DeepIsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfbe9b4c-fd4c-4e91-b534-7426484c5eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  9.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Inference on the training data...\n",
      "Start Inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:31<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:56<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "clf_dif = DeepIsolationForest()\n",
    "clf_dif.fit(normal_data, y=None)\n",
    "y_preds_dif = clf_dif.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b73e1091-7f36-444e-b4c3-fd1157bfe1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_dif_binary = np.where(y_preds_dif == 1, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94e6f314-4175-4888-8430-a2ec067eb5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DIF</td>\n",
       "      <td>0.156965</td>\n",
       "      <td>0.156965</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  precision  recall        f1\n",
       "0   DIF  0.156965   0.156965     1.0  0.271339"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dif = pd.DataFrame(evaluate_model(\"DIF\", y_test_binary, y_preds_dif_binary))\n",
    "results_dif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbc2d72-d3dd-4732-83dc-811317721e71",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# SLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cafe92df-46e5-404d-8bc3-0e8338441a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import SLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0f64b88-738f-4d35-a984-5d61d25194eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 50, ensemble size: 20\n",
      "len pool: [ 1  4  5  6  7  8  9 10 11 13 14 16 17 18 19 20 23 26 28 29 31 32 34 35\n",
      " 36 37 39 40 41 43 45 46 47 48 50 51 54 55 56 57 58 59 60 62 64 66 68 71\n",
      " 73 74]\n",
      "epoch  1, training loss: 0.728733, time: 1.5s\n",
      "epoch 10, training loss: 0.695240, time: 0.8s\n",
      "epoch 20, training loss: 0.695133, time: 0.8s\n",
      "epoch 30, training loss: 0.695192, time: 0.8s\n",
      "epoch 40, training loss: 0.695134, time: 0.9s\n",
      "epoch 50, training loss: 0.695210, time: 0.8s\n",
      "epoch 60, training loss: 0.695120, time: 0.9s\n",
      "epoch 70, training loss: 0.695145, time: 0.9s\n",
      "epoch 80, training loss: 0.695100, time: 0.8s\n",
      "epoch 90, training loss: 0.695126, time: 0.9s\n",
      "epoch100, training loss: 0.695124, time: 0.9s\n",
      "Start Inference on the training data...\n"
     ]
    }
   ],
   "source": [
    "clf_slad = SLAD()\n",
    "clf_slad.fit(normal_data, y=None)\n",
    "y_preds_slad = clf_slad.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c647b99e-c503-4a29-ba13-0f500b2e0d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_slad_binary = np.where(y_preds_slad == 0, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70cb9a65-2865-4a27-ac09-34d66eb3e8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SLAD</td>\n",
       "      <td>0.983344</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.893889</td>\n",
       "      <td>0.943972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  precision    recall        f1\n",
       "0  SLAD  0.983344        1.0  0.893889  0.943972"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_slad = pd.DataFrame(evaluate_model(\"SLAD\", y_test_binary, y_preds_slad_binary))\n",
    "results_slad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69102ee-1483-4a02-95aa-26a05b9c43d8",
   "metadata": {},
   "source": [
    "# ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d305edf-6e09-462e-a73c-fef6ad0cf828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aced5dd2-80a4-43c1-bed2-1cce4ab33726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=64, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 3.200270, time: 1.9s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=64, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(65, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 3.010341, time: 1.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 302/302 [00:00<00:00, 594.22it/s]\n",
      "testing: 100%|██████████| 302/302 [00:00<00:00, 601.70it/s]\n",
      "testing: 100%|██████████| 476/476 [00:00<00:00, 604.95it/s]\n",
      "testing: 100%|██████████| 476/476 [00:00<00:00, 601.38it/s]\n"
     ]
    }
   ],
   "source": [
    "clf_icl = ICL(epochs=5)\n",
    "clf_icl.fit(normal_data, y=None)\n",
    "y_preds_icl = clf_icl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed556d2e-a610-46eb-8372-fb23dba01a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_icl_binary = np.where(y_preds_icl == 0, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "222bedd4-13c1-4e56-8652-c1bf721c0b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICL</td>\n",
       "      <td>0.984297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.899958</td>\n",
       "      <td>0.947345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  precision    recall        f1\n",
       "0   ICL  0.984297        1.0  0.899958  0.947345"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_icl = pd.DataFrame(evaluate_model(\"ICL\", y_test_binary, y_preds_icl_binary))\n",
    "results_icl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cb2107-ad4e-4edd-8c62-68e998559805",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# NeuTraL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7d18c99-d180-4e06-9a3e-19d9b5b4e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import NeuTraL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40234787-2a6c-4c53-b588-a28a29c0d515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "epoch  1, training loss: 0.134671, time: 106.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 10.75 GiB total capacity; 9.35 GiB already allocated; 2.69 MiB free; 9.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m clf_neutral \u001b[38;5;241m=\u001b[39m NeuTraL(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mclf_neutral\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m y_preds_neutral \u001b[38;5;241m=\u001b[39m clf_neutral\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/core/base_model.py:190\u001b[0m, in \u001b[0;36mBaseDeepAD.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart Inference on the training data...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_scores_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_decision_scores()\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/core/base_model.py:227\u001b[0m, in \u001b[0;36mBaseDeepAD.decision_function\u001b[0;34m(self, X, return_rep)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_ensemble):\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_prepare(X)\n\u001b[0;32m--> 227\u001b[0m     z, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     z, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function_update(z, scores)\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mts\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/core/base_model.py:374\u001b[0m, in \u001b[0;36mBaseDeepAD._inference\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m     _iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_x \u001b[38;5;129;01min\u001b[39;00m _iter_:\n\u001b[0;32m--> 374\u001b[0m     batch_z, s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m     z_lst\u001b[38;5;241m.\u001b[39mappend(batch_z)\n\u001b[1;32m    376\u001b[0m     score_lst\u001b[38;5;241m.\u001b[39mappend(s)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/models/tabular/neutral.py:76\u001b[0m, in \u001b[0;36mNeuTraL.inference_forward\u001b[0;34m(self, batch_x, net, criterion)\u001b[0m\n\u001b[1;32m     74\u001b[0m batch_x \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     75\u001b[0m batch_z \u001b[38;5;241m=\u001b[39m net(batch_x)\n\u001b[0;32m---> 76\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_z\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch_z, s\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/models/tabular/neutral.py:173\u001b[0m, in \u001b[0;36mDCL.forward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    170\u001b[0m z_trans \u001b[38;5;241m=\u001b[39m z[:, \u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# n,k-1, z\u001b[39;00m\n\u001b[1;32m    171\u001b[0m batch_size, n_trans, z_dim \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 173\u001b[0m sim_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(torch\u001b[38;5;241m.\u001b[39mmatmul(z, \u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemp\u001b[49m))  \u001b[38;5;66;03m# n,k,k\u001b[39;00m\n\u001b[1;32m    174\u001b[0m mask \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mones_like(sim_matrix)\u001b[38;5;241m.\u001b[39mto(z) \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(n_trans)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(z))\u001b[38;5;241m.\u001b[39mbool()\n\u001b[1;32m    175\u001b[0m sim_matrix \u001b[38;5;241m=\u001b[39m sim_matrix\u001b[38;5;241m.\u001b[39mmasked_select(mask)\u001b[38;5;241m.\u001b[39mview(batch_size, n_trans, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 10.75 GiB total capacity; 9.35 GiB already allocated; 2.69 MiB free; 9.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "clf_neutral = NeuTraL(epochs=1)\n",
    "clf_neutral.fit(normal_data, y=None)\n",
    "y_preds_neutral = clf_neutral.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdec86a-65d9-4e46-8cc9-04d6756df258",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_neutral_binary = np.where(y_preds_neutral == 0, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff5cff-428d-4be0-8070-7a6f87afdf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_neutral = pd.DataFrame(evaluate_model(\"NeuTraL\", y_test_binary, y_preds_neutral_binary))\n",
    "results_neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d0df81-2927-4b24-b77b-305a6eea115b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8ccb62-1ac3-4caf-9ef9-be7eaff88f8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2a328ee-3f24-493a-9bbf-fec07f1198ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b2966b5-6384-4813-8a27-b75de8e1a215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=74, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=74, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=74, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=74, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.077065, time: 1.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.037608, time: 1.2s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.94it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.49it/s]\n"
     ]
    }
   ],
   "source": [
    "clf_rca = RCA(epochs=10)\n",
    "clf_rca.fit(normal_data, y=None)\n",
    "y_preds_rca = clf_rca.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abd64bd4-ab0f-4c53-833d-0c4a3da792f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_rca_binary = np.where(y_preds_rca == 0, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e85843b0-45a1-43a6-b4d1-bedc1cbb6156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RCA</td>\n",
       "      <td>0.983509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.894935</td>\n",
       "      <td>0.944555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  precision    recall        f1\n",
       "0   RCA  0.983509        1.0  0.894935  0.944555"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_rca = pd.DataFrame(evaluate_model(\"RCA\", y_test_binary, y_preds_rca_binary))\n",
    "results_rca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60f2b58-d1dd-4e1f-a1f3-576bb43b162c",
   "metadata": {},
   "source": [
    "# RDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcf284e3-9b93-419c-9346-af209e808f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import RDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40c28af6-6e49-4682-ac9b-603a442dfcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=74, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000006, time: 1.0s\n",
      "epoch 10, training loss: 0.000009, time: 1.0s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 302/302 [00:00<00:00, 1122.10it/s]\n",
      "testing: 100%|██████████| 476/476 [00:00<00:00, 1113.61it/s]\n"
     ]
    }
   ],
   "source": [
    "clf_rdp = RDP(epochs=10)\n",
    "clf_rdp.fit(normal_data, y=None)\n",
    "y_preds_rdp = clf_rdp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75e2977a-94c0-4ecf-9b19-11fa88d3a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_rdp_binary = np.where(y_preds_rdp == 0, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dda19bc-9626-4e44-94c5-0f0b0664e6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RDP</td>\n",
       "      <td>0.965276</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.778778</td>\n",
       "      <td>0.875632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  precision    recall        f1\n",
       "0   RDP  0.965276        1.0  0.778778  0.875632"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_rdp = pd.DataFrame(evaluate_model(\"RDP\", y_test_binary, y_preds_rdp_binary))\n",
    "results_rdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae974a4d-c608-488d-8e10-100f2d62a4b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# REPEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "398c4ab2-b26d-464a-92ce-bd8d8fb0ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import REPEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c560811-f718-4eaf-8dac-d8ca5201a26e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=41, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m clf_repen \u001b[38;5;241m=\u001b[39m REPEN(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mclf_repen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m y_preds_repdn \u001b[38;5;241m=\u001b[39m clf_repen\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/core/base_model.py:185\u001b[0m, in \u001b[0;36mBaseDeepAD.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_ensemble):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_prepare(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data,\n\u001b[1;32m    184\u001b[0m                                                                         y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_label)\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart Inference on the training data...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/core/base_model.py:336\u001b[0m, in \u001b[0;36mBaseDeepAD._training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    335\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader:\n\u001b[1;32m    337\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_forward(batch_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/models/tabular/repen.py:118\u001b[0m, in \u001b[0;36mREPENLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 118\u001b[0m     examples, positives, negatives \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtriplet_batch_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     examples, positives, negatives \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(examples), \\\n\u001b[1;32m    120\u001b[0m                                      torch\u001b[38;5;241m.\u001b[39mfrom_numpy(positives), \\\n\u001b[1;32m    121\u001b[0m                                      torch\u001b[38;5;241m.\u001b[39mfrom_numpy(negatives)\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_epoch:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/models/tabular/repen.py:145\u001b[0m, in \u001b[0;36mREPENLoader.triplet_batch_generation\u001b[0;34m(self, prior_knowledge)\u001b[0m\n\u001b[1;32m    143\u001b[0m negatives_ids \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros([batch_size])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, batch_size):\n\u001b[0;32m--> 145\u001b[0m     sid \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minlier_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositive_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     examples_ids[i] \u001b[38;5;241m=\u001b[39m inlier_ids[sid]\n\u001b[1;32m    147\u001b[0m     sid2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(inlier_ids), \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32mmtrand.pyx:946\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf_repen = REPEN(epochs=1)\n",
    "clf_repen.fit(normal_data, y=None)\n",
    "y_preds_repdn = clf_repen.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16dce1e-3d66-4cf6-9105-a49e2fc48a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_repen_binary = np.where(y_preds_repdn == 0, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82b44f-9b8f-4977-acc1-24d66cfcf148",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_repen = pd.DataFrame(evaluate_model(\"REPEN\", y_test_binary, y_preds_repen_binary))\n",
    "results_repen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9745426-5d9c-4596-a2a4-91d44d8b12af",
   "metadata": {},
   "source": [
    "# Deep SVDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ddd8cb0-986c-4a90-b1dc-77a21c030eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import DeepSVDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f685e51-80cb-4aa3-8ee0-cb8757f23f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=74, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.020199, time: 0.4s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 302/302 [00:00<00:00, 2533.55it/s]\n",
      "testing: 100%|██████████| 476/476 [00:00<00:00, 2554.55it/s]\n"
     ]
    }
   ],
   "source": [
    "clf_deepsvdd = DeepSVDD(epochs=1)\n",
    "clf_deepsvdd.fit(normal_data, y=None)\n",
    "y_preds_deepsvdd = clf_deepsvdd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9319716d-fcf2-4d99-acd2-17cef0c7f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_deepsvdd_binary = np.where(y_preds_deepsvdd == 0, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b46cda7-97f9-43aa-b846-d42791be8231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeepSVDD</td>\n",
       "      <td>0.983706</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.896191</td>\n",
       "      <td>0.945254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  accuracy  precision    recall        f1\n",
       "0  DeepSVDD  0.983706        1.0  0.896191  0.945254"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_deepsvdd = pd.DataFrame(evaluate_model(\"DeepSVDD\", y_test_binary, y_preds_deepsvdd_binary))\n",
    "results_deepsvdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612e3c61-cb38-40dd-b949-4220c674ec80",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "064ef917-611c-4bed-aaa3-0bfdbef151c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DIF</td>\n",
       "      <td>0.156965</td>\n",
       "      <td>0.156965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.271339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SLAD</td>\n",
       "      <td>0.983344</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893889</td>\n",
       "      <td>0.943972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  precision    recall        f1\n",
       "0   DIF  0.156965   0.156965  1.000000  0.271339\n",
       "1  SLAD  0.983344   1.000000  0.893889  0.943972"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.concat([results_dif, results_slad], ignore_index=True)\n",
    "results_df.to_csv('results/DeepOD_results.csv', index=False)\n",
    "\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
