{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "701d42fa-fa25-4f44-babe-7950b1ebad0f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12a730eb-6200-45b1-b54a-afb0099f42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, make_scorer\n",
    "from deepod.metrics import tabular_metrics\n",
    "\n",
    "from tqdm import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323c86ac-b77a-4176-a19b-cc254198860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('data/x_train.npy')\n",
    "y_train = np.load('data/y_train.npy')\n",
    "\n",
    "X_test = np.load('data/x_test.npy')\n",
    "y_test = np.load('data/y_test.npy')\n",
    "\n",
    "#X_val = np.load('data/x_val.npy')\n",
    "#y_val = np.load('data/y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4f53dd4-c836-4f18-be9f-ead9e15a2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = np.concatenate((X_train, X_val), axis=0)\n",
    "#y_train = np.concatenate((y_train, y_val), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1afcfae-9b3e-418e-8df9-0f41c099a495",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d79e84cd-3e88-43d6-9a90-5834e4d0b646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4]), array([   166,    210,  62760,   6637, 885235]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26860cb-afc6-462b-a65f-f9c14f733be8",
   "metadata": {},
   "source": [
    "4 is normal class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09299cdd-bdf5-40ed-b95d-82aae54b5284",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_binary = np.where(y_test == 4, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11109899-e1c2-454a-85a9-44b89befaeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = X_train[y_train == 4] # normal class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04c96228-4afc-4ec0-9eec-070308871cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "885235"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normal_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d5cb01-b1aa-4bfa-9133-51962151230d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cfb9704-c52b-4c9f-8c23-655eab0d1649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, y_test, y_pred):\n",
    "    positive_class = \"normal\"\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred, pos_label=positive_class)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=positive_class)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=positive_class)\n",
    "    \n",
    "    metrics = {\n",
    "        'model': [model],\n",
    "        'accuracy': [accuracy],\n",
    "        'precision': [precision],\n",
    "        'recall': [recall],\n",
    "        'f1': [f1],\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b50a07-7246-473f-8f6f-531d37acd4b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# DIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b10d8531-be07-4bef-ab71-ff5639fe5dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import DeepIsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfbe9b4c-fd4c-4e91-b534-7426484c5eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:41<00:00,  8.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Inference on the training data...\n",
      "Start Inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [17:23<00:00, 20.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:26<00:00,  5.34s/it]\n"
     ]
    }
   ],
   "source": [
    "clf_dif = DeepIsolationForest()\n",
    "clf_dif.fit(normal_data, y=None)\n",
    "y_preds_dif = clf_dif.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b73e1091-7f36-444e-b4c3-fd1157bfe1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_dif_binary = np.where(y_preds_dif == 0, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94e6f314-4175-4888-8430-a2ec067eb5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ['DIF'],\n",
       " 'accuracy': [0.9277872948193321],\n",
       " 'precision': [0.9277872948193321],\n",
       " 'recall': [1.0],\n",
       " 'f1': [0.9625411447752925]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dif = evaluate_model(\"DIF\", y_test_binary, y_preds_dif_binary)\n",
    "results_dif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbc2d72-d3dd-4732-83dc-811317721e71",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# SLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cafe92df-46e5-404d-8bc3-0e8338441a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import SLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0f64b88-738f-4d35-a984-5d61d25194eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "unified size: 128, subspace pool size: 41, ensemble size: 20\n",
      "len pool: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41]\n",
      "epoch  1, training loss: 0.506606, time: 18.9s\n",
      "epoch 10, training loss: 0.503751, time: 17.9s\n",
      "epoch 20, training loss: 0.503722, time: 19.0s\n",
      "epoch 30, training loss: 0.503705, time: 18.3s\n",
      "epoch 40, training loss: 0.503693, time: 17.9s\n",
      "epoch 50, training loss: 0.503690, time: 17.9s\n",
      "epoch 60, training loss: 0.503697, time: 18.1s\n",
      "epoch 70, training loss: 0.503689, time: 18.1s\n",
      "epoch 80, training loss: 0.503688, time: 18.3s\n",
      "epoch 90, training loss: 0.503690, time: 18.1s\n",
      "epoch100, training loss: 0.503688, time: 18.2s\n",
      "Start Inference on the training data...\n"
     ]
    }
   ],
   "source": [
    "clf_slad = SLAD()\n",
    "clf_slad.fit(normal_data, y=None)\n",
    "y_preds_slad = clf_slad.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c647b99e-c503-4a29-ba13-0f500b2e0d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_slad_binary = np.where(y_preds_slad == 0, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70cb9a65-2865-4a27-ac09-34d66eb3e8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SLAD</td>\n",
       "      <td>0.910636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.90368</td>\n",
       "      <td>0.949403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  precision   recall        f1\n",
       "0  SLAD  0.910636        1.0  0.90368  0.949403"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_slad = pd.DataFrame(evaluate_model(\"SLAD\", y_test_binary, y_preds_slad_binary))\n",
    "results_slad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c091f966-77ac-4b2a-8641-c6d3f6939960",
   "metadata": {},
   "source": [
    "# ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7296acb-5477-405e-b37f-8986339b30a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c48a6b43-cabc-4c17-bc4e-5ca856965397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 2\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=31, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.280528, time: 60.4s\n",
      "kernel size: 10\n",
      "ICLNet(\n",
      "  (enc_f_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=31, out_features=100, bias=False)\n",
      "        (act_layer): Tanh()\n",
      "        (bn_layer): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc_g_net): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=10, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=25, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=25, out_features=128, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (bn_layer): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 1.293355, time: 59.5s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 13832/13832 [00:24<00:00, 559.60it/s]\n",
      "testing: 100%|██████████| 13832/13832 [00:24<00:00, 562.10it/s]\n",
      "testing: 100%|██████████| 3731/3731 [00:06<00:00, 582.08it/s]\n",
      "testing: 100%|██████████| 3731/3731 [00:06<00:00, 586.22it/s]\n"
     ]
    }
   ],
   "source": [
    "clf_icl = ICL(epochs=5)\n",
    "clf_icl.fit(normal_data, y=None)\n",
    "y_preds_icl = clf_icl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b26ecce-8477-4b8e-b48f-b3f4465ae4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_icl_binary = np.where(y_preds_icl == 0, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99f0177c-9e81-4da9-af69-c3dfc108ed0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICL</td>\n",
       "      <td>0.876668</td>\n",
       "      <td>0.965714</td>\n",
       "      <td>0.898985</td>\n",
       "      <td>0.931156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  precision    recall        f1\n",
       "0   ICL  0.876668   0.965714  0.898985  0.931156"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_icl = pd.DataFrame(evaluate_model(\"ICL\", y_test_binary, y_preds_icl_binary))\n",
    "results_icl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a664a-f7e9-4f57-8853-3987c663df07",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# NeuTraL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e505cf77-1779-4c49-97c7-01dc136004b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import NeuTraL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9953ab0b-1c3d-4f08-90b1-cc08d70df8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "epoch  1, training loss: 0.134671, time: 106.3s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 10.75 GiB total capacity; 9.35 GiB already allocated; 2.69 MiB free; 9.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m clf_neutral \u001b[38;5;241m=\u001b[39m NeuTraL(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mclf_neutral\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m y_preds_neutral \u001b[38;5;241m=\u001b[39m clf_neutral\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/core/base_model.py:190\u001b[0m, in \u001b[0;36mBaseDeepAD.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart Inference on the training data...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_scores_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_decision_scores()\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/core/base_model.py:227\u001b[0m, in \u001b[0;36mBaseDeepAD.decision_function\u001b[0;34m(self, X, return_rep)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_ensemble):\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_prepare(X)\n\u001b[0;32m--> 227\u001b[0m     z, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     z, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function_update(z, scores)\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mts\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/core/base_model.py:374\u001b[0m, in \u001b[0;36mBaseDeepAD._inference\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m     _iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_x \u001b[38;5;129;01min\u001b[39;00m _iter_:\n\u001b[0;32m--> 374\u001b[0m     batch_z, s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m     z_lst\u001b[38;5;241m.\u001b[39mappend(batch_z)\n\u001b[1;32m    376\u001b[0m     score_lst\u001b[38;5;241m.\u001b[39mappend(s)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/models/tabular/neutral.py:76\u001b[0m, in \u001b[0;36mNeuTraL.inference_forward\u001b[0;34m(self, batch_x, net, criterion)\u001b[0m\n\u001b[1;32m     74\u001b[0m batch_x \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     75\u001b[0m batch_z \u001b[38;5;241m=\u001b[39m net(batch_x)\n\u001b[0;32m---> 76\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_z\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch_z, s\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/models/tabular/neutral.py:173\u001b[0m, in \u001b[0;36mDCL.forward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    170\u001b[0m z_trans \u001b[38;5;241m=\u001b[39m z[:, \u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# n,k-1, z\u001b[39;00m\n\u001b[1;32m    171\u001b[0m batch_size, n_trans, z_dim \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 173\u001b[0m sim_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(torch\u001b[38;5;241m.\u001b[39mmatmul(z, \u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemp\u001b[49m))  \u001b[38;5;66;03m# n,k,k\u001b[39;00m\n\u001b[1;32m    174\u001b[0m mask \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mones_like(sim_matrix)\u001b[38;5;241m.\u001b[39mto(z) \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(n_trans)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(z))\u001b[38;5;241m.\u001b[39mbool()\n\u001b[1;32m    175\u001b[0m sim_matrix \u001b[38;5;241m=\u001b[39m sim_matrix\u001b[38;5;241m.\u001b[39mmasked_select(mask)\u001b[38;5;241m.\u001b[39mview(batch_size, n_trans, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 10.75 GiB total capacity; 9.35 GiB already allocated; 2.69 MiB free; 9.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "clf_neutral = NeuTraL(epochs=1)\n",
    "clf_neutral.fit(normal_data, y=None)\n",
    "y_preds_neutral = clf_neutral.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cd8d71-b80f-43d4-a8f6-7dc1064ea1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_neutral_binary = np.where(y_preds_neutral == 0, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14b26da-661e-4b17-8a2d-005760fca42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_neutral = pd.DataFrame(evaluate_model(\"NeuTraL\", y_test_binary, y_preds_neutral_binary))\n",
    "results_neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e5823-16f4-414c-a497-7bdeb66d9721",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79750ac2-97a6-4b03-b1aa-be42b71dbd86",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf082ad8-0f95-4c83-ad20-370af9a1a1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f677567c-0ed8-4372-ac59-ef0df3d44d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "RCANet(\n",
      "  (enc1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=41, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (enc2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=41, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec1): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=41, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec2): MLPnet(\n",
      "    (network): Sequential(\n",
      "      (0): LinearBlock(\n",
      "        (linear): Linear(in_features=128, out_features=50, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): LinearBlock(\n",
      "        (linear): Linear(in_features=50, out_features=100, bias=False)\n",
      "        (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "        (dropout_layer): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): LinearBlock(\n",
      "        (linear): Linear(in_features=100, out_features=41, bias=False)\n",
      "        (act_layer): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.007093, time: 55.2s\n",
      "beta: 0.996\n",
      "beta: 0.992\n",
      "beta: 0.988\n",
      "beta: 0.984\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "beta: 0.98\n",
      "epoch 10, training loss: 0.003869, time: 54.6s\n",
      "beta: 0.98\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:01<00:00, 12.19s/it]\n",
      "100%|██████████| 10/10 [00:32<00:00,  3.28s/it]\n"
     ]
    }
   ],
   "source": [
    "clf_rca = RCA(epochs=10)\n",
    "clf_rca.fit(normal_data, y=None)\n",
    "y_preds_rca = clf_rca.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a0145aa-c1bf-4771-b575-a559a2dfe5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_rca_binary = np.where(y_preds_rca == 0, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97589f47-89db-4a8f-87a8-83084a137202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RCA</td>\n",
       "      <td>0.907327</td>\n",
       "      <td>0.99998</td>\n",
       "      <td>0.900132</td>\n",
       "      <td>0.947432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  precision    recall        f1\n",
       "0   RCA  0.907327    0.99998  0.900132  0.947432"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_rca = pd.DataFrame(evaluate_model(\"RCA\", y_test_binary, y_preds_rca_binary))\n",
    "results_rca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e669dc7f-f1a4-43f0-a4fb-9746b28f2729",
   "metadata": {},
   "source": [
    "# RDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c32f7d7-f615-4d92-87ca-fbbfebf650b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import RDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e4039e7-d9e2-47d3-9e2a-36c41562ba1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=41, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000004, time: 39.2s\n",
      "epoch 10, training loss: 0.000004, time: 40.1s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 13832/13832 [00:13<00:00, 1043.60it/s]\n",
      "testing: 100%|██████████| 3731/3731 [00:03<00:00, 1063.66it/s]\n"
     ]
    }
   ],
   "source": [
    "clf_rdp = RDP(epochs=10)\n",
    "clf_rdp.fit(normal_data, y=None)\n",
    "y_preds_rdp = clf_rdp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5ef33b2-c14e-4cc8-9277-8c527a471802",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_rdp_binary = np.where(y_preds_rdp == 0, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8210f72-19e9-4059-a568-0d1bbc7dce6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RDP</td>\n",
       "      <td>0.879687</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.870323</td>\n",
       "      <td>0.930666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  precision    recall        f1\n",
       "0   RDP  0.879687        1.0  0.870323  0.930666"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_rdp = pd.DataFrame(evaluate_model(\"RDP\", y_test_binary, y_preds_rdp_binary))\n",
    "results_rdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e8cbe6-3687-4016-8ca6-1bfabb51677e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# REPEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "168b6074-c8b7-4bca-aebc-e647f6d74420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import REPEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac5dea31-22b7-4e04-aa46-d53a8481cdb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=41, out_features=100, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m clf_repen \u001b[38;5;241m=\u001b[39m REPEN(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mclf_repen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m y_preds_repdn \u001b[38;5;241m=\u001b[39m clf_repen\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/core/base_model.py:185\u001b[0m, in \u001b[0;36mBaseDeepAD.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_ensemble):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_prepare(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data,\n\u001b[1;32m    184\u001b[0m                                                                         y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_label)\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart Inference on the training data...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/core/base_model.py:336\u001b[0m, in \u001b[0;36mBaseDeepAD._training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    335\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader:\n\u001b[1;32m    337\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_forward(batch_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/models/tabular/repen.py:118\u001b[0m, in \u001b[0;36mREPENLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 118\u001b[0m     examples, positives, negatives \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtriplet_batch_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     examples, positives, negatives \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(examples), \\\n\u001b[1;32m    120\u001b[0m                                      torch\u001b[38;5;241m.\u001b[39mfrom_numpy(positives), \\\n\u001b[1;32m    121\u001b[0m                                      torch\u001b[38;5;241m.\u001b[39mfrom_numpy(negatives)\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_epoch:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/deepod/models/tabular/repen.py:145\u001b[0m, in \u001b[0;36mREPENLoader.triplet_batch_generation\u001b[0;34m(self, prior_knowledge)\u001b[0m\n\u001b[1;32m    143\u001b[0m negatives_ids \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros([batch_size])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, batch_size):\n\u001b[0;32m--> 145\u001b[0m     sid \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minlier_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositive_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     examples_ids[i] \u001b[38;5;241m=\u001b[39m inlier_ids[sid]\n\u001b[1;32m    147\u001b[0m     sid2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(inlier_ids), \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32mmtrand.pyx:946\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf_repen = REPEN(epochs=1)\n",
    "clf_repen.fit(normal_data, y=None)\n",
    "y_preds_repdn = clf_repen.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc8f591-452b-42b4-8697-81911c0a9dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_repen_binary = np.where(y_preds_repdn == 0, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e3f36c-7271-4e6f-977e-7fd1ff1d509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_repen = pd.DataFrame(evaluate_model(\"REPEN\", y_test_binary, y_preds_repen_binary))\n",
    "results_repen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ac7c1-67c6-4e0f-819b-849c9f2d5778",
   "metadata": {},
   "source": [
    "# Deep SVDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44397931-24ec-45e5-ab4c-3c55acd27ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import DeepSVDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ea5d623-5364-4e62-98ff-9a65613dac32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=41, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 0.000710, time: 15.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 13832/13832 [00:05<00:00, 2522.36it/s]\n",
      "testing: 100%|██████████| 3731/3731 [00:01<00:00, 2541.90it/s]\n"
     ]
    }
   ],
   "source": [
    "clf_deepsvdd = DeepSVDD(epochs=1)\n",
    "clf_deepsvdd.fit(normal_data, y=None)\n",
    "y_preds_deepsvdd = clf_deepsvdd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fc91ebd-1b90-4674-b6e5-c10f499471a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_deepsvdd_binary = np.where(y_preds_deepsvdd == 0, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42f5f964-364f-4344-a7bd-a14d9850ddff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeepSVDD</td>\n",
       "      <td>0.908144</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.901233</td>\n",
       "      <td>0.947932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  accuracy  precision    recall        f1\n",
       "0  DeepSVDD  0.908144   0.999735  0.901233  0.947932"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_deepsvdd = pd.DataFrame(evaluate_model(\"DeepSVDD\", y_test_binary, y_preds_deepsvdd_binary))\n",
    "results_deepsvdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612e3c61-cb38-40dd-b949-4220c674ec80",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ef917-611c-4bed-aaa3-0bfdbef151c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat([results_dif, results_slad], ignore_index=True)\n",
    "results_df.to_csv('results/DeepOD_results.csv', index=False)\n",
    "\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
