{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4c53c3-78bb-475e-bd04-2d415661a0a5",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3439f538-9b52-4fd2-8395-ab1c0fc73dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "22e6c040-6369-436c-b639-1b346d5cb01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('data/x_train.npy')\n",
    "y_train = np.load('data/y_train.npy')\n",
    "\n",
    "X_test = np.load('data/x_test.npy')\n",
    "y_test = np.load('data/y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f571c683-9dc8-481e-b9db-6f1b6533efb2",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27d27efa-6b41-4b14-bb56-48da24fe4b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2d178053-5bae-4ff0-bc38-5cd0ec8a6055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_images(X, gamma=0.1, final_size=(32, 32), mean=0.5, std=0.5):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_gamma_corrected = np.power(X_scaled, gamma) * 255\n",
    "\n",
    "    X_padded = np.pad(X_gamma_corrected, ((0, 0), (0, 6)), 'constant', constant_values=0)\n",
    "    images = X_padded.reshape(-1, 8, 8)\n",
    "    images = images.astype(np.uint8)\n",
    "    scaled_images = np.array([cv2.resize(img, final_size, interpolation=cv2.INTER_NEAREST) for img in images])\n",
    "    rgb_images = np.stack([scaled_images] * 3, axis=-1)\n",
    "\n",
    "    transposed_images = np.transpose(rgb_images, (0, 3, 1, 2))\n",
    "    transposed_images = (transposed_images / 255.0 - mean) / std\n",
    "\n",
    "    return transposed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a449e43d-c486-40a0-aa8f-e209a902613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_transformed_image(transformed_image):\n",
    "    image = np.transpose(transformed_image, (1, 2, 0))\n",
    "    \n",
    "    mean = 0.5\n",
    "    std = 0.5\n",
    "    image = image * std + mean\n",
    "\n",
    "    image = np.clip(image, 0, 1)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "db12dbf6-2128-4ab1-b1f2-83ea0291590a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_images = transform_to_images(X_train)\n",
    "X_test_images = transform_to_images(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9ef7ac1e-d991-439c-9b12-f065c8cb8089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_transformed_image(X_train_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2781fba3-66da-4713-99d1-cebb9752bc38",
   "metadata": {},
   "source": [
    "# MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9b04ef6c-4af1-4de2-8b31-a1e0fd621945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "\n",
    "from einops import repeat, rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "from timm.models.layers import trunc_normal_\n",
    "from timm.models.vision_transformer import Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ff7ee621-ac20-4853-9a2b-33294f09ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images):\n",
    "        self.images = images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        # Convert to tensor\n",
    "        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "7e997ef8-c945-42be-b5a6-34c28150aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_indexes(size : int):\n",
    "    forward_indexes = np.arange(size)\n",
    "    np.random.shuffle(forward_indexes)\n",
    "    backward_indexes = np.argsort(forward_indexes)\n",
    "    return forward_indexes, backward_indexes\n",
    "\n",
    "def take_indexes(sequences, indexes):\n",
    "    return torch.gather(sequences, 0, repeat(indexes, 't b -> t b c', c=sequences.shape[-1]))\n",
    "\n",
    "class PatchShuffle(torch.nn.Module):\n",
    "    def __init__(self, ratio) -> None:\n",
    "        super().__init__()\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def forward(self, patches : torch.Tensor):\n",
    "        T, B, C = patches.shape\n",
    "        remain_T = int(T * (1 - self.ratio))\n",
    "\n",
    "        indexes = [random_indexes(T) for _ in range(B)]\n",
    "        forward_indexes = torch.as_tensor(np.stack([i[0] for i in indexes], axis=-1), dtype=torch.long).to(patches.device)\n",
    "        backward_indexes = torch.as_tensor(np.stack([i[1] for i in indexes], axis=-1), dtype=torch.long).to(patches.device)\n",
    "\n",
    "        patches = take_indexes(patches, forward_indexes)\n",
    "        patches = patches[:remain_T]\n",
    "\n",
    "        return patches, forward_indexes, backward_indexes\n",
    "\n",
    "class MAE_Encoder(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 image_size=32,\n",
    "                 patch_size=2,\n",
    "                 emb_dim=192,\n",
    "                 num_layer=12,\n",
    "                 num_head=3,\n",
    "                 mask_ratio=0.75,\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.cls_token = torch.nn.Parameter(torch.zeros(1, 1, emb_dim))\n",
    "        self.pos_embedding = torch.nn.Parameter(torch.zeros((image_size // patch_size) ** 2, 1, emb_dim))\n",
    "        self.shuffle = PatchShuffle(mask_ratio)\n",
    "\n",
    "        self.patchify = torch.nn.Conv2d(3, emb_dim, patch_size, patch_size)\n",
    "\n",
    "        self.transformer = torch.nn.Sequential(*[Block(emb_dim, num_head) for _ in range(num_layer)])\n",
    "\n",
    "        self.layer_norm = torch.nn.LayerNorm(emb_dim)\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        trunc_normal_(self.cls_token, std=.02)\n",
    "        trunc_normal_(self.pos_embedding, std=.02)\n",
    "\n",
    "    def forward(self, img):\n",
    "        patches = self.patchify(img)\n",
    "        patches = rearrange(patches, 'b c h w -> (h w) b c')\n",
    "        patches = patches + self.pos_embedding\n",
    "\n",
    "        patches, forward_indexes, backward_indexes = self.shuffle(patches)\n",
    "\n",
    "        patches = torch.cat([self.cls_token.expand(-1, patches.shape[1], -1), patches], dim=0)\n",
    "        patches = rearrange(patches, 't b c -> b t c')\n",
    "        features = self.layer_norm(self.transformer(patches))\n",
    "        features = rearrange(features, 'b t c -> t b c')\n",
    "\n",
    "        return features, backward_indexes\n",
    "\n",
    "class MAE_Decoder(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 image_size=32,\n",
    "                 patch_size=2,\n",
    "                 emb_dim=192,\n",
    "                 num_layer=4,\n",
    "                 num_head=3,\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.mask_token = torch.nn.Parameter(torch.zeros(1, 1, emb_dim))\n",
    "        self.pos_embedding = torch.nn.Parameter(torch.zeros((image_size // patch_size) ** 2 + 1, 1, emb_dim))\n",
    "\n",
    "        self.transformer = torch.nn.Sequential(*[Block(emb_dim, num_head) for _ in range(num_layer)])\n",
    "\n",
    "        self.head = torch.nn.Linear(emb_dim, 3 * patch_size ** 2)\n",
    "        self.patch2img = Rearrange('(h w) b (c p1 p2) -> b c (h p1) (w p2)', p1=patch_size, p2=patch_size, h=image_size//patch_size)\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        trunc_normal_(self.mask_token, std=.02)\n",
    "        trunc_normal_(self.pos_embedding, std=.02)\n",
    "\n",
    "    def forward(self, features, backward_indexes):\n",
    "        T = features.shape[0]\n",
    "        backward_indexes = torch.cat([torch.zeros(1, backward_indexes.shape[1]).to(backward_indexes), backward_indexes + 1], dim=0)\n",
    "        features = torch.cat([features, self.mask_token.expand(backward_indexes.shape[0] - features.shape[0], features.shape[1], -1)], dim=0)\n",
    "        features = take_indexes(features, backward_indexes)\n",
    "        features = features + self.pos_embedding\n",
    "\n",
    "        features = rearrange(features, 't b c -> b t c')\n",
    "        features = self.transformer(features)\n",
    "        features = rearrange(features, 'b t c -> t b c')\n",
    "        features = features[1:] # remove global feature\n",
    "\n",
    "        patches = self.head(features)\n",
    "\n",
    "        mask = torch.zeros_like(patches)\n",
    "        mask[T-1:] = 1\n",
    "        mask = take_indexes(mask, backward_indexes[1:] - 1)\n",
    "        img = self.patch2img(patches)\n",
    "        img = img.mean(dim=1, keepdim=True).expand(-1, 3, -1, -1) # mean to grayscale\n",
    "        \n",
    "        mask = self.patch2img(mask)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "class MAE_ViT(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 image_size=32,\n",
    "                 patch_size=2,\n",
    "                 emb_dim=192,\n",
    "                 encoder_layer=12,\n",
    "                 encoder_head=3,\n",
    "                 decoder_layer=4,\n",
    "                 decoder_head=3,\n",
    "                 mask_ratio=0.75,\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = MAE_Encoder(image_size, patch_size, emb_dim, encoder_layer, encoder_head, mask_ratio)\n",
    "        self.decoder = MAE_Decoder(image_size, patch_size, emb_dim, decoder_layer, decoder_head)\n",
    "\n",
    "    def forward(self, img):\n",
    "        features, backward_indexes = self.encoder(img)\n",
    "        predicted_img, mask = self.decoder(features,  backward_indexes)\n",
    "        return predicted_img, mask\n",
    "\n",
    "class ViT_Classifier(torch.nn.Module):\n",
    "    def __init__(self, encoder : MAE_Encoder, num_classes=10) -> None:\n",
    "        super().__init__()\n",
    "        self.cls_token = encoder.cls_token\n",
    "        self.pos_embedding = encoder.pos_embedding\n",
    "        self.patchify = encoder.patchify\n",
    "        self.transformer = encoder.transformer\n",
    "        self.layer_norm = encoder.layer_norm\n",
    "        self.head = torch.nn.Linear(self.pos_embedding.shape[-1], num_classes)\n",
    "\n",
    "    def forward(self, img):\n",
    "        patches = self.patchify(img)\n",
    "        patches = rearrange(patches, 'b c h w -> (h w) b c')\n",
    "        patches = patches + self.pos_embedding\n",
    "        patches = torch.cat([self.cls_token.expand(-1, patches.shape[1], -1), patches], dim=0)\n",
    "        patches = rearrange(patches, 't b c -> b t c')\n",
    "        features = self.layer_norm(self.transformer(patches))\n",
    "        features = rearrange(features, 'b t c -> t b c')\n",
    "        logits = self.head(features[0])\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ba3b29-03e0-4ce0-b21c-5a7daaba5307",
   "metadata": {},
   "source": [
    "# Short Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "9496ebb2-5b6e-4e54-a021-cf183b73a1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 10])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor(0.3206, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "shuffle = PatchShuffle(0.75)\n",
    "a = torch.rand(16, 2, 10)\n",
    "b, forward_indexes, backward_indexes = shuffle(a)\n",
    "print(b.shape)\n",
    "\n",
    "img = torch.rand(2, 3, 32, 32)\n",
    "encoder = MAE_Encoder()\n",
    "decoder = MAE_Decoder()\n",
    "features, backward_indexes = encoder(img)\n",
    "print(forward_indexes.shape)\n",
    "predicted_img, mask = decoder(features, backward_indexes)\n",
    "print(predicted_img.shape)\n",
    "loss = torch.mean((predicted_img - img) ** 2 * mask / 0.75)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3644c4-092a-4fb1-a4fe-f16ef0e19fd2",
   "metadata": {},
   "source": [
    "# Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e5fd572f-2901-4915-8576-f522821cbde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "7176c74a-c85e-4f33-a5b8-8f38dfeda48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "batch_size = 4096\n",
    "max_device_batch_size = 512\n",
    "base_learning_rate = 1.5e-4\n",
    "weight_decay = 0.05\n",
    "mask_ratio = 0.75\n",
    "total_epoch = 10\n",
    "warmup_epoch = 200\n",
    "\n",
    "batch_size = 4096\n",
    "load_batch_size = 512\n",
    "steps_per_update = batch_size // load_batch_size\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "49e9191c-3fa6-49f1-9fd2-b0e09801653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_images, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_images, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=load_batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=load_batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "9af4d5df-5f32-4a45-a149-855cd8eed830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 877/877 [03:54<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Learning Rate: 0.000024, Average Training Loss: 0.4693\n",
      "In epoch 0, average traning loss is 0.4692647380153293.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 877/877 [03:57<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Learning Rate: 0.000036, Average Training Loss: 0.1822\n",
      "In epoch 1, average traning loss is 0.18216178225546634.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 877/877 [03:56<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Learning Rate: 0.000048, Average Training Loss: 0.1347\n",
      "In epoch 2, average traning loss is 0.1347071622650191.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 877/877 [03:56<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Learning Rate: 0.000060, Average Training Loss: 0.1113\n",
      "In epoch 3, average traning loss is 0.11125801470525724.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 877/877 [03:55<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Learning Rate: 0.000072, Average Training Loss: 0.0986\n",
      "In epoch 4, average traning loss is 0.09855007239221303.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 877/877 [03:56<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Learning Rate: 0.000084, Average Training Loss: 0.0836\n",
      "In epoch 5, average traning loss is 0.08355684151093527.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 877/877 [03:55<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Learning Rate: 0.000096, Average Training Loss: 0.0704\n",
      "In epoch 6, average traning loss is 0.07043039311517875.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 877/877 [03:56<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Learning Rate: 0.000108, Average Training Loss: 0.0653\n",
      "In epoch 7, average traning loss is 0.065326296345266.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 877/877 [03:56<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Learning Rate: 0.000059, Average Training Loss: 0.0551\n",
      "In epoch 8, average traning loss is 0.05513790624477437.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 877/877 [03:56<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Learning Rate: 0.000000, Average Training Loss: 0.0397\n",
      "In epoch 9, average traning loss is 0.03973021445118375.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = batch_size\n",
    "load_batch_size = min(max_device_batch_size, batch_size)\n",
    "\n",
    "assert batch_size % load_batch_size == 0\n",
    "steps_per_update = batch_size // load_batch_size\n",
    "\n",
    "#train_dataset = torchvision.datasets.CIFAR10('data', train=True, download=True, transform=Compose([ToTensor(), Normalize(0.5, 0.5)]))\n",
    "#val_dataset = torchvision.datasets.CIFAR10('data', train=False, download=True, transform=Compose([ToTensor(), Normalize(0.5, 0.5)]))\n",
    "#dataloader = torch.utils.data.DataLoader(train_dataset, load_batch_size, shuffle=True, num_workers=4)\n",
    "dataloader=train_loader\n",
    "\n",
    "writer = SummaryWriter(os.path.join('logs', 'cifar10', 'mae-pretrain'))\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = MAE_ViT(mask_ratio=mask_ratio).to(device)\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=base_learning_rate * batch_size / 256, betas=(0.9, 0.95), weight_decay=weight_decay)\n",
    "lr_func = lambda epoch: min((epoch + 1) / (warmup_epoch + 1e-8), 0.5 * (math.cos(epoch / total_epoch * math.pi) + 1))\n",
    "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=lr_func, verbose=True)\n",
    "\n",
    "step_count = 0\n",
    "optim.zero_grad()\n",
    "for e in range(total_epoch):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for img, label in tqdm(iter(dataloader)):\n",
    "        step_count += 1\n",
    "        img = img.to(device)\n",
    "        predicted_img, mask = model(img)\n",
    "        loss = torch.mean((predicted_img - img) ** 2 * mask) / mask_ratio\n",
    "        loss.backward()\n",
    "        if step_count % steps_per_update == 0:\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "    lr_scheduler.step()\n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "\n",
    "    current_lr = lr_scheduler.get_last_lr()[0]\n",
    "    print(f'Epoch {e+1}/{total_epoch}, Learning Rate: {current_lr:.6f}, Average Training Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    writer.add_scalar('mae_loss', avg_loss, global_step=e)\n",
    "    print(f'In epoch {e}, average traning loss is {avg_loss}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "39f6f0a2-c76e-4597-a5ee-755967de149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'mae.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5679e36-235d-4fcd-9990-970ed00674f1",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "fed21d90-27e7-438b-b368-cc8be95da30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_reconstruction(model, test_loader, device, num_images=8):\n",
    "    model.eval()\n",
    "\n",
    "    data_iter = iter(test_loader)\n",
    "    images, _ = next(data_iter)\n",
    "\n",
    "    images = images.to(device)\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        reconstructed_images, _ = model(images)\n",
    "\n",
    "    images = images.cpu()\n",
    "    reconstructed_images = reconstructed_images.cpu()\n",
    "\n",
    "    fig, axes = plt.subplots(2, num_images, figsize=(num_images * 2, 4))\n",
    "    for i in range(num_images):\n",
    "\n",
    "        axes[0, i].imshow(images[i].permute(1, 2, 0).numpy())\n",
    "        axes[0, i].axis('off')\n",
    "        axes[0, i].set_title(\"Original\")\n",
    "        \n",
    "        axes[1, i].imshow(reconstructed_images[i].permute(1, 2, 0).numpy())\n",
    "        axes[1, i].axis('off')\n",
    "        axes[1, i].set_title(\"Reconstructed\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "visualize_reconstruction(model, test_loader, device, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb8ce9-051d-42d7-ae4c-7c447b519ca4",
   "metadata": {},
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "bc134ae8-da3a-4938-b011-af9c2e6cee73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 877/877 [00:43<00:00, 19.97it/s]\n",
      "Extracting features: 100%|██████████| 274/274 [00:14<00:00, 18.79it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_features(encoder, data_loader, device):\n",
    "    encoder.eval()\n",
    "    features_list = []\n",
    "    labels_list = [] \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader, desc=\"Extracting features\"): \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device) \n",
    "            features, _ = encoder(inputs)\n",
    "\n",
    "            features = features[0].cpu().numpy()\n",
    "            labels = labels.cpu().numpy()  \n",
    "            features_list.append(features)\n",
    "            labels_list.append(labels)\n",
    "\n",
    "    features_array = np.vstack(features_list)\n",
    "    labels_array = np.concatenate(labels_list)\n",
    "    return features_array, labels_array\n",
    "\n",
    "encoder = model.encoder\n",
    "\n",
    "X_train_features, y_train_features = extract_features(encoder, train_loader, device)\n",
    "X_test_features, y_test_features = extract_features(encoder, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ae023a32-29f1-448f-b732-e26c17e10ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448735, 192)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "fd29ba9f-2119-47c5-9ea9-578a46fc6c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448735"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e24b5b7-003e-4d3e-a15a-1fa2a9e46227",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "66cba2d6-5248-4d1f-88b1-c6fecec514a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "94e8d2ff-6d10-402f-960f-abbccbbb2803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18]),\n",
       " array([ 30073,   1823,   1339,  14562,  14165,     18,   3246,  24286,\n",
       "         13316,     72,   3810, 259964,  49365,    650,  20234,   1354,\n",
       "           294,    733,   9431]))"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "24da9439-bf33-4725-87eb-fc8b9a72d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_binary = np.where(y_test == 11, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "a25ab7a6-28db-4f28-b902-e337db96b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = X_train_features[y_train == 11] # 11 is normal class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "d9af2888-0545-4e12-9088-66f1fcc2d6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259964"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "9e824718-d5ec-4b1f-a41e-1f69ea226578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, y_test, y_pred):\n",
    "    positive_class = \"normal\"\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred, pos_label=positive_class)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=positive_class)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=positive_class)\n",
    "    \n",
    "    metrics = {\n",
    "        'model': [model],\n",
    "        'accuracy': [accuracy],\n",
    "        'precision': [precision],\n",
    "        'recall': [recall],\n",
    "        'f1': [f1],\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "5075935c-8ef3-4430-8c75-850f433e07f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_binary = np.where(y_test_features == 11, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449f0f8e-abc0-4d09-a6ed-4a39a3ccfd11",
   "metadata": {},
   "source": [
    "# SGDOCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "9646748f-776a-4220-a203-361a6cdcc54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDOneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "62a5789f-d802-4414-adbe-b7c29e329ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.97, NNZs: 192, Bias: -22.075314, T: 448735, Avg. loss: 0.026048\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.07, NNZs: 192, Bias: -23.331380, T: 897470, Avg. loss: 0.032506\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.13, NNZs: 192, Bias: -24.063186, T: 1346205, Avg. loss: 0.035521\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.18, NNZs: 192, Bias: -24.581211, T: 1794940, Avg. loss: 0.037145\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.21, NNZs: 192, Bias: -24.982204, T: 2243675, Avg. loss: 0.038732\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.24, NNZs: 192, Bias: -25.309588, T: 2692410, Avg. loss: 0.039678\n",
      "Total training time: 1.34 seconds.\n",
      "Convergence after 6 epochs took 1.34 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-39 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-39 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-39 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-39 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-39 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-39 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-39 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-39 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-39 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-39 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-39 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-39 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-39 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-39 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-39 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-39 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-39 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-39 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-39 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-39 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-39 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-39 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-39 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-39 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-39 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-39 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-39 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-39 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-39 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-39 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-39 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-39 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-39 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-39 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-39 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-39 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-39 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-39 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-39 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-39 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-39 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-39 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-39\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDOneClassSVM(eta0=0.3, nu=0.9, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" checked><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SGDOneClassSVM<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.SGDOneClassSVM.html\">?<span>Documentation for SGDOneClassSVM</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SGDOneClassSVM(eta0=0.3, nu=0.9, verbose=3)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SGDOneClassSVM(eta0=0.3, nu=0.9, verbose=3)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_svm = SGDOneClassSVM(nu=0.9, verbose=3, eta0=0.3, learning_rate='optimal')\n",
    "sgd_svm.fit(X_train_features, y_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "f07e84c2-ecce-441b-8c74-539b2bbad33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sgd_svm = sgd_svm.predict(X_test_features)\n",
    "y_preds_sgd_svm_binary = np.where(y_pred_sgd_svm == 1, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "79228fb7-0744-4bb6-a693-181af1d452ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDOCSVM</td>\n",
       "      <td>0.607031</td>\n",
       "      <td>0.600681</td>\n",
       "      <td>0.959601</td>\n",
       "      <td>0.738859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  accuracy  precision    recall        f1\n",
       "0  SGDOCSVM  0.607031   0.600681  0.959601  0.738859"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_sgd_svm = pd.DataFrame(evaluate_model(\"SGDOCSVM\", y_test_binary, y_preds_sgd_svm_binary))\n",
    "results_sgd_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e7fa13-4dd4-4136-90d5-ea6acc610693",
   "metadata": {},
   "source": [
    "# IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "7437c729-32d4-4348-ae1b-f357ccef34ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "a134e32a-565d-4d93-8adc-c0db13c74f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-56 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-56 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-56 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-56 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-56 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-56 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-56 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-56 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-56 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-56 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-56 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-56 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-56 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-56 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-56 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-56 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-56 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-56 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-56 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-56 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-56 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-56 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-56 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-56 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-56 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-56 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-56 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-56 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-56 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-56 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-56 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-56 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-56 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-56 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-56 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-56 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-56 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-56 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-56 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-56 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-56 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-56 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-56\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IsolationForest(contamination=0.05, max_samples=256, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" checked><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;IsolationForest<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.IsolationForest.html\">?<span>Documentation for IsolationForest</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>IsolationForest(contamination=0.05, max_samples=256, verbose=1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "IsolationForest(contamination=0.05, max_samples=256, verbose=1)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_if = IsolationForest(n_estimators=100, max_samples=256, contamination=0.05, verbose=1)\n",
    "model_if.fit(X_train_features, y_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "55285674-3c11-4b3d-955c-e1c4a79e76ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_if = model_if.predict(X_test_features)\n",
    "y_preds_if_binary = np.where(y_pred_if == 1, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "4dced8ff-71bf-4310-ba7c-550c50b17ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IF</td>\n",
       "      <td>0.604414</td>\n",
       "      <td>0.595937</td>\n",
       "      <td>0.985069</td>\n",
       "      <td>0.742615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  precision    recall        f1\n",
       "0    IF  0.604414   0.595937  0.985069  0.742615"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_if = pd.DataFrame(evaluate_model(\"IF\", y_test_binary, y_preds_if_binary))\n",
    "results_if"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b852af8c-16cd-4a1b-bd9f-9d3818da3116",
   "metadata": {},
   "source": [
    "# PCA Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "09c1136f-f132-44af-96f6-a0956e7a7944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "e23b31e8-3d23-4ee1-a731-cc03a6d48e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds: 0.24628782272338867\n"
     ]
    }
   ],
   "source": [
    "pca_start = time()\n",
    "\n",
    "pca = PCA(n_components=2, whiten=True, svd_solver='auto')\n",
    "\n",
    "normal_data_pca = pca.fit_transform(normal_data)\n",
    "normal_data_reconstructed = pca.inverse_transform(normal_data_pca)\n",
    "\n",
    "reconstruction_error = np.mean((normal_data - normal_data_reconstructed) ** 2, axis=1)\n",
    "\n",
    "threshold = np.percentile(reconstruction_error, 95)\n",
    "\n",
    "X_test_pca = pca.transform(X_test)\n",
    "X_test_reconstructed = pca.inverse_transform(X_test_pca)\n",
    "X_test_reconstruction_error = np.mean((X_test - X_test_reconstructed) ** 2, axis=1)\n",
    "\n",
    "print(f\"seconds: {time() - pca_start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "ca33dbc6-e0e8-4612-b47e-1b058c58a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_pca = np.where(X_test_reconstruction_error > threshold, 'anomaly', 'normal')\n",
    "y_test_converted_pca = np.where(y_test == 11, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "c6f9717f-159f-4b72-9256-75b66e833a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA Reconstruction</td>\n",
       "      <td>0.872937</td>\n",
       "      <td>0.848701</td>\n",
       "      <td>0.950036</td>\n",
       "      <td>0.896514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  accuracy  precision    recall        f1\n",
       "0  PCA Reconstruction  0.872937   0.848701  0.950036  0.896514"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_df = pd.DataFrame(evaluate_model('PCA Reconstruction', y_test_converted_pca, y_pred_test_pca))\n",
    "pca_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b62f32-6b37-4dbf-9ed4-c85e20f8e6fc",
   "metadata": {},
   "source": [
    "# LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "05b065b7-4b14-4688-9e18-aebb6e1503bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "bbaaa459-5b28-4a06-9c3d-3110d38ada64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-62 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-62 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-62 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-62 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-62 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-62 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-62 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-62 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-62 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-62 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-62 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-62 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-62 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-62 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-62 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-62 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-62 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-62 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-62 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-62 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-62 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-62 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-62 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-62 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-62 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-62 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-62 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-62 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-62 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-62 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-62 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-62 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-62 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-62 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-62 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-62 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-62 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-62 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-62 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-62 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-62 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-62 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-62\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LocalOutlierFactor(contamination=0.001, n_neighbors=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" checked><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LocalOutlierFactor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.LocalOutlierFactor.html\">?<span>Documentation for LocalOutlierFactor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LocalOutlierFactor(contamination=0.001, n_neighbors=100)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LocalOutlierFactor(contamination=0.001, n_neighbors=100)"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lof_model = LocalOutlierFactor(n_neighbors=100, contamination=0.001)\n",
    "lof_model.fit(X_train_features, y_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "d6557c96-79a5-4d38-b17e-9ca84b264987",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lof = lof_model.fit_predict(X_test_features)\n",
    "y_preds_lof_binary = np.where(y_pred_lof == 1, 'normal', 'anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "5f71adf5-8985-4c2c-a6b2-ce57833e37d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOF</td>\n",
       "      <td>0.57942</td>\n",
       "      <td>0.579453</td>\n",
       "      <td>0.999212</td>\n",
       "      <td>0.733527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  precision    recall        f1\n",
       "0   LOF   0.57942   0.579453  0.999212  0.733527"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lof_df = pd.DataFrame(evaluate_model(\"LOF\", y_test_binary, y_preds_lof_binary))\n",
    "lof_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e5f17c-396e-4a8a-b50f-10488fcb297d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
